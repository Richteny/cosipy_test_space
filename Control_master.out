20
TSL file: ./data/input/Abramov/snowlines/TSLA_Abramov_filtered_jaso.csv
Time start:  2009-10-01T00:00
Time end:  2019-12-31T00:00
Initialised.
Initializing the  Markov Chain Monte Carlo (MCMC) sampler  with  1000  repetitions
The objective function will be maximized
Starting the MCMC algotrithm with 1000 repetitions...
Initialize  1  chain(s)...
Count 1
Time required to load in opt_dic:  0:00:00.000005

 Maximum available time interval from 1999-01-01T00:00 until 2019-12-31T23:00. Time steps: 184080 


--------------------------------------------------------------
	 Integration from 2009-10-01T00:00 to 2019-12-31T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Time required to init IO, DATA, RESULT, RESTART:  0:00:08.197643
#--------------------------------------#

Starting run with lapse rates: -0.005971531123172777 and: 0.00010071047670654723

Albedo ice, snow and firn: 0.21751530721120413 , 0.6662628982463199 and 0.6372213843133333

RRR mult factor is: 0.6607544851901438

#--------------------------------------#
(89833, 27, 37)
Assigning values back to DATA
Seconds needed for lapse rate: 0:00:01.786054
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/340, jobs=0/17)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 340 2
