20
Time required to load in opt_dic:  0:00:00.000007

 Maximum available time interval from 1999-01-01T00:00 until 2010-01-01T00:00. Time steps: 96444 


--------------------------------------------------------------
	 Integration from 1999-01-01T00:00 to 2005-01-01T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Please check the input data, its seems they are out of range T2 MAX: 298.32 MIN: 240.05 

Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Please check the input data, its seems they are out of range G MAX: 2027.60 MIN: 0.00 

Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Please check the input data, its seems they are out of range Rrr MAX: 67.49 MIN: 0.00 

Cloud cover data (N) ... ok 
Pressure data (PRES) ... ok 

 Glacier gridpoints: 120 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Time required to init IO, DATA, RESULT, RESTART:  0:00:02.069593
#--------------------------------------#

Starting run with lapse rates: -0.0065 and: 0.0

Albedo ice, snow and firn: 0.2 , 0.77 and 0.55

RRR mult factor is: 0.25

#--------------------------------------#
(52616, 14, 30)
Assigning values back to DATA
100.0
0.04078483581542969
(52616, 14, 30)
Seconds needed for lapse rate: 0:00:02.059025
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:35569 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/380, jobs=0/19)
<Client: scheduler='tcp://192.168.1.9:35569' processes=0 cores=0>
420 380 1
