20
TSL file: ./data/input/Abramov/snowlines/TSLA_Abramov_filtered_jaso.csv
Time start:  1998-10-01T00:00
Time end:  2019-09-30T00:00
Initialised.
Initializing the  Markov Chain Monte Carlo (MCMC) sampler  with  300  repetitions
The objective function will be maximized
Starting the MCMC algotrithm with 300 repetitions...
Initialize  1  chain(s)...
Count 1249

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0059509381057373184 and: 0.00013710719032091213

Albedo ice, snow and firn: 0.3609012508165561 , 0.8489521113420062 and 0.5168226028042509

RRR mult factor is: 0.6494486852535479

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 7.51748 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 280.2740477450358; R-squared: 0.20940339762425722
	 Time required to write restart and output files:    3 minutes 43.8894 seconds 

	 Total run duration:   41 minutes 50.1455 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -276.0054540617289
1 of 300, maximal objective function=-276.005, time remaining: 07:53:42
Initialize database...
['csv', 'hdf5', 'ram', 'sql', 'custom', 'noData']
* Database file 'cosipy_par_smpl.csv' created.
Beginn of Random Walk
Count 1250

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005678176343410799 and: 0.0001335646705504166

Albedo ice, snow and firn: 0.36870866179334777 , 0.8399723375300623 and 0.5141920143390727

RRR mult factor is: 0.6397682978629036

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.8024 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 301.39990319078504; R-squared: 0.19933433089240182
	 Time required to write restart and output files:    3 minutes 44.9946 seconds 

	 Total run duration:   38 minutes 28.0336 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -297.33409647696243
2 of 300, maximal objective function=-276.005, time remaining: 12:30:14
Acceptance rates [%] =100.
Count 1251

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005736593051844328 and: 0.00014119209280472294

Albedo ice, snow and firn: 0.36885994713881687 , 0.839630518983978 and 0.5100813327047102

RRR mult factor is: 0.6393562987934858

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 31.1623 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 298.99022641144717; R-squared: 0.22230789506856835
	 Time required to write restart and output files:    3 minutes 41.4068 seconds 

	 Total run duration:   38 minutes 32.6645 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -298.2662680095036
3 of 300, maximal objective function=-276.005, time remaining: 02:34:58
Acceptance rates [%] =100.
Count 1252

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005659713072859995 and: 0.00015441665826470898

Albedo ice, snow and firn: 0.3565334170213272 , 0.8384608753020596 and 0.5138186758510297

RRR mult factor is: 0.6393350415278052

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 21.1679 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 297.7602347739627; R-squared: 0.22906178846157088
	 Time required to write restart and output files:    3 minutes 40.8399 seconds 

	 Total run duration:   37 minutes 55.9497 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -297.5521099061302
4 of 300, maximal objective function=-276.005, time remaining: 10:10:17
Acceptance rates [%] =100.
Count 1253

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0055798517150985995 and: 0.00015685831168076327

Albedo ice, snow and firn: 0.35757421481583423 , 0.8347179019946598 and 0.5213240508324808

RRR mult factor is: 0.6342373846599695

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.2893 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 312.79486659229485; R-squared: 0.1683589484638818
	 Time required to write restart and output files:    3 minutes 40.8649 seconds 

	 Total run duration:   37 minutes 55.6564 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.90478648667994
5 of 300, maximal objective function=-276.005, time remaining: 15:00:57
Acceptance rates [%] =100.
Count 1254

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00579067410521121 and: 0.00014469880636611796

Albedo ice, snow and firn: 0.3599723510173133 , 0.8324706964333379 and 0.5283533625594758

RRR mult factor is: 0.6316923679247104

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.7019 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 321.60439103924296; R-squared: 0.14146219926095158
	 Time required to write restart and output files:    3 minutes 40.9129 seconds 

	 Total run duration:   37 minutes 51.5775 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -309.65863194308423
6 of 300, maximal objective function=-276.005, time remaining: 18:14:53
Acceptance rates [%] =100.
Count 1255

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0060002797179588814 and: 0.00016624109704315316

Albedo ice, snow and firn: 0.3709196368786214 , 0.8382721078687759 and 0.5286551015940254

RRR mult factor is: 0.6324004986202053

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.3089 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 319.3215339247104; R-squared: 0.1370540236306359
	 Time required to write restart and output files:    3 minutes 41.1251 seconds 

	 Total run duration:   37 minutes 54.097 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.0978701645288
7 of 300, maximal objective function=-276.005, time remaining: 20:32:24
Acceptance rates [%] =100.
Count 1256

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0062156611359217954 and: 0.00015113544129031727

Albedo ice, snow and firn: 0.3531210710169178 , 0.8360887709316421 and 0.5199840360798493

RRR mult factor is: 0.6329320891488512

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.7041 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 324.43705936524645; R-squared: 0.13352097368581764
	 Time required to write restart and output files:    3 minutes 42.5358 seconds 

	 Total run duration:   38 minutes 23.5328 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -311.94368598070093
8 of 300, maximal objective function=-276.005, time remaining: 22:26:49
Acceptance rates [%] =100.
Count 1257

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006710885049999107 and: 0.00016577942875640528

Albedo ice, snow and firn: 0.35709143749525213 , 0.8320729257706353 and 0.533131385413522

RRR mult factor is: 0.6332981559650478

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.9979 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 328.79757290939193; R-squared: 0.13356176528525815
	 Time required to write restart and output files:    3 minutes 41.1539 seconds 

	 Total run duration:   37 minutes 54.5664 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -316.16679131080735
9 of 300, maximal objective function=-276.005, time remaining: 23:36:39
Acceptance rates [%] =100.
Count 1258

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006822955148784799 and: 0.00016460259565312564

Albedo ice, snow and firn: 0.36738806497014737 , 0.8197258118285562 and 0.5192735608989296

RRR mult factor is: 0.6418687717566393

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 23.8792 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 373.1282641810607; R-squared: 0.1828711983670957
	 Time required to write restart and output files:    3 minutes 43.8333 seconds 

	 Total run duration:   38 minutes 0.299777 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -370.1109009012195
10 of 300, maximal objective function=-276.005, time remaining: 00:29:26
Acceptance rates [%] =100.
Count 1259

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006976812795817533 and: 0.00016690896670646196

Albedo ice, snow and firn: 0.36478818263959434 , 0.8014533210771909 and 0.5415866252320318

RRR mult factor is: 0.6373184813285473

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 6.92377 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 393.100786636008; R-squared: 0.15201627493264935
	 Time required to write restart and output files:    3 minutes 44.4219 seconds 

	 Total run duration:   38 minutes 6.51511 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -390.7582474410298
11 of 300, maximal objective function=-276.005, time remaining: 01:09:35
Acceptance rates [%] =100.
Count 1260

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006921787976868302 and: 0.0001551255772337225

Albedo ice, snow and firn: 0.3883623966825308 , 0.8003629216565228 and 0.56243493243021

RRR mult factor is: 0.6338673512423522

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.3077 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 395.3616207298781; R-squared: 0.14581005275836403
	 Time required to write restart and output files:    3 minutes 45.0073 seconds 

	 Total run duration:   38 minutes 16.621 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -391.5063014557348
12 of 300, maximal objective function=-276.005, time remaining: 01:41:24
Acceptance rates [%] =100.
Count 1261

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006681561460841607 and: 0.0001525934614911082

Albedo ice, snow and firn: 0.3876190182175558 , 0.7990622746667758 and 0.5683145048585029

RRR mult factor is: 0.6311716041385851

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.6633 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 379.520967790068; R-squared: 0.1690916857209783
	 Time required to write restart and output files:    3 minutes 43.3042 seconds 

	 Total run duration:   38 minutes 17.5275 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -376.1648189442587
13 of 300, maximal objective function=-276.005, time remaining: 02:03:31
Acceptance rates [%] =100.
Count 1262

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006456551330135148 and: 0.00012774769866195744

Albedo ice, snow and firn: 0.3730146680295248 , 0.797586566994724 and 0.5394512623140141

RRR mult factor is: 0.6362290703922926

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 10.8463 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 391.67129270699866; R-squared: 0.153591982821214
	 Time required to write restart and output files:    3 minutes 44.8345 seconds 

	 Total run duration:   37 minutes 52.4709 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -390.1059034387079
14 of 300, maximal objective function=-276.005, time remaining: 02:09:39
Acceptance rates [%] =100.
Count 1263

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006636759199802929 and: 0.00014268638067113618

Albedo ice, snow and firn: 0.38497302886074125 , 0.7803417452117701 and 0.5352005891095196

RRR mult factor is: 0.6376226791770622

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 4.38991 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 397.35917388331796; R-squared: 0.14815371215755296
	 Time required to write restart and output files:    3 minutes 42.0646 seconds 

	 Total run duration:   37 minutes 55.9535 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -396.6581164583374
15 of 300, maximal objective function=-276.005, time remaining: 02:11:17
Acceptance rates [%] =100.
Count 1264

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006645131177536354 and: 0.00014134079626345838

Albedo ice, snow and firn: 0.39345230341220705 , 0.7686757257545974 and 0.5408991927513576

RRR mult factor is: 0.6419275871992631

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.2442 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 428.20275033100796; R-squared: 0.16293982331955806
	 Time required to write restart and output files:    3 minutes 41.784 seconds 

	 Total run duration:   37 minutes 53.7211 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -434.2709296630381
16 of 300, maximal objective function=-276.005, time remaining: 02:07:39
Acceptance rates [%] =100.
Count 1265

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006968728414520155 and: 0.00015940775088078602

Albedo ice, snow and firn: 0.3925709534877099 , 0.7835899058567496 and 0.5385134297075039

RRR mult factor is: 0.6532395363038207

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 15.1676 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 391.1234137691731; R-squared: 0.15894616253721358
	 Time required to write restart and output files:    3 minutes 42.4664 seconds 

	 Total run duration:   37 minutes 51.9588 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -388.9278999406908
17 of 300, maximal objective function=-276.005, time remaining: 01:59:44
Acceptance rates [%] =100.
Count 1266

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006881215577187808 and: 0.00016359704049099576

Albedo ice, snow and firn: 0.38065642126957644 , 0.7632208902359673 and 0.5302589765570505

RRR mult factor is: 0.6534161506110043

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   20 minutes 47.9026 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 433.37750155329707; R-squared: 0.1535792342281722
	 Time required to write restart and output files:    3 minutes 43.8947 seconds 

	 Total run duration:   45 minutes 17.5094 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -435.5872101234455
18 of 300, maximal objective function=-276.005, time remaining: 03:38:31
Acceptance rates [%] =100.
Count 1267

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006977676019669858 and: 0.00015352717988580185

Albedo ice, snow and firn: 0.3781324686144149 , 0.786986773916258 and 0.5268714078177371

RRR mult factor is: 0.6570255854122039

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.4983 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 382.653151330391; R-squared: 0.17664996060338067
	 Time required to write restart and output files:    3 minutes 42.3064 seconds 

	 Total run duration:   38 minutes 12.0106 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -381.098016636264
19 of 300, maximal objective function=-276.005, time remaining: 03:23:36
Acceptance rates [%] =100.
Count 1268

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006928893412103712 and: 0.000159811484047644

Albedo ice, snow and firn: 0.3767316249789571 , 0.7890543494884028 and 0.5379782403838855

RRR mult factor is: 0.6581912116025652

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.7157 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 370.0013010557502; R-squared: 0.22242064451638374
	 Time required to write restart and output files:    3 minutes 42.5447 seconds 

	 Total run duration:   38 minutes 11.0371 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -372.25317782086233
20 of 300, maximal objective function=-276.005, time remaining: 03:06:14
Acceptance rates [%] =100.
Count 1269

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006793659986873424 and: 0.00015127631370705577

Albedo ice, snow and firn: 0.38018104440185324 , 0.789000384202906 and 0.5405069771812724

RRR mult factor is: 0.6552950811119126

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.2788 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 371.50797302784497; R-squared: 0.19389578925481396
	 Time required to write restart and output files:    3 minutes 49.9733 seconds 

	 Total run duration:   38 minutes 21.2901 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -370.7069000378001
21 of 300, maximal objective function=-276.005, time remaining: 02:49:11
Acceptance rates [%] =100.
Count 1270

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0065512173019115355 and: 0.00012521807059270472

Albedo ice, snow and firn: 0.3931366138230343 , 0.792509237003103 and 0.5317114823415087

RRR mult factor is: 0.6495952096820132

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 11.8314 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 382.0865885452616; R-squared: 0.18355036458535376
	 Time required to write restart and output files:    3 minutes 42.7532 seconds 

	 Total run duration:   38 minutes 12.0462 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -384.13636086504437
22 of 300, maximal objective function=-276.005, time remaining: 02:28:24
Acceptance rates [%] =100.
Count 1271

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006985453575834832 and: 0.00012198029526469836

Albedo ice, snow and firn: 0.39976078221256045 , 0.7964996554376408 and 0.5342801154757649

RRR mult factor is: 0.6579125441048959

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 7.30323 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 380.46341883186733; R-squared: 0.18686068149352386
	 Time required to write restart and output files:    3 minutes 42.6959 seconds 

	 Total run duration:   38 minutes 16.9555 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -381.24718998964863
23 of 300, maximal objective function=-276.005, time remaining: 02:07:05
Acceptance rates [%] =100.
Count 1272

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006874968280659108 and: 0.00010605256624109612

Albedo ice, snow and firn: 0.39441733752141356 , 0.7916328160698815 and 0.5258726887329148

RRR mult factor is: 0.6640324836517596

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 8.57191 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 390.7463440352644; R-squared: 0.1619458665367106
	 Time required to write restart and output files:    3 minutes 47.93 seconds 

	 Total run duration:   38 minutes 22.1789 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -391.3258704972849
24 of 300, maximal objective function=-276.005, time remaining: 01:45:24
Acceptance rates [%] =100.
Count 1273

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006889686798291705 and: 0.00013913497802497593

Albedo ice, snow and firn: 0.39984035230404025 , 0.7983627831863318 and 0.530996982532349

RRR mult factor is: 0.662784295359585

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.2782 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 383.2548583206203; R-squared: 0.1762304225274866
	 Time required to write restart and output files:    3 minutes 46.235 seconds 

	 Total run duration:   38 minutes 28.0733 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -384.45925525863765
25 of 300, maximal objective function=-276.005, time remaining: 01:23:28
Acceptance rates [%] =100.
Count 1274

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006881476560409528 and: 0.0001664893148950416

Albedo ice, snow and firn: 0.39208132403349943 , 0.7900393327972113 and 0.5440427725225988

RRR mult factor is: 0.6640167328960185

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 15.2409 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 387.865581384942; R-squared: 0.16697234887580437
	 Time required to write restart and output files:    3 minutes 48.5414 seconds 

	 Total run duration:   38 minutes 7.06713 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -389.02733017746095
26 of 300, maximal objective function=-276.005, time remaining: 00:56:47
Acceptance rates [%] =100.
Count 1275

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006989865745957759 and: 0.00015516260012378837

Albedo ice, snow and firn: 0.3973015046515987 , 0.7922375059069043 and 0.5413248172069896

RRR mult factor is: 0.6689095934511041

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.0403 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 391.4730902334479; R-squared: 0.27903859162256966
	 Time required to write restart and output files:    3 minutes 51.1766 seconds 

	 Total run duration:   38 minutes 8.39508 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -404.8635109375005
27 of 300, maximal objective function=-276.005, time remaining: 00:29:30
Acceptance rates [%] =100.
Count 1276

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00686855097436377 and: 0.00015783013872806056

Albedo ice, snow and firn: 0.3918222452378577 , 0.7982259654377888 and 0.537846587449318

RRR mult factor is: 0.6714202211890751

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.557 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 371.3666465181762; R-squared: 0.2283470233954287
	 Time required to write restart and output files:    3 minutes 48.8413 seconds 

	 Total run duration:   38 minutes 43.253 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -377.7010068252684
28 of 300, maximal objective function=-276.005, time remaining: 00:06:55
Acceptance rates [%] =100.
Count 1277

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006803124530363087 and: 0.00015998451202376603

Albedo ice, snow and firn: 0.39924349341791404 , 0.8141188064647195 and 0.5276432585515782

RRR mult factor is: 0.6761739901599129

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 24.2849 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 341.1895700114785; R-squared: 0.24997217243248174
	 Time required to write restart and output files:    3 minutes 48.8019 seconds 

	 Total run duration:   38 minutes 35.8371 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -344.24801030982877
29 of 300, maximal objective function=-276.005, time remaining: 23:42:09
Acceptance rates [%] =100.
Count 1278

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006711464546390412 and: 0.00014111153285910127

Albedo ice, snow and firn: 0.39246954679971857 , 0.8111126019197183 and 0.5389339926299154

RRR mult factor is: 0.6722557044507461

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 12.6367 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 338.85672693278366; R-squared: 0.2765930486809221
	 Time required to write restart and output files:    3 minutes 52.7168 seconds 

	 Total run duration:   38 minutes 38.4942 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -343.26115156023377
30 of 300, maximal objective function=-276.005, time remaining: 23:16:52
Acceptance rates [%] =100.
Count 1279

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00656353108907212 and: 0.0001494191320476937

Albedo ice, snow and firn: 0.39720965408384934 , 0.803686063180933 and 0.5346347870927558

RRR mult factor is: 0.665667244958384

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.5196 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 359.5078895999608; R-squared: 0.23846278814678437
	 Time required to write restart and output files:    3 minutes 52.9009 seconds 

	 Total run duration:   38 minutes 26.7286 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -364.976360520294
31 of 300, maximal objective function=-276.005, time remaining: 22:49:07
Acceptance rates [%] =100.
Count 1280

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0064060337920276746 and: 0.00012513376721643303

Albedo ice, snow and firn: 0.38121655430797274 , 0.8239830585038094 and 0.5431194566541518

RRR mult factor is: 0.6609288579461639

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.4999 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 330.01593159263246; R-squared: 0.13413632629675185
	 Time required to write restart and output files:    3 minutes 48.7115 seconds 

	 Total run duration:   38 minutes 28.5175 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -318.97021294464696
32 of 300, maximal objective function=-276.005, time remaining: 22:20:57
Acceptance rates [%] =100.
Count 1281

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006389455109378341 and: 0.00010306593969574467

Albedo ice, snow and firn: 0.3869909637689435 , 0.8352520604970537 and 0.5381573031368867

RRR mult factor is: 0.6694814170355621

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.4211 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 328.27198167237316; R-squared: 0.13427552800848674
	 Time required to write restart and output files:    3 minutes 48.2638 seconds 

	 Total run duration:   38 minutes 2.32063 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -317.04459489958873
33 of 300, maximal objective function=-276.005, time remaining: 21:48:47
Acceptance rates [%] =100.
Count 1282

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006068152645609763 and: 9.978187583890384e-05

Albedo ice, snow and firn: 0.38200723186544094 , 0.8515509040524569 and 0.5288027458713617

RRR mult factor is: 0.6669340475395439

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 11.6012 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 322.3973028332958; R-squared: 0.14910120507779348
	 Time required to write restart and output files:    3 minutes 54.2422 seconds 

	 Total run duration:   38 minutes 14.0066 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -315.4574728873908
34 of 300, maximal objective function=-276.005, time remaining: 21:17:44
Acceptance rates [%] =100.
Count 1283

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0055701336878297035 and: 8.148281661894569e-05

Albedo ice, snow and firn: 0.38085019245711466 , 0.8359082323186765 and 0.5374657549775899

RRR mult factor is: 0.6697441470320019

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.5782 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 390.6622257240831; R-squared: 0.1483057411365899
	 Time required to write restart and output files:    3 minutes 49.3889 seconds 

	 Total run duration:   38 minutes 36.3453 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -390.9278400485225
35 of 300, maximal objective function=-276.005, time remaining: 20:49:02
Acceptance rates [%] =100.
Count 1284

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005500155305644165 and: 6.488598084875657e-05

Albedo ice, snow and firn: 0.37142625681170455 , 0.8241274760988228 and 0.5394193131372268

RRR mult factor is: 0.6687505360307825

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 42.6969 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 420.71607135778856; R-squared: 0.1779543942173849
	 Time required to write restart and output files:    3 minutes 51.0469 seconds 

	 Total run duration:   39 minutes 2.66213 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -430.4363721434746
36 of 300, maximal objective function=-276.005, time remaining: 20:22:54
Acceptance rates [%] =100.
Count 1285

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005470830610644119 and: 5.482184220238151e-05

Albedo ice, snow and firn: 0.37676406856047734 , 0.8263235367906022 and 0.5554693422682905

RRR mult factor is: 0.6750076045686122

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 4.81061 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 389.1591764584369; R-squared: 0.22351398801414424
	 Time required to write restart and output files:    3 minutes 47.7528 seconds 

	 Total run duration:   38 minutes 17.4517 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -400.94823544878
37 of 300, maximal objective function=-276.005, time remaining: 19:50:54
Acceptance rates [%] =100.
Count 1286

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005118899821897853 and: 5.5120268218435324e-05

Albedo ice, snow and firn: 0.38489378204741725 , 0.8303408577516945 and 0.5381017244476347

RRR mult factor is: 0.6696859640873463

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 7.5075 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 405.04380485643526; R-squared: 0.22092617491719538
	 Time required to write restart and output files:    3 minutes 50.3311 seconds 

	 Total run duration:   38 minutes 6.80205 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -420.63956176111304
38 of 300, maximal objective function=-276.005, time remaining: 19:17:24
Acceptance rates [%] =100.
Count 1287

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005168358912328396 and: 8.303968374243274e-05

Albedo ice, snow and firn: 0.3801962666961175 , 0.833333190500941 and 0.5234187763659813

RRR mult factor is: 0.6716935091616093

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 6.62559 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 371.5215357563696; R-squared: 0.19383577064503182
	 Time required to write restart and output files:    3 minutes 52.3032 seconds 

	 Total run duration:   38 minutes 24.6501 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -377.85705117809204
39 of 300, maximal objective function=-276.005, time remaining: 18:45:35
Acceptance rates [%] =100.
Count 1288

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005065833040668492 and: 0.00010616054689643982

Albedo ice, snow and firn: 0.3789004267246705 , 0.828592817957409 and 0.5135308112761611

RRR mult factor is: 0.6712967993558514

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.1989 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 389.92909068385836; R-squared: 0.143137929293406
	 Time required to write restart and output files:    3 minutes 53.135 seconds 

	 Total run duration:   39 minutes 3.89407 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -388.1495757700345
40 of 300, maximal objective function=-276.005, time remaining: 18:17:35
Acceptance rates [%] =100.
Count 1289

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005119422673672474 and: 0.00014028171838146195

Albedo ice, snow and firn: 0.37558745956238104 , 0.8344287464966496 and 0.5348149582733974

RRR mult factor is: 0.6724161705740979

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.516 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 332.6712163411138; R-squared: 0.11304315771781039
	 Time required to write restart and output files:    3 minutes 49.6464 seconds 

	 Total run duration:   38 minutes 46.6699 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -319.20589881276084
41 of 300, maximal objective function=-276.005, time remaining: 17:47:18
Acceptance rates [%] =100.
Count 1290

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005647211286071189 and: 0.00014019586923043936

Albedo ice, snow and firn: 0.3801350219415411 , 0.8309603502721868 and 0.5167003446334154

RRR mult factor is: 0.6670756115181621

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.8689 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 335.67713383827044; R-squared: 0.11340782224753151
	 Time required to write restart and output files:    3 minutes 47.8177 seconds 

	 Total run duration:   38 minutes 18.4438 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -321.92057644923534
42 of 300, maximal objective function=-276.005, time remaining: 17:13:49
Acceptance rates [%] =100.
Count 1291

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005783506588848829 and: 0.00012468651479371348

Albedo ice, snow and firn: 0.3738030295289805 , 0.833046124676801 and 0.5256618434423107

RRR mult factor is: 0.6685050694178035

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.5079 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 335.29531144080113; R-squared: 0.1150521334474738
	 Time required to write restart and output files:    3 minutes 49.0953 seconds 

	 Total run duration:   37 minutes 53.5211 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -321.7997456360212
43 of 300, maximal objective function=-276.005, time remaining: 16:37:41
Acceptance rates [%] =100.
Count 1292

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005869310676351737 and: 0.0001165413690722717

Albedo ice, snow and firn: 0.38480111267537354 , 0.8304783687428601 and 0.5055220363026391

RRR mult factor is: 0.6678493610770294

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.395 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 330.04226668301254; R-squared: 0.1338074658266229
	 Time required to write restart and output files:    3 minutes 52.7174 seconds 

	 Total run duration:   37 minutes 59.4419 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -320.1124840236188
44 of 300, maximal objective function=-276.005, time remaining: 16:02:03
Acceptance rates [%] =100.
Count 1293

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005914516828057761 and: 0.00012122040221962328

Albedo ice, snow and firn: 0.38008941394469486 , 0.8367708828262332 and 0.5134304122437696

RRR mult factor is: 0.6662627247608759

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.1948 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 320.2744641907084; R-squared: 0.1554379515739728
	 Time required to write restart and output files:    3 minutes 47.9137 seconds 

	 Total run duration:   38 minutes 17.939 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -314.4794980606826
45 of 300, maximal objective function=-276.005, time remaining: 15:27:58
Acceptance rates [%] =100.
Count 1294

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006077038660071589 and: 0.00011199097068794375

Albedo ice, snow and firn: 0.3534686399873101 , 0.8458176362564791 and 0.5147743136498643

RRR mult factor is: 0.6736003353208604

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 21.9327 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 325.63677811144; R-squared: 0.14087066333187534
	 Time required to write restart and output files:    3 minutes 49.7126 seconds 

	 Total run duration:   38 minutes 59.6419 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -316.8889872947318
46 of 300, maximal objective function=-276.005, time remaining: 14:57:29
Acceptance rates [%] =100.
Count 1295

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006250153584120588 and: 0.00012079240934267407

Albedo ice, snow and firn: 0.3443716929414013 , 0.8602205939400399 and 0.5145878786337136

RRR mult factor is: 0.6758379548152061

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.8767 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 290.43150177623977; R-squared: 0.1622236448585706
	 Time required to write restart and output files:    3 minutes 49.366 seconds 

	 Total run duration:   38 minutes 25.276 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -279.3700846449892
47 of 300, maximal objective function=-276.005, time remaining: 14:23:37
Acceptance rates [%] =100.
Count 1296

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006039923642142185 and: 0.00013072865899338372

Albedo ice, snow and firn: 0.35163882750620085 , 0.8587153461228592 and 0.5079595028447479

RRR mult factor is: 0.679467851342297

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.1633 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 293.47616812749754; R-squared: 0.21279278573598437
	 Time required to write restart and output files:    3 minutes 50.6652 seconds 

	 Total run duration:   38 minutes 29.5307 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -291.06623569925665
48 of 300, maximal objective function=-276.005, time remaining: 13:49:57
Acceptance rates [%] =100.
Count 1297

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005810864763795603 and: 0.00012899884544831394

Albedo ice, snow and firn: 0.3372581614722454 , 0.8443303034538326 and 0.49305063524571235

RRR mult factor is: 0.6799408978723462

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.0861 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 297.6566680389169; R-squared: 0.20712516397129127
	 Time required to write restart and output files:    3 minutes 52.8988 seconds 

	 Total run duration:   38 minutes 44.1076 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -295.3240028042371
49 of 300, maximal objective function=-276.005, time remaining: 13:17:18
Acceptance rates [%] =100.
Count 1298

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00602506182565282 and: 0.0001363542786651764

Albedo ice, snow and firn: 0.3586812222932109 , 0.8532638550869838 and 0.48952248444174695

RRR mult factor is: 0.6780539626037055

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 32.6255 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 283.5437622395405; R-squared: 0.2568520142190461
	 Time required to write restart and output files:    3 minutes 50.647 seconds 

	 Total run duration:   38 minutes 56.7683 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -287.0723887890376
50 of 300, maximal objective function=-276.005, time remaining: 12:45:27
Acceptance rates [%] =100.
Count 1299

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005931089385661829 and: 0.00013616083929035087

Albedo ice, snow and firn: 0.3864506959434958 , 0.8443525126606503 and 0.4817899422759708

RRR mult factor is: 0.6692929451396477

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 49.0598 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 304.6248918265506; R-squared: 0.22373153085030548
	 Time required to write restart and output files:    3 minutes 52.4901 seconds 

	 Total run duration:   39 minutes 14.9275 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -305.9570623775184
51 of 300, maximal objective function=-276.005, time remaining: 12:14:46
Acceptance rates [%] =100.
Count 1300

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006031609550919084 and: 0.00011959891855015608

Albedo ice, snow and firn: 0.3843496388503571 , 0.8368195910784291 and 0.47814008962157273

RRR mult factor is: 0.6697465276320965

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.6967 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 340.0110088602368; R-squared: 0.22057913730911569
	 Time required to write restart and output files:    3 minutes 56.0996 seconds 

	 Total run duration:   38 minutes 22.3027 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -344.16576425335245
52 of 300, maximal objective function=-276.005, time remaining: 11:39:40
Acceptance rates [%] =100.
Count 1301

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005956724039770445 and: 0.00011241082554860684

Albedo ice, snow and firn: 0.3967662047910922 , 0.8388874419468236 and 0.47183061646692115

RRR mult factor is: 0.6712455992860336

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 12.8257 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 325.1476492894631; R-squared: 0.33896752883776576
	 Time required to write restart and output files:    3 minutes 54.0513 seconds 

	 Total run duration:   38 minutes 38.4294 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -337.94525257597513
53 of 300, maximal objective function=-276.005, time remaining: 11:05:41
Acceptance rates [%] =100.
Count 1302

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005829378781859127 and: 0.00012828617087134146

Albedo ice, snow and firn: 0.3904309147632824 , 0.8448869695560741 and 0.48231196497227147

RRR mult factor is: 0.6632965447511046

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.9883 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 347.43109387662736; R-squared: 0.23619139298898614
	 Time required to write restart and output files:    3 minutes 51.3173 seconds 

	 Total run duration:   38 minutes 33.2167 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -352.8053915501029
54 of 300, maximal objective function=-276.005, time remaining: 10:31:08
Acceptance rates [%] =98.11
Count 1303

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006175231801780993 and: 8.887965736945973e-05

Albedo ice, snow and firn: 0.3961159951577264 , 0.8360418709498816 and 0.47209803428538294

RRR mult factor is: 0.6744618838444447

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.8765 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 297.95055363708485; R-squared: 0.2545313543570012
	 Time required to write restart and output files:    3 minutes 50.5306 seconds 

	 Total run duration:   38 minutes 35.5626 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -303.3612778977759
55 of 300, maximal objective function=-276.005, time remaining: 09:56:37
Acceptance rates [%] =98.15
Count 1304

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006139076965358696 and: 9.830151676263918e-05

Albedo ice, snow and firn: 0.39621938460001055 , 0.8447684774286344 and 0.45186676416812926

RRR mult factor is: 0.6690968125075087

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 12.9161 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 291.9985835535179; R-squared: 0.27577800105782296
	 Time required to write restart and output files:    3 minutes 51.0091 seconds 

	 Total run duration:   38 minutes 29.4857 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -300.764385351646
56 of 300, maximal objective function=-276.005, time remaining: 09:21:31
Acceptance rates [%] =98.18
Count 1305

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0062133992808567 and: 0.00010738489742471637

Albedo ice, snow and firn: 0.3953029601560588 , 0.8494209852136014 and 0.46567045163651666

RRR mult factor is: 0.6703565518117172

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.1032 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 296.3659018801939; R-squared: 0.22593665021649822
	 Time required to write restart and output files:    3 minutes 51.9044 seconds 

	 Total run duration:   38 minutes 47.3617 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -297.70760448581206
57 of 300, maximal objective function=-276.005, time remaining: 08:47:33
Acceptance rates [%] =98.21
Count 1306

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00622204525484754 and: 8.560841667747621e-05

Albedo ice, snow and firn: 0.3863388311397062 , 0.8465014965818973 and 0.4715857687074828

RRR mult factor is: 0.6691219224903245

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 15.5877 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 281.604915735666; R-squared: 0.2812054895218809
	 Time required to write restart and output files:    3 minutes 50.6415 seconds 

	 Total run duration:   38 minutes 26.3964 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -288.1221817776567
58 of 300, maximal objective function=-276.005, time remaining: 08:12:00
Acceptance rates [%] =98.25
Count 1307

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006606836731587646 and: 8.601782758230164e-05

Albedo ice, snow and firn: 0.3784756738112929 , 0.8406584042542549 and 0.47092227932962694

RRR mult factor is: 0.6657538725147517

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.263 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 294.28928681778797; R-squared: 0.2511327098711169
	 Time required to write restart and output files:    3 minutes 51.342 seconds 

	 Total run duration:   38 minutes 28.9496 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -297.1031723852978
59 of 300, maximal objective function=-276.005, time remaining: 07:36:31
Acceptance rates [%] =98.28
Count 1308

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0067196535586626 and: 7.407809613853873e-05

Albedo ice, snow and firn: 0.37242563948372537 , 0.854321091636886 and 0.479351757757885

RRR mult factor is: 0.6674794305884784

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.6454 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 280.559923856177; R-squared: 0.24508266164008233
	 Time required to write restart and output files:    3 minutes 50.1663 seconds 

	 Total run duration:   38 minutes 37.8737 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -280.532012102247
60 of 300, maximal objective function=-276.005, time remaining: 07:01:31
Acceptance rates [%] =98.31
Count 1309

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0068251700243242095 and: 8.137988307074097e-05

Albedo ice, snow and firn: 0.3743022233288793 , 0.8681805563074126 and 0.48062124754454155

RRR mult factor is: 0.6524944333248454

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.2413 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 302.83531560544276; R-squared: 0.13999903515660225
	 Time required to write restart and output files:    3 minutes 51.8549 seconds 

	 Total run duration:   38 minutes 20.7653 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -288.9932306756796
61 of 300, maximal objective function=-276.005, time remaining: 06:25:19
Acceptance rates [%] =98.33
Count 1310

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006941135119570168 and: 9.110953959328506e-05

Albedo ice, snow and firn: 0.3786319240089193 , 0.8626046385156482 and 0.4806777470125451

RRR mult factor is: 0.6553247008376939

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.5455 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 308.6863754328139; R-squared: 0.1212818080413098
	 Time required to write restart and output files:    3 minutes 52.0856 seconds 

	 Total run duration:   38 minutes 42.3185 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -289.939015710049
62 of 300, maximal objective function=-276.005, time remaining: 05:50:22
Acceptance rates [%] =98.36
Count 1311

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006969746078051052 and: 7.899870003430347e-05

Albedo ice, snow and firn: 0.37458690394502 , 0.8623402549925512 and 0.49469369997767776

RRR mult factor is: 0.6530258720995611

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.0499 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 322.62816133990606; R-squared: 0.13084296833910727
	 Time required to write restart and output files:    3 minutes 57.3195 seconds 

	 Total run duration:   39 minutes 17.8462 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.6479450761695
63 of 300, maximal objective function=-276.005, time remaining: 05:17:31
Acceptance rates [%] =98.39
Count 1312

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006810165759636123 and: 8.182089579361607e-05

Albedo ice, snow and firn: 0.3754248803588475 , 0.8594000275291314 and 0.5067428070614652

RRR mult factor is: 0.6526296934743318

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 12.4632 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 321.032986726429; R-squared: 0.13697810294180618
	 Time required to write restart and output files:    3 minutes 51.9498 seconds 

	 Total run duration:   38 minutes 42.5346 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -308.08432035807806
64 of 300, maximal objective function=-276.005, time remaining: 04:42:20
Acceptance rates [%] =98.41
Count 1313

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006535452286120224 and: 5.681867390339699e-05

Albedo ice, snow and firn: 0.36206895697542507 , 0.8705013985156703 and 0.5042961446990597

RRR mult factor is: 0.6548569976823017

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.7426 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 315.20762343919256; R-squared: 0.1537120126460789
	 Time required to write restart and output files:    3 minutes 54.1528 seconds 

	 Total run duration:   37 minutes 59.5948 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -305.7411024804376
65 of 300, maximal objective function=-276.005, time remaining: 04:04:30
Acceptance rates [%] =98.44
Count 1314

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006430109828067977 and: 4.280325878059196e-05

Albedo ice, snow and firn: 0.3580524128450779 , 0.8768441706821068 and 0.510062542766322

RRR mult factor is: 0.6560559478318061

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 15.2665 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 301.0063913085856; R-squared: 0.14301492980999556
	 Time required to write restart and output files:    3 minutes 54.9397 seconds 

	 Total run duration:   38 minutes 28.9152 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -287.8610566654483
66 of 300, maximal objective function=-276.005, time remaining: 03:28:22
Acceptance rates [%] =98.46
Count 1315

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006290167669736908 and: 4.078626209579976e-05

Albedo ice, snow and firn: 0.36093462622090117 , 0.8903615200205067 and 0.49701593333220806

RRR mult factor is: 0.6478637977810122

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.7536 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 313.22769382970614; R-squared: 0.15138605091473661
	 Time required to write restart and output files:    3 minutes 55.5004 seconds 

	 Total run duration:   38 minutes 41.7295 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -303.3445519545371
67 of 300, maximal objective function=-276.005, time remaining: 02:52:53
Acceptance rates [%] =98.48
Count 1316

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006213876413307479 and: 1.9571655654544728e-05

Albedo ice, snow and firn: 0.3745896600028821 , 0.8827039363794993 and 0.49790064905803455

RRR mult factor is: 0.6444748600864774

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 15.3782 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 317.8007202591913; R-squared: 0.1553860059392985
	 Time required to write restart and output files:    3 minutes 51.0932 seconds 

	 Total run duration:   38 minutes 47.1028 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -309.7995954800293
68 of 300, maximal objective function=-276.005, time remaining: 02:17:37
Acceptance rates [%] =98.51
Count 1317

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006025885817399292 and: 2.5255450788326834e-06

Albedo ice, snow and firn: 0.36795329676416155 , 0.8812786443129804 and 0.4943009155143037

RRR mult factor is: 0.6469408882696628

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.5564 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 311.56560876722506; R-squared: 0.17394052659908468
	 Time required to write restart and output files:    3 minutes 52.4525 seconds 

	 Total run duration:   38 minutes 12.7222 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.97050503778144
69 of 300, maximal objective function=-276.005, time remaining: 01:40:21
Acceptance rates [%] =98.53
Count 1318

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005985782188032278 and: 3.2575935846039435e-05

Albedo ice, snow and firn: 0.3666925336992349 , 0.8825733610105032 and 0.48550960896004025

RRR mult factor is: 0.6506904194524139

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.8615 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 318.90645739227597; R-squared: 0.15336300877020956
	 Time required to write restart and output files:    3 minutes 49.8629 seconds 

	 Total run duration:   38 minutes 18.8877 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -311.3755627279303
70 of 300, maximal objective function=-276.005, time remaining: 01:03:24
Acceptance rates [%] =98.55
Count 1319

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006084416992285237 and: 2.3025795598385333e-05

Albedo ice, snow and firn: 0.3677884259408964 , 0.888917532305571 and 0.48114401793279016

RRR mult factor is: 0.6532597789703443

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.8823 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 311.0103196858697; R-squared: 0.16407363450635667
	 Time required to write restart and output files:    3 minutes 48.2345 seconds 

	 Total run duration:   38 minutes 40.605 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -304.6182682630669
71 of 300, maximal objective function=-276.005, time remaining: 00:27:33
Acceptance rates [%] =98.57
Count 1320

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006160799357621021 and: 1.7623945827412075e-06

Albedo ice, snow and firn: 0.37402086011117086 , 0.896980062332578 and 0.4881248071462627

RRR mult factor is: 0.6583691919555414

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.9115 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 302.0006936268639; R-squared: 0.19108307378168174
	 Time required to write restart and output files:    3 minutes 50.2547 seconds 

	 Total run duration:   38 minutes 30.6744 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -301.37215014383304
72 of 300, maximal objective function=-276.005, time remaining: 23:51:07
Acceptance rates [%] =98.59
Count 1321

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006201808241758759 and: 1.6297223967216504e-05

Albedo ice, snow and firn: 0.3775212819944729 , 0.8959325701139907 and 0.482915132457286

RRR mult factor is: 0.6557167595886406

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.2078 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 296.417662242938; R-squared: 0.2304143876736655
	 Time required to write restart and output files:    3 minutes 54.3379 seconds 

	 Total run duration:   38 minutes 42.9225 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -299.69069213190267
73 of 300, maximal objective function=-276.005, time remaining: 23:15:15
Acceptance rates [%] =98.61
Count 1322

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005933038219291128 and: 1.9764506918630186e-05

Albedo ice, snow and firn: 0.3825560956447623 , 0.8920735240970206 and 0.4778744156521647

RRR mult factor is: 0.6513447079116514

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 6.84533 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 348.2203982559618; R-squared: 0.24752496281732747
	 Time required to write restart and output files:    3 minutes 49.6469 seconds 

	 Total run duration:   38 minutes 20.8575 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -358.1128123263338
74 of 300, maximal objective function=-276.005, time remaining: 22:38:12
Acceptance rates [%] =98.63
Count 1323

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005612234321598989 and: 6.91488404248391e-05

Albedo ice, snow and firn: 0.3766471363181015 , 0.8881274299846934 and 0.492201091343287

RRR mult factor is: 0.6534582664206293

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.5862 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 307.2233334944053; R-squared: 0.17230377481040451
	 Time required to write restart and output files:    3 minutes 49.5262 seconds 

	 Total run duration:   38 minutes 40.3901 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -303.8478183992003
75 of 300, maximal objective function=-276.005, time remaining: 22:02:05
Acceptance rates [%] =98.65
Count 1324

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005601898470777675 and: 7.052078683519056e-05

Albedo ice, snow and firn: 0.3770441591808461 , 0.8837450788845224 and 0.5007802462252984

RRR mult factor is: 0.6504173550137451

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=57.00 GB, workers=19/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.2196 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 319.09600950820624; R-squared: 0.1356035299804506
	 Time required to write restart and output files:    3 minutes 51.7616 seconds 

	 Total run duration:   38 minutes 32.943 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.7783753250803
76 of 300, maximal objective function=-276.005, time remaining: 21:25:33
Acceptance rates [%] =98.67
Count 1325

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0054895963571096355 and: 6.902975872276772e-05

Albedo ice, snow and firn: 0.36375566382684205 , 0.8844258869646937 and 0.4886166889362327

RRR mult factor is: 0.6564035260945842

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.7282 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 308.4153663193132; R-squared: 0.1616314261469504
	 Time required to write restart and output files:    3 minutes 53.0167 seconds 

	 Total run duration:   38 minutes 37.004 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -301.7715160221671
77 of 300, maximal objective function=-276.005, time remaining: 20:49:08
Acceptance rates [%] =98.68
Count 1326

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005196587367187955 and: 6.316237293316447e-05

Albedo ice, snow and firn: 0.35560394876930546 , 0.8843031884572085 and 0.4804838836707479

RRR mult factor is: 0.6567827360675659

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.266 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 316.60776162364954; R-squared: 0.15805937868367548
	 Time required to write restart and output files:    3 minutes 53.9898 seconds 

	 Total run duration:   38 minutes 37.7817 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -311.86444851241606
78 of 300, maximal objective function=-276.005, time remaining: 20:12:43
Acceptance rates [%] =98.7
Count 1327

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005258039478749274 and: 5.7478382367812943e-05

Albedo ice, snow and firn: 0.3637824952160631 , 0.8845602014428715 and 0.47623160132087855

RRR mult factor is: 0.654032599703349

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 11.1554 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 376.43980721205395; R-squared: 0.17622246980771394
	 Time required to write restart and output files:    3 minutes 52.2906 seconds 

	 Total run duration:   38 minutes 11.3006 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -379.52559649874803
79 of 300, maximal objective function=-276.005, time remaining: 19:35:01
Acceptance rates [%] =98.72
Count 1328

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005399674868392699 and: 9.157320389795683e-05

Albedo ice, snow and firn: 0.38286371395008567 , 0.8994175168634021 and 0.4732886718458724

RRR mult factor is: 0.6547994127287896

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 21.3458 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 299.714171062568; R-squared: 0.21090331609729984
	 Time required to write restart and output files:    3 minutes 52.828 seconds 

	 Total run duration:   38 minutes 38.5537 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -300.4969125851814
80 of 300, maximal objective function=-276.005, time remaining: 18:58:32
Acceptance rates [%] =98.73
Count 1329

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005316608724475804 and: 9.234604850814052e-05

Albedo ice, snow and firn: 0.39497985172209277 , 0.8966786695214275 and 0.47022178004213316

RRR mult factor is: 0.665113988384311

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.1502 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 306.83751292128915; R-squared: 0.1904581216991311
	 Time required to write restart and output files:    3 minutes 51.8678 seconds 

	 Total run duration:   38 minutes 12.0182 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -308.70546170559163
81 of 300, maximal objective function=-276.005, time remaining: 18:20:49
Acceptance rates [%] =98.75
Count 1330

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005558170567921828 and: 6.692189044064333e-05

Albedo ice, snow and firn: 0.3939039684132873 , 0.8980684124360826 and 0.48571563387170025

RRR mult factor is: 0.6681746045741674

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.1396 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 279.6559828833696; R-squared: 0.20412532774080372
	 Time required to write restart and output files:    3 minutes 54.8739 seconds 

	 Total run duration:   38 minutes 20.3911 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -278.34550123575696
82 of 300, maximal objective function=-276.005, time remaining: 17:43:28
Acceptance rates [%] =98.77
Count 1331

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005823204993952661 and: 7.404830327352543e-05

Albedo ice, snow and firn: 0.3973423098526255 , 0.8985682275460466 and 0.4834369876163361

RRR mult factor is: 0.6710754190736374

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.8242 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 251.86684423322177; R-squared: 0.2985031728072685
	 Time required to write restart and output files:    3 minutes 54.6432 seconds 

	 Total run duration:   39 minutes 33.3216 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -257.9286412310112
83 of 300, maximal objective function=-257.929, time remaining: 17:09:12
Acceptance rates [%] =98.78
Count 1332

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005652082900360981 and: 8.867966866511291e-05

Albedo ice, snow and firn: 0.3909472649116679 , 0.8884477850061 and 0.49187608827721346

RRR mult factor is: 0.6763769158312682

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 23.2723 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 273.87047701765187; R-squared: 0.31760803783379565
	 Time required to write restart and output files:    3 minutes 54.7064 seconds 

	 Total run duration:   38 minutes 46.2523 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -286.48392513296415
84 of 300, maximal objective function=-257.929, time remaining: 16:32:50
Acceptance rates [%] =98.8
Count 1333

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00591717526052659 and: 8.350113234792727e-05

Albedo ice, snow and firn: 0.394307027239894 , 0.8927861266485593 and 0.4885197035906453

RRR mult factor is: 0.6730124970634996

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 15.1923 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 291.28399390449357; R-squared: 0.25110257135948044
	 Time required to write restart and output files:    3 minutes 50.0317 seconds 

	 Total run duration:   38 minutes 28.9795 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -296.7401193814191
85 of 300, maximal objective function=-257.929, time remaining: 15:55:42
Acceptance rates [%] =98.81
Count 1334

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005795821221830877 and: 7.961820784578314e-05

Albedo ice, snow and firn: 0.3838626480168109 , 0.8873742410369876 and 0.4843904355249872

RRR mult factor is: 0.6738704300260991

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 10.9837 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 331.45002464694994; R-squared: 0.3010544924926607
	 Time required to write restart and output files:    3 minutes 55.0711 seconds 

	 Total run duration:   38 minutes 2.74348 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -342.24555825858505
86 of 300, maximal objective function=-257.929, time remaining: 15:17:28
Acceptance rates [%] =98.82
Count 1335

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005878593169848885 and: 8.146831519032927e-05

Albedo ice, snow and firn: 0.3871439046229924 , 0.8928110537867633 and 0.47805063154026933

RRR mult factor is: 0.668564432984627

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 25.3256 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 294.1454566008268; R-squared: 0.32272595926287106
	 Time required to write restart and output files:    3 minutes 58.373 seconds 

	 Total run duration:   38 minutes 27.2632 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -306.74624364333664
87 of 300, maximal objective function=-257.929, time remaining: 14:40:13
Acceptance rates [%] =98.84
Count 1336

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005816492624353545 and: 0.0001022451546919714

Albedo ice, snow and firn: 0.38912047609689626 , 0.8980268514592694 and 0.4911398418143704

RRR mult factor is: 0.6701565081227333

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 52.978 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 290.71571778369935; R-squared: 0.22247843706882428
	 Time required to write restart and output files:    3 minutes 53.1708 seconds 

	 Total run duration:   43 minutes 21.0238 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -290.9370775779357
88 of 300, maximal objective function=-257.929, time remaining: 14:14:33
Acceptance rates [%] =98.85
Count 1337

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005986379221582683 and: 0.00012588769977055155

Albedo ice, snow and firn: 0.3823498823112882 , 0.8798572040296191 and 0.49044935884891605

RRR mult factor is: 0.6737945978887426

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   18 minutes 25.8002 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 310.62319757897; R-squared: 0.1776141248786851
	 Time required to write restart and output files:    3 minutes 54.9332 seconds 

	 Total run duration:   43 minutes 40.6518 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -309.4755959251491
89 of 300, maximal objective function=-257.929, time remaining: 13:49:14
Acceptance rates [%] =98.86
Count 1338

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006198013859471335 and: 0.00010285519816037776

Albedo ice, snow and firn: 0.3952300760618392 , 0.8672433700705756 and 0.49208967106058465

RRR mult factor is: 0.6712129457613432

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   21 minutes 1.15305 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 314.5119138460528; R-squared: 0.16404023424162759
	 Time required to write restart and output files:    3 minutes 51.7823 seconds 

	 Total run duration:   45 minutes 52.4584 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -310.17422640062495
90 of 300, maximal objective function=-257.929, time remaining: 13:28:35
Acceptance rates [%] =98.88
Count 1339

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006286885340405586 and: 9.119279801089862e-05

Albedo ice, snow and firn: 0.3738564971457137 , 0.8731870502106278 and 0.5038665720980606

RRR mult factor is: 0.673329836618021

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   15 minutes 49.324 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 312.0119322625079; R-squared: 0.18426259872837777
	 Time required to write restart and output files:    3 minutes 55.2275 seconds 

	 Total run duration:   40 minutes 40.6625 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -311.98080440010284
91 of 300, maximal objective function=-257.929, time remaining: 12:55:38
Acceptance rates [%] =98.89
Count 1340

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006318330472878185 and: 0.00012156028607233235

Albedo ice, snow and firn: 0.38281576237316906 , 0.8730308087779949 and 0.5052067496487923

RRR mult factor is: 0.6798075259543608

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   18 minutes 59.3133 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 317.47510760862326; R-squared: 0.15085225443930686
	 Time required to write restart and output files:    3 minutes 53.8569 seconds 

	 Total run duration:   44 minutes 24.5082 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -310.5815423897984
92 of 300, maximal objective function=-257.929, time remaining: 12:30:48
Acceptance rates [%] =98.9
Count 1341

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006036916875716868 and: 0.00013148118432992873

Albedo ice, snow and firn: 0.3854822211700706 , 0.8729120594489653 and 0.5103236540806976

RRR mult factor is: 0.6783361438902777

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 21.3201 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 320.0932522015312; R-squared: 0.1516840074429035
	 Time required to write restart and output files:    3 minutes 50.3882 seconds 

	 Total run duration:   38 minutes 35.9217 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -313.79394320382914
93 of 300, maximal objective function=-257.929, time remaining: 11:52:50
Acceptance rates [%] =98.91
Count 1342

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006041074900929644 and: 0.00011486871096677508

Albedo ice, snow and firn: 0.39393624550557593 , 0.8902402015788079 and 0.5133341956119355

RRR mult factor is: 0.678039505500992

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.6825 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 317.29798798901345; R-squared: 0.15507607348935473
	 Time required to write restart and output files:    3 minutes 51.4169 seconds 

	 Total run duration:   38 minutes 32.5519 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -311.56878916591927
94 of 300, maximal objective function=-257.929, time remaining: 11:14:44
Acceptance rates [%] =98.92
Count 1343

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006118606055947047 and: 0.00014526932929043157

Albedo ice, snow and firn: 0.3930076098477471 , 0.8997622167015569 and 0.5035984527333316

RRR mult factor is: 0.6755653529706962

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 13.1909 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 305.1952081946128; R-squared: 0.18978264028600275
	 Time required to write restart and output files:    3 minutes 53.4452 seconds 

	 Total run duration:   39 minutes 33.6199 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -303.0403037934495
95 of 300, maximal objective function=-257.929, time remaining: 10:38:47
Acceptance rates [%] =98.94
Count 1344

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006026088288389357 and: 0.0001520092868593129

Albedo ice, snow and firn: 0.38708283372023145 , 0.8893090303835005 and 0.5024355403526501

RRR mult factor is: 0.6737520461719205

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 23.4694 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 323.9992428011558; R-squared: 0.14595526453008748
	 Time required to write restart and output files:    3 minutes 54.2461 seconds 

	 Total run duration:   38 minutes 45.7903 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -317.1471771484434
96 of 300, maximal objective function=-257.929, time remaining: 10:01:06
Acceptance rates [%] =98.95
Count 1345

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0060416989366579455 and: 0.00015081312911889382

Albedo ice, snow and firn: 0.37468273157613347 , 0.8755027861798613 and 0.4962960497772771

RRR mult factor is: 0.678063374270643

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.9646 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 376.43445592519095; R-squared: 0.1704680557975251
	 Time required to write restart and output files:    3 minutes 55.488 seconds 

	 Total run duration:   39 minutes 17.6067 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -374.5767490084382
97 of 300, maximal objective function=-257.929, time remaining: 09:24:28
Acceptance rates [%] =98.96
Count 1346

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005857554724623278 and: 0.0001528520268248732

Albedo ice, snow and firn: 0.37642193207129165 , 0.8777718784905479 and 0.4915090883225095

RRR mult factor is: 0.6727145964921291

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 55.3763 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 379.27431668912436; R-squared: 0.16281037858319894
	 Time required to write restart and output files:    3 minutes 55.0446 seconds 

	 Total run duration:   39 minutes 15.5305 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -377.3825065350004
98 of 300, maximal objective function=-257.929, time remaining: 08:47:44
Acceptance rates [%] =98.97
Count 1347

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00608922292188118 and: 0.00015817517834170497

Albedo ice, snow and firn: 0.3620535223154454 , 0.8676013144910966 and 0.47367116849442975

RRR mult factor is: 0.677797912427979

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 28.2935 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 346.16000583387574; R-squared: 0.17335111384701218
	 Time required to write restart and output files:    3 minutes 57.2558 seconds 

	 Total run duration:   38 minutes 53.9902 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -342.306007653475
99 of 300, maximal objective function=-257.929, time remaining: 08:10:13
Acceptance rates [%] =98.98
Count 1348

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006065270009640375 and: 0.00016773749065639683

Albedo ice, snow and firn: 0.3667158032349226 , 0.8830833660623965 and 0.48347631441383426

RRR mult factor is: 0.6725951682194551

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.0226 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 316.5329453462442; R-squared: 0.1474741744656035
	 Time required to write restart and output files:    3 minutes 55.6203 seconds 

	 Total run duration:   38 minutes 57.5834 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -308.0634520613463
100 of 300, maximal objective function=-257.929, time remaining: 07:32:48
Acceptance rates [%] =98.99
Count 1349

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005951307279880364 and: 0.00016726819412731303

Albedo ice, snow and firn: 0.382427783151913 , 0.8865797555937434 and 0.47112582842290435

RRR mult factor is: 0.667717291035322

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 21.4153 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 315.8924380428334; R-squared: 0.1528095748870233
	 Time required to write restart and output files:    3 minutes 54.5612 seconds 

	 Total run duration:   38 minutes 45.1366 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -309.0213651712727
101 of 300, maximal objective function=-257.929, time remaining: 06:54:56
Acceptance rates [%] =99.
Count 1350

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006083045149560029 and: 0.00013986992471230191

Albedo ice, snow and firn: 0.385150510928982 , 0.896278587314752 and 0.4671769876519065

RRR mult factor is: 0.6659886826405048

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 32.0931 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 316.48422568108043; R-squared: 0.147488317528473
	 Time required to write restart and output files:    3 minutes 54.304 seconds 

	 Total run duration:   38 minutes 51.5502 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -308.21068490791805
102 of 300, maximal objective function=-257.929, time remaining: 06:17:16
Acceptance rates [%] =99.01
Count 1351

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006003533201977045 and: 0.0001143449211621952

Albedo ice, snow and firn: 0.38221129046780866 , 0.8792115153514716 and 0.49349445238576206

RRR mult factor is: 0.6689257203423467

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 25.2389 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 336.4600839630867; R-squared: 0.17904572284546266
	 Time required to write restart and output files:    3 minutes 57.8814 seconds 

	 Total run duration:   38 minutes 58.3287 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -336.7653739329599
103 of 300, maximal objective function=-257.929, time remaining: 05:39:48
Acceptance rates [%] =99.02
Count 1352

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00593633909630335 and: 0.00011104022167336896

Albedo ice, snow and firn: 0.3826796267069452 , 0.8638682758098666 and 0.4894956080361173

RRR mult factor is: 0.6722106154727602

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 27.0809 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 315.83553977010905; R-squared: 0.1702404030272851
	 Time required to write restart and output files:    3 minutes 55.9558 seconds 

	 Total run duration:   38 minutes 57.7992 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -313.3651834892098
104 of 300, maximal objective function=-257.929, time remaining: 05:02:16
Acceptance rates [%] =99.03
Count 1353

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005794219578728099 and: 0.00013204202591542768

Albedo ice, snow and firn: 0.3871856057602066 , 0.8721498359981482 and 0.5044765489553289

RRR mult factor is: 0.6795438479107013

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 29.34 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 300.156224882514; R-squared: 0.19342148404177295
	 Time required to write restart and output files:    3 minutes 56.2412 seconds 

	 Total run duration:   39 minutes 6.24195 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -298.7787826310611
105 of 300, maximal objective function=-257.929, time remaining: 04:24:59
Acceptance rates [%] =99.04
Count 1354

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0058592925540496 and: 0.00010268964819685966

Albedo ice, snow and firn: 0.39470384021619837 , 0.8777616824600809 and 0.5176631251486926

RRR mult factor is: 0.6723717843406087

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 11.7352 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 302.68687125151297; R-squared: 0.20695301301285204
	 Time required to write restart and output files:    3 minutes 59.1302 seconds 

	 Total run duration:   38 minutes 46.207 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -304.71153392191167
106 of 300, maximal objective function=-257.929, time remaining: 03:47:03
Acceptance rates [%] =99.05
Count 1355

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0057759721198332795 and: 8.469441563035396e-05

Albedo ice, snow and firn: 0.3914811901934545 , 0.875285839223394 and 0.5111135666312963

RRR mult factor is: 0.6687336024972153

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.3486 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 347.57185974215116; R-squared: 0.25943271765273607
	 Time required to write restart and output files:    3 minutes 51.2872 seconds 

	 Total run duration:   38 minutes 38.7875 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -358.0016815126883
107 of 300, maximal objective function=-257.929, time remaining: 03:08:53
Acceptance rates [%] =98.11
Count 1356

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005840690639172297 and: 0.00011050903901492921

Albedo ice, snow and firn: 0.37145324462711593 , 0.8796940679320041 and 0.5220072163493065

RRR mult factor is: 0.6716926873723357

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 29.4263 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 309.37923533876545; R-squared: 0.1782878958524282
	 Time required to write restart and output files:    3 minutes 57.8119 seconds 

	 Total run duration:   39 minutes 28.3683 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -308.74366415368644
108 of 300, maximal objective function=-257.929, time remaining: 02:32:10
Acceptance rates [%] =98.13
Count 1357

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005899840357192353 and: 8.425619837461254e-05

Albedo ice, snow and firn: 0.3808376418263486 , 0.8827011241716685 and 0.5201224460462268

RRR mult factor is: 0.6692927306255921

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.2937 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 309.0520240452916; R-squared: 0.24286715803754053
	 Time required to write restart and output files:    3 minutes 54.8053 seconds 

	 Total run duration:   38 minutes 33.4683 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -310.62651524495806
109 of 300, maximal objective function=-257.929, time remaining: 01:53:48
Acceptance rates [%] =98.15
Count 1358

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005711153938359123 and: 9.537072417169962e-05

Albedo ice, snow and firn: 0.36770144557857065 , 0.8822054805904899 and 0.5027290546659914

RRR mult factor is: 0.6708078594298421

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.5421 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 352.4882723762493; R-squared: 0.24476323721028223
	 Time required to write restart and output files:    3 minutes 52.4603 seconds 

	 Total run duration:   37 minutes 54.1682 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -361.755060575904
110 of 300, maximal objective function=-257.929, time remaining: 01:14:20
Acceptance rates [%] =97.25
Count 1359

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006147081274453756 and: 8.384881466239101e-05

Albedo ice, snow and firn: 0.3833234939522311 , 0.8788946445959597 and 0.5311463310575658

RRR mult factor is: 0.6697195149417535

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 24.6444 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 296.6878826651633; R-squared: 0.25178890103603274
	 Time required to write restart and output files:    3 minutes 53.5529 seconds 

	 Total run duration:   38 minutes 51.0973 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -302.9006731070116
111 of 300, maximal objective function=-257.929, time remaining: 00:36:28
Acceptance rates [%] =97.27
Count 1360

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006151723593274425 and: 6.855763102626908e-05

Albedo ice, snow and firn: 0.38340045080944296 , 0.8717965744570808 and 0.5281546891468609

RRR mult factor is: 0.667564069968409

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.6391 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 289.88059827935916; R-squared: 0.26537685220225404
	 Time required to write restart and output files:    3 minutes 56.6442 seconds 

	 Total run duration:   38 minutes 57.8915 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -297.0761536443732
112 of 300, maximal objective function=-257.929, time remaining: 23:58:47
Acceptance rates [%] =97.3
Count 1361

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006140350481738535 and: 7.13009040329038e-05

Albedo ice, snow and firn: 0.3857394721224895 , 0.8728648884183531 and 0.5535195274078998

RRR mult factor is: 0.6703157830641678

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 43.1991 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 282.5409291472912; R-squared: 0.24124250716581597
	 Time required to write restart and output files:    3 minutes 53.2099 seconds 

	 Total run duration:   39 minutes 9.58139 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -284.5125259593531
113 of 300, maximal objective function=-257.929, time remaining: 23:21:24
Acceptance rates [%] =97.32
Count 1362

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006375936257684 and: 9.90242501934428e-05

Albedo ice, snow and firn: 0.3946244749700377 , 0.8889912941168508 and 0.560188658137276

RRR mult factor is: 0.6797249969395358

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 26.6197 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 265.0736371288529; R-squared: 0.24542506101557318
	 Time required to write restart and output files:    3 minutes 55.3217 seconds 

	 Total run duration:   38 minutes 53.9128 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -264.2067039677767
114 of 300, maximal objective function=-257.929, time remaining: 22:43:33
Acceptance rates [%] =97.35
Count 1363

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006616932110471738 and: 9.149028766545529e-05

Albedo ice, snow and firn: 0.3861583891351926 , 0.8928998839848249 and 0.5767492364223435

RRR mult factor is: 0.6749453695733564

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 32.1334 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 240.19938117343975; R-squared: 0.3491036248732264
	 Time required to write restart and output files:    3 minutes 53.5866 seconds 

	 Total run duration:   38 minutes 58.8385 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -247.36024642699866
115 of 300, maximal objective function=-247.36, time remaining: 22:05:49
Acceptance rates [%] =97.37
Count 1364

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006815708511037619 and: 8.508110072877742e-05

Albedo ice, snow and firn: 0.387714028192015 , 0.8849444044473166 and 0.5747085237392043

RRR mult factor is: 0.6786136154778546

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 53.8553 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 271.5935849912716; R-squared: 0.2362217965910395
	 Time required to write restart and output files:    3 minutes 56.2739 seconds 

	 Total run duration:   39 minutes 14.9816 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -269.957910294563
116 of 300, maximal objective function=-247.36, time remaining: 21:28:29
Acceptance rates [%] =97.39
Count 1365

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006988118788244519 and: 7.772967808477697e-05

Albedo ice, snow and firn: 0.3996592464548625 , 0.8815566051239715 and 0.5724418412298276

RRR mult factor is: 0.6771260956015718

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 23.7861 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 291.59839958994047; R-squared: 0.2361569674425363
	 Time required to write restart and output files:    3 minutes 52.264 seconds 

	 Total run duration:   38 minutes 40.7314 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -291.6411480671982
117 of 300, maximal objective function=-247.36, time remaining: 20:50:14
Acceptance rates [%] =97.41
Count 1366

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006815164895194183 and: 0.00010156765383791656

Albedo ice, snow and firn: 0.3991582699845544 , 0.8766289884296562 and 0.5735113651233921

RRR mult factor is: 0.6751412093014175

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 51.0349 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 291.4379431720202; R-squared: 0.24810592309111057
	 Time required to write restart and output files:    3 minutes 54.1013 seconds 

	 Total run duration:   39 minutes 21.2508 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -293.6182724691561
118 of 300, maximal objective function=-247.36, time remaining: 20:13:01
Acceptance rates [%] =97.44
Count 1367

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006980075920940045 and: 0.00011430563892453055

Albedo ice, snow and firn: 0.3916090187538527 , 0.8704406894179624 and 0.5454154788288793

RRR mult factor is: 0.6727871809848951

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=177.00 GB, workers=59/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 27.0326 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 277.8646005859675; R-squared: 0.2921794323876151
	 Time required to write restart and output files:    3 minutes 49.2536 seconds 

	 Total run duration:   38 minutes 39.545 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -283.7194910239029
119 of 300, maximal objective function=-247.36, time remaining: 19:34:42
Acceptance rates [%] =97.46
Count 1368

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006789682194249911 and: 0.00013599371433565584

Albedo ice, snow and firn: 0.3813725552561015 , 0.8752807370394194 and 0.5390482923796516

RRR mult factor is: 0.6711123274266942

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 23.6256 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 319.9098035581988; R-squared: 0.16050244644012146
	 Time required to write restart and output files:    3 minutes 49.2789 seconds 

	 Total run duration:   38 minutes 42.5283 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -313.2458773878738
120 of 300, maximal objective function=-247.36, time remaining: 18:56:28
Acceptance rates [%] =97.48
Count 1369

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0069514684254613724 and: 0.00011875517054141797

Albedo ice, snow and firn: 0.38612972525573 , 0.8627172035977514 and 0.554636473357096

RRR mult factor is: 0.6788810015860812

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 58.4858 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 312.83131008019564; R-squared: 0.16116857827184985
	 Time required to write restart and output files:    3 minutes 54.1303 seconds 

	 Total run duration:   39 minutes 18.1209 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -304.9889568351746
121 of 300, maximal objective function=-247.36, time remaining: 18:19:05
Acceptance rates [%] =97.5
Count 1370

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00653201491641743 and: 0.00011019952263230831

Albedo ice, snow and firn: 0.3823886824599985 , 0.8620258544760825 and 0.5532217589165725

RRR mult factor is: 0.6734598069609377

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.6022 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 319.5601780770648; R-squared: 0.15356437303876885
	 Time required to write restart and output files:    3 minutes 53.7203 seconds 

	 Total run duration:   38 minutes 48.8345 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -312.6093347578917
122 of 300, maximal objective function=-247.36, time remaining: 17:40:58
Acceptance rates [%] =97.52
Count 1371

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006492572867923696 and: 0.0001063999886218296

Albedo ice, snow and firn: 0.37575661269315563 , 0.8721249941157502 and 0.575026759028575

RRR mult factor is: 0.6781255222875461

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   18 minutes 57.9185 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 298.56826869269923; R-squared: 0.14386033628234993
	 Time required to write restart and output files:    3 minutes 52.0996 seconds 

	 Total run duration:   44 minutes 26.9765 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -285.94180886709233
123 of 300, maximal objective function=-247.36, time remaining: 17:10:50
Acceptance rates [%] =97.54
Count 1372

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006527417221531928 and: 8.707327916585589e-05

Albedo ice, snow and firn: 0.3738967102866717 , 0.8738854258393649 and 0.567615875448693

RRR mult factor is: 0.6755029529595503

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=57.00 GB, workers=19/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.1514 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 314.8473648958748; R-squared: 0.15661608219580997
	 Time required to write restart and output files:    3 minutes 47.6804 seconds 

	 Total run duration:   38 minutes 30.0198 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -308.12084339154507
124 of 300, maximal objective function=-247.36, time remaining: 16:32:09
Acceptance rates [%] =96.75
Count 1373

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006205171271513834 and: 7.676962131486124e-05

Albedo ice, snow and firn: 0.3780646540492503 , 0.8710538896786733 and 0.5709180474439218

RRR mult factor is: 0.6791241098708674

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   19 minutes 30.6293 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 298.3625368203055; R-squared: 0.15051783197017535
	 Time required to write restart and output files:    3 minutes 51.9385 seconds 

	 Total run duration:   44 minutes 52.6851 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -288.54764040875034
125 of 300, maximal objective function=-247.36, time remaining: 16:02:16
Acceptance rates [%] =96.77
Count 1374

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006353558541527313 and: 5.633953597322388e-05

Albedo ice, snow and firn: 0.3893584505301642 , 0.8684892916378837 and 0.5708954501416337

RRR mult factor is: 0.6795007726524595

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   16 minutes 35.8306 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 287.2415786958676; R-squared: 0.17253790278459805
	 Time required to write restart and output files:    3 minutes 52.0911 seconds 

	 Total run duration:   41 minutes 56.2181 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -278.88103705865706
126 of 300, maximal objective function=-247.36, time remaining: 15:28:08
Acceptance rates [%] =96.8
Count 1375

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006094427679852514 and: 7.102226334585677e-05

Albedo ice, snow and firn: 0.3733209332269713 , 0.8845181258740547 and 0.578281390807515

RRR mult factor is: 0.675747085678143

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 2.71963 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 246.49569661512737; R-squared: 0.1322315402036534
	 Time required to write restart and output files:    3 minutes 49.9632 seconds 

	 Total run duration:   42 minutes 17.913 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -226.68715172093962
127 of 300, maximal objective function=-226.687, time remaining: 14:54:23
Acceptance rates [%] =96.83
Count 1376

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006260050932499938 and: 7.307068241907993e-05

Albedo ice, snow and firn: 0.3815619773319349 , 0.8691577268548929 and 0.5803984565600709

RRR mult factor is: 0.6708767825205532

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 28.045 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 256.69097729343906; R-squared: 0.1283356447360128
	 Time required to write restart and output files:    3 minutes 51.9516 seconds 

	 Total run duration:   42 minutes 50.0031 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -236.92355324176518
128 of 300, maximal objective function=-226.687, time remaining: 14:21:12
Acceptance rates [%] =96.85
Count 1377

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005907469566315442 and: 6.857255398677473e-05

Albedo ice, snow and firn: 0.3770960363647057 , 0.8559038209755386 and 0.5749604229367286

RRR mult factor is: 0.666511691840013

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 2.18304 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 288.02297169497086; R-squared: 0.17145973609366552
	 Time required to write restart and output files:    3 minutes 51.1853 seconds 

	 Total run duration:   42 minutes 27.708 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -280.3922362091479
129 of 300, maximal objective function=-226.687, time remaining: 13:47:23
Acceptance rates [%] =96.88
Count 1378

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0058476297744187115 and: 7.21421672993931e-05

Albedo ice, snow and firn: 0.38335214287483316 , 0.8568095795563427 and 0.563582615956295

RRR mult factor is: 0.6699876949766282

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   16 minutes 53.202 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 272.50561819322667; R-squared: 0.19740642074547332
	 Time required to write restart and output files:    3 minutes 51.9792 seconds 

	 Total run duration:   42 minutes 22.1517 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -267.52445837830845
130 of 300, maximal objective function=-226.687, time remaining: 13:13:19
Acceptance rates [%] =96.9
Count 1379

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00597839604355729 and: 7.939346874324182e-05

Albedo ice, snow and firn: 0.37596152758695306 , 0.8466630190673322 and 0.5591479802108539

RRR mult factor is: 0.6678104685684545

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   16 minutes 54.245 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 297.2577321714648; R-squared: 0.18278871615333298
	 Time required to write restart and output files:    3 minutes 49.1625 seconds 

	 Total run duration:   42 minutes 17.5728 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -293.41258597679445
131 of 300, maximal objective function=-226.687, time remaining: 12:39:01
Acceptance rates [%] =96.15
Count 1380

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00571371386288571 and: 0.00010294690019776305

Albedo ice, snow and firn: 0.3963771142680117 , 0.8732932189700819 and 0.5595622042065896

RRR mult factor is: 0.6708017927999914

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 26.618 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 224.54590103142542; R-squared: 0.2506278829762088
	 Time required to write restart and output files:    3 minutes 51.4187 seconds 

	 Total run duration:   42 minutes 45.9739 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -222.30887519348943
132 of 300, maximal objective function=-222.309, time remaining: 12:05:12
Acceptance rates [%] =96.18
Count 1381

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005720397095293102 and: 0.0001270103656996015

Albedo ice, snow and firn: 0.37803393877563307 , 0.882174842050863 and 0.5669635633573605

RRR mult factor is: 0.6732434843234875

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 20.5349 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 232.11338023776077; R-squared: 0.21565663729252202
	 Time required to write restart and output files:    3 minutes 51.2218 seconds 

	 Total run duration:   42 minutes 19.1323 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -227.09762160752473
133 of 300, maximal objective function=-222.309, time remaining: 11:30:42
Acceptance rates [%] =96.21
Count 1382

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0058251101648217965 and: 0.00012265155573894986

Albedo ice, snow and firn: 0.37872190692700564 , 0.8615867374757619 and 0.5660159988030823

RRR mult factor is: 0.6792590684668953

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 18.5497 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 261.76139756382133; R-squared: 0.2353208139329689
	 Time required to write restart and output files:    3 minutes 49.0367 seconds 

	 Total run duration:   42 minutes 24.766 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -259.8119797235686
134 of 300, maximal objective function=-222.309, time remaining: 10:56:12
Acceptance rates [%] =96.24
Count 1383

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005997812526318932 and: 0.00010194237164117296

Albedo ice, snow and firn: 0.38305296763282015 , 0.8662680974406188 and 0.5707046317742388

RRR mult factor is: 0.6798556133200078

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 15.0562 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 252.98304434537673; R-squared: 0.21753661786799783
	 Time required to write restart and output files:    3 minutes 50.8235 seconds 

	 Total run duration:   42 minutes 31.8562 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -247.7645955799103
135 of 300, maximal objective function=-222.309, time remaining: 10:21:43
Acceptance rates [%] =96.27
Count 1384

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005948963118645333 and: 0.00011621182028174386

Albedo ice, snow and firn: 0.3839871212854384 , 0.8764712937314897 and 0.5688650191954276

RRR mult factor is: 0.6783730358948348

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 29.6032 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 222.50936483493334; R-squared: 0.26229061025092426
	 Time required to write restart and output files:    3 minutes 51.0257 seconds 

	 Total run duration:   42 minutes 41.5536 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -219.87884104614176
136 of 300, maximal objective function=-219.879, time remaining: 09:47:19
Acceptance rates [%] =96.3
Count 1385

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005863396998390125 and: 0.0001470655917810602

Albedo ice, snow and firn: 0.3854110475898655 , 0.8846940942952853 and 0.5502969618167942

RRR mult factor is: 0.6744953759540607

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.6641 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 228.27500417773678; R-squared: 0.27006608539223664
	 Time required to write restart and output files:    3 minutes 48.462 seconds 

	 Total run duration:   38 minutes 45.744 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -227.3691576590846
137 of 300, maximal objective function=-219.879, time remaining: 09:08:10
Acceptance rates [%] =96.32
Count 1386

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005758546278119761 and: 0.00015597881921437958

Albedo ice, snow and firn: 0.3806280984587723 , 0.8792984064069534 and 0.5566532628318077

RRR mult factor is: 0.6719032542972229

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.2066 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 233.39210614386187; R-squared: 0.2910226986334498
	 Time required to write restart and output files:    3 minutes 50.0071 seconds 

	 Total run duration:   38 minutes 25.6337 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -235.35994622682819
138 of 300, maximal objective function=-219.879, time remaining: 08:28:39
Acceptance rates [%] =96.35
Count 1387

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005975493098758053 and: 0.000145047366885081

Albedo ice, snow and firn: 0.39352274454751285 , 0.8735309118243048 and 0.549793463976181

RRR mult factor is: 0.6744590391725342

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 30.9546 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 243.01171931874984; R-squared: 0.2566588121453672
	 Time required to write restart and output files:    3 minutes 50.241 seconds 

	 Total run duration:   38 minutes 48.2834 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -241.4587461097165
139 of 300, maximal objective function=-219.879, time remaining: 07:49:34
Acceptance rates [%] =96.38
Count 1388

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006355325293653635 and: 0.00014912387315581732

Albedo ice, snow and firn: 0.39423027427117474 , 0.8618908055130832 and 0.5665976561719728

RRR mult factor is: 0.6795926688804077

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 29.3587 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 251.4517663350697; R-squared: 0.3261014379077338
	 Time required to write restart and output files:    3 minutes 51.9942 seconds 

	 Total run duration:   38 minutes 55.3774 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -256.51717896338755
140 of 300, maximal objective function=-219.879, time remaining: 07:10:38
Acceptance rates [%] =95.68
Count 1389

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005812491275991796 and: 0.00015738810221615167

Albedo ice, snow and firn: 0.38614310216909875 , 0.8838534263376513 and 0.5393811903131976

RRR mult factor is: 0.6717918468880707

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 23.2279 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 227.75681222779824; R-squared: 0.24001305955719274
	 Time required to write restart and output files:    3 minutes 49.1144 seconds 

	 Total run duration:   38 minutes 28.3651 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -224.0708217258226
141 of 300, maximal objective function=-219.879, time remaining: 06:31:12
Acceptance rates [%] =95.71
Count 1390

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005875547816362734 and: 0.00016751185872030232

Albedo ice, snow and firn: 0.39821040338811686 , 0.8939101689740651 and 0.5554226764217657

RRR mult factor is: 0.6690976669016413

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 39.5299 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 242.16079527746047; R-squared: 0.15152033033108742
	 Time required to write restart and output files:    3 minutes 49.7882 seconds 

	 Total run duration:   38 minutes 56.6857 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -226.03114980481365
142 of 300, maximal objective function=-219.879, time remaining: 05:52:17
Acceptance rates [%] =95.74
Count 1391

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006322650691014966 and: 0.00014662811491004949

Albedo ice, snow and firn: 0.39830843115564235 , 0.8980832903339386 and 0.5625894091894774

RRR mult factor is: 0.6743891910239469

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 53.0363 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 204.6501512398289; R-squared: 0.21534859548225987
	 Time required to write restart and output files:    3 minutes 49.096 seconds 

	 Total run duration:   39 minutes 3.35256 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -191.88510654563382
143 of 300, maximal objective function=-191.885, time remaining: 05:13:30
Acceptance rates [%] =95.77
Count 1392

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006068778249118055 and: 0.00016601595431120302

Albedo ice, snow and firn: 0.39988917917656247 , 0.8959921940830262 and 0.560289366053146

RRR mult factor is: 0.6666524674000224

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 52.6133 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 212.34854139755407; R-squared: 0.14746530108171632
	 Time required to write restart and output files:    3 minutes 47.0979 seconds 

	 Total run duration:   38 minutes 50.5802 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -191.3215606137211
144 of 300, maximal objective function=-191.322, time remaining: 04:34:29
Acceptance rates [%] =95.8
Count 1393

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006250443273042169 and: 0.00015523747929796188

Albedo ice, snow and firn: 0.3960662617518516 , 0.898574045611733 and 0.5739607562113989

RRR mult factor is: 0.6674358902909845

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 0.316984 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 215.35482333444438; R-squared: 0.13831794319012916
	 Time required to write restart and output files:    3 minutes 49.5257 seconds 

	 Total run duration:   39 minutes 15.4428 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -192.97249395796106
145 of 300, maximal objective function=-191.322, time remaining: 03:55:54
Acceptance rates [%] =95.83
Count 1394

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006170954371332259 and: 0.00016078286370815268

Albedo ice, snow and firn: 0.38336792758303345 , 0.887666677607321 and 0.580131817336786

RRR mult factor is: 0.6656110588398539

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 49.8084 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 228.91677113282012; R-squared: 0.11059574594355151
	 Time required to write restart and output files:    3 minutes 49.0257 seconds 

	 Total run duration:   39 minutes 17.5858 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -202.82818394360834
146 of 300, maximal objective function=-191.322, time remaining: 03:17:21
Acceptance rates [%] =95.86
Count 1395

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006286942490926974 and: 0.0001330341554951676

Albedo ice, snow and firn: 0.3581440871665837 , 0.8903698225086876 and 0.5812397794568983

RRR mult factor is: 0.6603697373492539

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 41.7212 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 245.69923599848102; R-squared: 0.09652463595996179
	 Time required to write restart and output files:    3 minutes 47.9482 seconds 

	 Total run duration:   38 minutes 59.8879 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -218.69343149431722
147 of 300, maximal objective function=-191.322, time remaining: 02:38:29
Acceptance rates [%] =95.89
Count 1396

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006067615358328641 and: 0.00014732899393049906

Albedo ice, snow and firn: 0.36464469652374953 , 0.8924911811820916 and 0.5808549023122993

RRR mult factor is: 0.6585009541090565

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.9435 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 256.6754617578456; R-squared: 0.10036753235640221
	 Time required to write restart and output files:    3 minutes 50.3949 seconds 

	 Total run duration:   38 minutes 52.1821 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -231.32424599069577
148 of 300, maximal objective function=-191.322, time remaining: 01:59:29
Acceptance rates [%] =95.92
Count 1397

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0057108766794463145 and: 0.00013823482861417683

Albedo ice, snow and firn: 0.3767401675389414 , 0.897828414911028 and 0.5692070921308933

RRR mult factor is: 0.6656212355976687

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 42.4183 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 256.3755890653462; R-squared: 0.10055326443498411
	 Time required to write restart and output files:    3 minutes 50.814 seconds 

	 Total run duration:   38 minutes 55.2308 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -232.27229922595026
149 of 300, maximal objective function=-191.322, time remaining: 01:20:33
Acceptance rates [%] =95.95
Count 1398

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005662602133366539 and: 0.00014054188869746463

Albedo ice, snow and firn: 0.3857068539583134 , 0.8939608017248839 and 0.5532281812305194

RRR mult factor is: 0.6632508729400278

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   16 minutes 58.1967 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 279.113108136011; R-squared: 0.12119167876836716
	 Time required to write restart and output files:    3 minutes 51.4077 seconds 

	 Total run duration:   42 minutes 23.4385 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -261.30843251133666
150 of 300, maximal objective function=-191.322, time remaining: 00:45:01
Acceptance rates [%] =95.3
Count 1399

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00546386418621885 and: 0.00015137361224552753

Albedo ice, snow and firn: 0.3850467512582276 , 0.8967014560298622 and 0.5584791621752645

RRR mult factor is: 0.6670658580695222

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   16 minutes 33.4344 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 255.3725791996173; R-squared: 0.10268763660562343
	 Time required to write restart and output files:    3 minutes 47.6584 seconds 

	 Total run duration:   41 minutes 53.6337 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -231.96415639349487
151 of 300, maximal objective function=-191.322, time remaining: 00:08:56
Acceptance rates [%] =95.33
Count 1400

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00519113348354524 and: 0.0001598060288824007

Albedo ice, snow and firn: 0.3655009087971945 , 0.8839955958173896 and 0.5580790732822452

RRR mult factor is: 0.6632785950919902

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   18 minutes 57.9572 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 265.073781704147; R-squared: 0.0959416341217446
	 Time required to write restart and output files:    3 minutes 51.5354 seconds 

	 Total run duration:   44 minutes 22.9318 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -241.07090071514776
152 of 300, maximal objective function=-191.322, time remaining: 23:35:09
Acceptance rates [%] =95.36
Count 1401

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005360856551363371 and: 0.0001456957500955259

Albedo ice, snow and firn: 0.35860634549807785 , 0.8975632901627338 and 0.5624875643778746

RRR mult factor is: 0.6601891486768634

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 20.3363 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 258.6983437388393; R-squared: 0.09227625424081365
	 Time required to write restart and output files:    3 minutes 49.7075 seconds 

	 Total run duration:   42 minutes 15.0366 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -233.14758413440484
153 of 300, maximal objective function=-191.322, time remaining: 22:59:13
Acceptance rates [%] =95.39
Count 1402

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005331372885717261 and: 0.00014397311825031355

Albedo ice, snow and firn: 0.3623599098502915 , 0.8935706739665568 and 0.5694264873438759

RRR mult factor is: 0.6494278140934628

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 13.057 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 258.78090743565036; R-squared: 0.09011055328099926
	 Time required to write restart and output files:    3 minutes 50.0284 seconds 

	 Total run duration:   42 minutes 26.8652 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -232.53868316804318
154 of 300, maximal objective function=-191.322, time remaining: 22:23:22
Acceptance rates [%] =95.42
Count 1403

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005396319726454255 and: 0.00014556121791026334

Albedo ice, snow and firn: 0.36804572166312943 , 0.8975768063716354 and 0.5805160085529244

RRR mult factor is: 0.6511463324936545

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 11.4804 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 246.5371971330843; R-squared: 0.09068139480576437
	 Time required to write restart and output files:    3 minutes 47.9608 seconds 

	 Total run duration:   42 minutes 24.5307 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -219.6026019295176
155 of 300, maximal objective function=-191.322, time remaining: 21:47:25
Acceptance rates [%] =95.45
Count 1404

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005328162232112827 and: 0.00013283212632786756

Albedo ice, snow and firn: 0.37532384949269765 , 0.892009799326087 and 0.5680192736006853

RRR mult factor is: 0.6595483821633121

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 26.5855 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 240.946764693762; R-squared: 0.10418053061253632
	 Time required to write restart and output files:    3 minutes 48.8403 seconds 

	 Total run duration:   42 minutes 38.1934 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -215.57282027750156
156 of 300, maximal objective function=-191.322, time remaining: 21:11:35
Acceptance rates [%] =95.48
Count 1405

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0051701822989735245 and: 0.00014020344030228488

Albedo ice, snow and firn: 0.3810143963500234 , 0.8706147654114087 and 0.5523885247346036

RRR mult factor is: 0.6609539141477524

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 24.5875 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 272.2374992162146; R-squared: 0.1381486758165436
	 Time required to write restart and output files:    3 minutes 49.7979 seconds 

	 Total run duration:   42 minutes 26.8623 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -256.5668778518044
157 of 300, maximal objective function=-191.322, time remaining: 20:35:30
Acceptance rates [%] =95.51
Count 1406

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005405992379018881 and: 0.00014009973685094872

Albedo ice, snow and firn: 0.37154722054186046 , 0.8730435761107833 and 0.5589750480261599

RRR mult factor is: 0.6678297231012917

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 18.4533 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 282.98851264175147; R-squared: 0.11335122280894706
	 Time required to write restart and output files:    3 minutes 53.6068 seconds 

	 Total run duration:   42 minutes 43.8079 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -263.2963791341768
158 of 300, maximal objective function=-191.322, time remaining: 19:59:35
Acceptance rates [%] =95.54
Count 1407

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005639707922141611 and: 0.00016444562842968943

Albedo ice, snow and firn: 0.39373569594480795 , 0.8909012358629369 and 0.57512186505118

RRR mult factor is: 0.676523597308587

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 12.5806 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 256.50943529768966; R-squared: 0.11093153338384812
	 Time required to write restart and output files:    3 minutes 50.1324 seconds 

	 Total run duration:   42 minutes 26.6071 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -235.11832735629082
159 of 300, maximal objective function=-191.322, time remaining: 19:23:20
Acceptance rates [%] =95.57
Count 1408

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005917962449301433 and: 0.0001667230757024044

Albedo ice, snow and firn: 0.37846211911328304 , 0.8980395572209172 and 0.573969459527298

RRR mult factor is: 0.6727160675980114

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 16.4878 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 257.3293871163235; R-squared: 0.10441342784360433
	 Time required to write restart and output files:    3 minutes 50.2146 seconds 

	 Total run duration:   42 minutes 28.3653 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -233.90756725234615
160 of 300, maximal objective function=-191.322, time remaining: 18:47:02
Acceptance rates [%] =95.6
Count 1409

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00613006324488632 and: 0.00016130384826220287

Albedo ice, snow and firn: 0.3708794615654197 , 0.8892361624517044 and 0.540414263223307

RRR mult factor is: 0.6720759262652036

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=57.00 GB, workers=19/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 29.3557 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 280.1373911183142; R-squared: 0.12278753420863918
	 Time required to write restart and output files:    3 minutes 48.6432 seconds 

	 Total run duration:   42 minutes 29.0871 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -261.78251572229846
161 of 300, maximal objective function=-191.322, time remaining: 18:10:39
Acceptance rates [%] =95.62
Count 1410

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006383872167719147 and: 0.00014370071947420428

Albedo ice, snow and firn: 0.37652328461616547 , 0.8841922245250684 and 0.5478474070648685

RRR mult factor is: 0.6760111735542977

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 8.11214 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 291.94179327676716; R-squared: 0.13999929621154705
	 Time required to write restart and output files:    3 minutes 48.7976 seconds 

	 Total run duration:   42 minutes 17.1993 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -276.2294240797754
162 of 300, maximal objective function=-191.322, time remaining: 17:34:03
Acceptance rates [%] =95.65
Count 1411

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006221483524474923 and: 0.00014406332167931192

Albedo ice, snow and firn: 0.39345558619000714 , 0.8720971026169635 and 0.5383528203395403

RRR mult factor is: 0.6784093125847306

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   18 minutes 10.506 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 298.2411105528473; R-squared: 0.1423980577435514
	 Time required to write restart and output files:    3 minutes 51.7185 seconds 

	 Total run duration:   43 minutes 35.6719 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -284.8312708886822
163 of 300, maximal objective function=-191.322, time remaining: 16:58:27
Acceptance rates [%] =95.68
Count 1412

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006497594110213815 and: 0.00013282834902029954

Albedo ice, snow and firn: 0.3950877267577336 , 0.8665153269555372 and 0.5386769926475269

RRR mult factor is: 0.6787894457885877

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 44.5342 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 292.7552267471253; R-squared: 0.17632700775264093
	 Time required to write restart and output files:    3 minutes 52.3172 seconds 

	 Total run duration:   39 minutes 1.01912 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -285.6017165248124
164 of 300, maximal objective function=-191.322, time remaining: 16:19:00
Acceptance rates [%] =95.71
Count 1413

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006180658289426018 and: 0.0001314704131867477

Albedo ice, snow and firn: 0.3829950188330801 , 0.8607126886146614 and 0.5412611414732776

RRR mult factor is: 0.6767458026158646

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 19.6375 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 288.18427516915494; R-squared: 0.17522178755331874
	 Time required to write restart and output files:    3 minutes 49.134 seconds 

	 Total run duration:   39 minutes 38.8608 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -280.4661944691427
165 of 300, maximal objective function=-191.322, time remaining: 15:40:05
Acceptance rates [%] =95.73
Count 1414

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006170583296581308 and: 0.00012939432474129122

Albedo ice, snow and firn: 0.38190334394791986 , 0.8774700413230825 and 0.5466694235324184

RRR mult factor is: 0.6757684308688428

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 37.8595 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 243.59025759067544; R-squared: 0.17248722055815482
	 Time required to write restart and output files:    3 minutes 48.2097 seconds 

	 Total run duration:   38 minutes 34.0338 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -231.1788408231599
166 of 300, maximal objective function=-191.322, time remaining: 15:00:17
Acceptance rates [%] =95.76
Count 1415

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006376047032852184 and: 0.0001312503458873429

Albedo ice, snow and firn: 0.38409886915124175 , 0.8708690584503124 and 0.5594978821538773

RRR mult factor is: 0.6776453140389888

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 7.59544 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 209.65910979448657; R-squared: 0.29700957721309273
	 Time required to write restart and output files:    3 minutes 49.2993 seconds 

	 Total run duration:   39 minutes 20.112 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -208.40010146503798
167 of 300, maximal objective function=-191.322, time remaining: 14:21:07
Acceptance rates [%] =95.78
Count 1416

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0065012100235291035 and: 8.17925676156186e-05

Albedo ice, snow and firn: 0.3749741932078537 , 0.8596018920207433 and 0.553243908343119

RRR mult factor is: 0.6734593538654784

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 30.625 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 228.2437760058296; R-squared: 0.2669767474342556
	 Time required to write restart and output files:    3 minutes 50.0996 seconds 

	 Total run duration:   39 minutes 0.467103 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -225.79092720474017
168 of 300, maximal objective function=-191.322, time remaining: 13:41:41
Acceptance rates [%] =95.21
Count 1417

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0058911028249240514 and: 0.00016164931109405523

Albedo ice, snow and firn: 0.38983186518754886 , 0.8716534555814494 and 0.5500303713525698

RRR mult factor is: 0.6794260387831881

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 38.8503 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 209.58245663733817; R-squared: 0.2864896920937433
	 Time required to write restart and output files:    3 minutes 54.3496 seconds 

	 Total run duration:   39 minutes 2.09114 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -207.19510175738918
169 of 300, maximal objective function=-191.322, time remaining: 13:02:16
Acceptance rates [%] =95.24
Count 1418

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00609957945062757 and: 0.00015841957459939733

Albedo ice, snow and firn: 0.3813457949018527 , 0.8714942180089065 and 0.559165321120848

RRR mult factor is: 0.6787235960639795

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 34.369 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 230.71507067028003; R-squared: 0.19820507619523173
	 Time required to write restart and output files:    3 minutes 49.612 seconds 

	 Total run duration:   38 minutes 56.0651 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -221.09288716589754
170 of 300, maximal objective function=-191.322, time remaining: 12:22:48
Acceptance rates [%] =95.27
Count 1419

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006223542401747701 and: 0.00016373894177568077

Albedo ice, snow and firn: 0.37657738334337043 , 0.8827854727202856 and 0.566364908836083

RRR mult factor is: 0.6783877431662068

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 55.8018 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 226.58889472958157; R-squared: 0.146859827871336
	 Time required to write restart and output files:    3 minutes 51.0351 seconds 

	 Total run duration:   40 minutes 17.5038 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -205.37689959063246
171 of 300, maximal objective function=-191.322, time remaining: 11:44:20
Acceptance rates [%] =95.29
Count 1420

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0064850687717504674 and: 0.00014522360284311824

Albedo ice, snow and firn: 0.37390051337938635 , 0.8757226082842099 and 0.5711197585081598

RRR mult factor is: 0.6770754509708746

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.2701 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 255.0940165819864; R-squared: 0.11046226728550206
	 Time required to write restart and output files:    3 minutes 49.9146 seconds 

	 Total run duration:   38 minutes 45.6568 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -231.58028498064323
172 of 300, maximal objective function=-191.322, time remaining: 11:04:44
Acceptance rates [%] =95.32
Count 1421

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00666552158627663 and: 0.00015016553589244447

Albedo ice, snow and firn: 0.37677198639068604 , 0.8710785153276074 and 0.5727586713301457

RRR mult factor is: 0.6723169751214528

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 45.9804 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 252.51996946042817; R-squared: 0.12043867092231363
	 Time required to write restart and output files:    3 minutes 53.8819 seconds 

	 Total run duration:   39 minutes 24.5198 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -229.15268324352954
173 of 300, maximal objective function=-191.322, time remaining: 10:25:36
Acceptance rates [%] =95.35
Count 1422

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006577857507692149 and: 0.0001336830603351182

Albedo ice, snow and firn: 0.367953047468668 , 0.8726518472845579 and 0.5750428329870378

RRR mult factor is: 0.677617864505801

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 51.6067 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 255.76904318110297; R-squared: 0.11805333713481479
	 Time required to write restart and output files:    3 minutes 50.5743 seconds 

	 Total run duration:   39 minutes 38.3537 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -233.33371289535964
174 of 300, maximal objective function=-191.322, time remaining: 09:46:38
Acceptance rates [%] =95.38
Count 1423

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006418746637253913 and: 0.0001461885090259089

Albedo ice, snow and firn: 0.3658844962352667 , 0.863534207907422 and 0.5789944880905699

RRR mult factor is: 0.6672273499956375

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.2527 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 269.6582848623106; R-squared: 0.15631249008491283
	 Time required to write restart and output files:    3 minutes 50.3107 seconds 

	 Total run duration:   39 minutes 6.96459 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -255.91615786440147
175 of 300, maximal objective function=-191.322, time remaining: 09:07:17
Acceptance rates [%] =95.4
Count 1424

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006331306864847523 and: 0.0001481431424215322

Albedo ice, snow and firn: 0.3693204054235364 , 0.8387815668895617 and 0.5831004666706434

RRR mult factor is: 0.6679049237625483

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 26.6346 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 290.37660960967753; R-squared: 0.17664098271194373
	 Time required to write restart and output files:    3 minutes 50.9577 seconds 

	 Total run duration:   38 minutes 53.8644 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -281.77944213946034
176 of 300, maximal objective function=-191.322, time remaining: 08:27:48
Acceptance rates [%] =95.43
Count 1425

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006445451019587419 and: 0.00013993723449047947

Albedo ice, snow and firn: 0.36412817276180415 , 0.8512599487730509 and 0.5831994589610736

RRR mult factor is: 0.6582824277229617

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 30.3912 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 271.25650332274625; R-squared: 0.14102919500461808
	 Time required to write restart and output files:    3 minutes 52.8432 seconds 

	 Total run duration:   39 minutes 3.17139 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -253.33270720121286
177 of 300, maximal objective function=-191.322, time remaining: 07:48:25
Acceptance rates [%] =95.45
Count 1426

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00675965590892132 and: 0.00015391530213184094

Albedo ice, snow and firn: 0.35855526544959576 , 0.8512840517004647 and 0.6029301331905463

RRR mult factor is: 0.6691521057508205

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 29.0662 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 254.4273358798018; R-squared: 0.13493375591352633
	 Time required to write restart and output files:    3 minutes 50.909 seconds 

	 Total run duration:   38 minutes 58.3031 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -233.63150865431797
178 of 300, maximal objective function=-191.322, time remaining: 07:08:59
Acceptance rates [%] =95.48
Count 1427

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0067711757051341125 and: 0.0001594955291705185

Albedo ice, snow and firn: 0.37363426575298864 , 0.8583996363594986 and 0.6059648073151175

RRR mult factor is: 0.6750348549981653

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 30.701 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 246.3581148601954; R-squared: 0.1503823119610482
	 Time required to write restart and output files:    3 minutes 51.1084 seconds 

	 Total run duration:   38 minutes 35.3654 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -228.62588407481044
179 of 300, maximal objective function=-191.322, time remaining: 06:29:18
Acceptance rates [%] =95.51
Count 1428

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006817548961000411 and: 0.00016720930207968118

Albedo ice, snow and firn: 0.3744277379981626 , 0.8581278422760229 and 0.6094575171880738

RRR mult factor is: 0.6784617430294391

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 38.3856 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 249.6990387973001; R-squared: 0.13248038675784096
	 Time required to write restart and output files:    3 minutes 53.9053 seconds 

	 Total run duration:   39 minutes 7.96225 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -228.07819997950526
180 of 300, maximal objective function=-191.322, time remaining: 05:50:00
Acceptance rates [%] =95.53
Count 1429

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006948104725401911 and: 0.00013876316305091898

Albedo ice, snow and firn: 0.37267469551737964 , 0.8656720972013041 and 0.5866606962451981

RRR mult factor is: 0.6727974905361614

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 38.4404 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 251.79009036025042; R-squared: 0.12623728848062188
	 Time required to write restart and output files:    3 minutes 50.8499 seconds 

	 Total run duration:   38 minutes 50.2835 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -229.14273163226835
181 of 300, maximal objective function=-191.322, time remaining: 05:10:30
Acceptance rates [%] =95.56
Count 1430

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006740286435813494 and: 0.00013321834213438018

Albedo ice, snow and firn: 0.3767802917877326 , 0.862486152867143 and 0.5867134361601353

RRR mult factor is: 0.6786657938420234

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 37.3871 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 249.13919181729014; R-squared: 0.12980561692656695
	 Time required to write restart and output files:    3 minutes 51.1324 seconds 

	 Total run duration:   38 minutes 54.0157 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -227.62793722627984
182 of 300, maximal objective function=-191.322, time remaining: 04:31:03
Acceptance rates [%] =95.58
Count 1431

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006804390770125699 and: 0.00013782233053010343

Albedo ice, snow and firn: 0.37782374340008085 , 0.8558849431860174 and 0.5865222699692494

RRR mult factor is: 0.6757883692490296

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 36.6193 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 216.95819289801923; R-squared: 0.2573887250854674
	 Time required to write restart and output files:    3 minutes 52.6654 seconds 

	 Total run duration:   38 minutes 59.8078 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -210.7932655504353
183 of 300, maximal objective function=-191.322, time remaining: 03:51:39
Acceptance rates [%] =95.6
Count 1432

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006604915163331686 and: 0.00012721394106984373

Albedo ice, snow and firn: 0.38798948434450203 , 0.8587792474730843 and 0.586984593646286

RRR mult factor is: 0.6698462339627687

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.534 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 208.8140605882959; R-squared: 0.2835231086097854
	 Time required to write restart and output files:    3 minutes 49.6482 seconds 

	 Total run duration:   38 minutes 48.5894 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -204.93800467564984
184 of 300, maximal objective function=-191.322, time remaining: 03:12:10
Acceptance rates [%] =95.63
Count 1433

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006681614992173536 and: 0.00015374246694094338

Albedo ice, snow and firn: 0.3788020730000721 , 0.87014735469207 and 0.6008148365835586

RRR mult factor is: 0.6648983593604855

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 43.1351 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 228.1700891226483; R-squared: 0.15596646575457812
	 Time required to write restart and output files:    3 minutes 50.7596 seconds 

	 Total run duration:   38 minutes 44.123 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -208.83043888770706
185 of 300, maximal objective function=-191.322, time remaining: 02:32:37
Acceptance rates [%] =95.11
Count 1434

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006592776884056866 and: 0.0001289244875148213

Albedo ice, snow and firn: 0.3877965914215679 , 0.8646056552654423 and 0.5926290574778587

RRR mult factor is: 0.6712902133138177

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 45.5475 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 221.53663777788447; R-squared: 0.18334523526041466
	 Time required to write restart and output files:    3 minutes 50.0521 seconds 

	 Total run duration:   38 minutes 52.8604 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -205.81235645526417
186 of 300, maximal objective function=-191.322, time remaining: 01:53:11
Acceptance rates [%] =95.14
Count 1435

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006386383166752504 and: 0.000132384122283287

Albedo ice, snow and firn: 0.3866187861417792 , 0.8650884042239505 and 0.5879346003582155

RRR mult factor is: 0.6708746264347207

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 15.9576 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 229.8699974888553; R-squared: 0.18441673172348116
	 Time required to write restart and output files:    3 minutes 51.8642 seconds 

	 Total run duration:   39 minutes 27.4664 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -216.12758744753341
187 of 300, maximal objective function=-191.322, time remaining: 01:14:05
Acceptance rates [%] =95.16
Count 1436

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006204462796362549 and: 0.00011087925697073117

Albedo ice, snow and firn: 0.37838875600079314 , 0.870871529345863 and 0.5818427222065811

RRR mult factor is: 0.6786782734078929

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 39.2244 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 216.77854073704674; R-squared: 0.19686513047891072
	 Time required to write restart and output files:    3 minutes 51.1083 seconds 

	 Total run duration:   39 minutes 2.20988 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -204.26057456021394
188 of 300, maximal objective function=-191.322, time remaining: 00:34:45
Acceptance rates [%] =95.19
Count 1437

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0062376076422004404 and: 0.00013308926285546726

Albedo ice, snow and firn: 0.3762307057469248 , 0.8799540744354349 and 0.5815862465722799

RRR mult factor is: 0.670812120347323

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 47.654 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 233.43906778562055; R-squared: 0.12583723192137988
	 Time required to write restart and output files:    3 minutes 50.362 seconds 

	 Total run duration:   39 minutes 0.341201 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -209.82046676104875
189 of 300, maximal objective function=-191.322, time remaining: 23:55:23
Acceptance rates [%] =95.21
Count 1438

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006132708466253071 and: 0.0001420302287548131

Albedo ice, snow and firn: 0.35637846520852157 , 0.8734480105615332 and 0.5809177843680285

RRR mult factor is: 0.6654188454918426

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 43.2904 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 251.97304185656333; R-squared: 0.10937689392466282
	 Time required to write restart and output files:    3 minutes 50.7619 seconds 

	 Total run duration:   38 minutes 56.07 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -227.16247556735948
190 of 300, maximal objective function=-191.322, time remaining: 23:16:00
Acceptance rates [%] =95.24
Count 1439

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006033367587559023 and: 0.00011956254098454325

Albedo ice, snow and firn: 0.3666567042813207 , 0.8814210402523115 and 0.597749857043766

RRR mult factor is: 0.6610085367917612

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 5.98678 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 240.4769288743683; R-squared: 0.09314228062279184
	 Time required to write restart and output files:    3 minutes 50.4085 seconds 

	 Total run duration:   39 minutes 28.5664 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -212.665976135813
191 of 300, maximal objective function=-191.322, time remaining: 22:36:55
Acceptance rates [%] =95.26
Count 1440

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006065692592754801 and: 0.00012597743269568808

Albedo ice, snow and firn: 0.35369371314781767 , 0.8929634560309015 and 0.6003702760590411

RRR mult factor is: 0.6700477141403617

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 52.4376 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 226.2577343188251; R-squared: 0.08860161644306928
	 Time required to write restart and output files:    3 minutes 49.8621 seconds 

	 Total run duration:   38 minutes 46.0957 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -196.49547051457375
192 of 300, maximal objective function=-191.322, time remaining: 21:57:26
Acceptance rates [%] =95.29
Count 1441

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006011309881208202 and: 0.00012969573833044752

Albedo ice, snow and firn: 0.35903923163191265 , 0.8922678963279914 and 0.5854617574904369

RRR mult factor is: 0.6717592847589204

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 46.8333 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 233.8151329017976; R-squared: 0.10043749517214526
	 Time required to write restart and output files:    3 minutes 48.9267 seconds 

	 Total run duration:   39 minutes 3.7714 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -205.49642301147819
193 of 300, maximal objective function=-191.322, time remaining: 21:18:07
Acceptance rates [%] =95.31
Count 1442

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006079704942011001 and: 0.0001132193848377013

Albedo ice, snow and firn: 0.3537919605022672 , 0.8707669976531627 and 0.5796913495372467

RRR mult factor is: 0.6786074982829818

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 28.5635 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 253.0761902139722; R-squared: 0.10723083045436471
	 Time required to write restart and output files:    3 minutes 50.0419 seconds 

	 Total run duration:   38 minutes 45.1385 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -228.8177506950978
194 of 300, maximal objective function=-191.322, time remaining: 20:38:38
Acceptance rates [%] =95.34
Count 1443

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006072055637650606 and: 9.88222527667213e-05

Albedo ice, snow and firn: 0.3527301296026325 , 0.8658473613720863 and 0.5841045446334857

RRR mult factor is: 0.6766029837229213

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 36.4882 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 251.2475253689788; R-squared: 0.10733161105610951
	 Time required to write restart and output files:    3 minutes 47.1888 seconds 

	 Total run duration:   38 minutes 57.2675 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -226.5444334934559
195 of 300, maximal objective function=-191.322, time remaining: 19:59:16
Acceptance rates [%] =95.36
Count 1444

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005849132991708299 and: 9.613579893497131e-05

Albedo ice, snow and firn: 0.3364295451483217 , 0.8797902342860637 and 0.5817369252655803

RRR mult factor is: 0.6776361431666147

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.6888 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 255.77761151161332; R-squared: 0.10680943538044181
	 Time required to write restart and output files:    3 minutes 51.9434 seconds 

	 Total run duration:   38 minutes 54.9565 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -232.40003353289916
196 of 300, maximal objective function=-191.322, time remaining: 19:19:54
Acceptance rates [%] =95.38
Count 1445

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005971695160533056 and: 9.996801868954494e-05

Albedo ice, snow and firn: 0.34103479730277164 , 0.8929853027506957 and 0.5831943294015579

RRR mult factor is: 0.6731584888774645

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=111.00 GB, workers=37/200, jobs=2/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 39.5915 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 232.0532562866441; R-squared: 0.11663052567608101
	 Time required to write restart and output files:    3 minutes 48.859 seconds 

	 Total run duration:   38 minutes 55.2816 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -206.85939004332653
197 of 300, maximal objective function=-191.322, time remaining: 18:40:31
Acceptance rates [%] =95.41
Count 1446

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006216675592554257 and: 0.00010985421508040654

Albedo ice, snow and firn: 0.3411856766116326 , 0.8949938435777629 and 0.597824067305261

RRR mult factor is: 0.668575223813612

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 48.2863 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 236.8877215040678; R-squared: 0.1054576831706579
	 Time required to write restart and output files:    3 minutes 49.6941 seconds 

	 Total run duration:   39 minutes 10.6632 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -210.4810855225083
198 of 300, maximal objective function=-191.322, time remaining: 18:01:17
Acceptance rates [%] =95.43
Count 1447

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005932599370483146 and: 0.0001226242298031682

Albedo ice, snow and firn: 0.34659875007213214 , 0.8939289298976375 and 0.5977478886767598

RRR mult factor is: 0.6706354684136782

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   19 minutes 39.4745 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 216.8901565538483; R-squared: 0.08530627174879415
	 Time required to write restart and output files:    3 minutes 46.3701 seconds 

	 Total run duration:   44 minutes 51.67 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -186.07748878594873
199 of 300, maximal objective function=-186.077, time remaining: 17:24:53
Acceptance rates [%] =95.45
Count 1448

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0061890591852513666 and: 0.00012100365612522135

Albedo ice, snow and firn: 0.3360470188509219 , 0.8981428288463381 and 0.5896344523347706

RRR mult factor is: 0.6762946048811115

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   17 minutes 1.82917 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 208.03946911576446; R-squared: 0.08346624063204586
	 Time required to write restart and output files:    3 minutes 49.3752 seconds 

	 Total run duration:   42 minutes 21.542 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -177.4455563845886
200 of 300, maximal objective function=-177.446, time remaining: 16:47:10
Acceptance rates [%] =95.48
Count 1449

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00613261285029879 and: 0.00011310246728216713

Albedo ice, snow and firn: 0.33148665454692844 , 0.8941142329353278 and 0.5854771178539049

RRR mult factor is: 0.6746218272332761

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   16 minutes 23.9449 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 219.18519708566802; R-squared: 0.09100325808791171
	 Time required to write restart and output files:    3 minutes 51.3112 seconds 

	 Total run duration:   41 minutes 43.8346 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -188.8340520498214
201 of 300, maximal objective function=-177.446, time remaining: 16:09:07
Acceptance rates [%] =95.5
Count 1450

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006003190382247489 and: 0.00011853650695033184

Albedo ice, snow and firn: 0.3366846620338004 , 0.8836424364095249 and 0.5759886378603367

RRR mult factor is: 0.6663015326430825

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 49.4632 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 228.88670842077414; R-squared: 0.12002670437553953
	 Time required to write restart and output files:    3 minutes 49.7537 seconds 

	 Total run duration:   39 minutes 5.98079 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -203.76169899264636
202 of 300, maximal objective function=-177.446, time remaining: 15:29:45
Acceptance rates [%] =95.52
Count 1451

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006165199021345224 and: 0.00012109998735087898

Albedo ice, snow and firn: 0.3338826727022264 , 0.8839915341232427 and 0.5593645540927671

RRR mult factor is: 0.6682022715425335

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 6.05241 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 239.04463355230968; R-squared: 0.10334082610392045
	 Time required to write restart and output files:    3 minutes 49.5559 seconds 

	 Total run duration:   39 minutes 24.7679 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -212.09027446307942
203 of 300, maximal objective function=-177.446, time remaining: 14:50:33
Acceptance rates [%] =95.54
Count 1452

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006114405794082052 and: 0.00010050275559070286

Albedo ice, snow and firn: 0.3321709950584158 , 0.8807304089348824 and 0.5703762130809918

RRR mult factor is: 0.6761561106137594

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 5.54983 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 217.1831386572776; R-squared: 0.10586527889643613
	 Time required to write restart and output files:    3 minutes 51.4416 seconds 

	 Total run duration:   39 minutes 31.5124 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -189.0056003623551
204 of 300, maximal objective function=-177.446, time remaining: 14:11:23
Acceptance rates [%] =95.57
Count 1453

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.006122112130948315 and: 0.0001249746783193091

Albedo ice, snow and firn: 0.31764443122996794 , 0.8859087069501786 and 0.5785937430112451

RRR mult factor is: 0.6741630760062107

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 32.5148 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 224.94444324001438; R-squared: 0.08460489533378338
	 Time required to write restart and output files:    3 minutes 50.5148 seconds 

	 Total run duration:   39 minutes 54.5021 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -195.0302083475791
205 of 300, maximal objective function=-177.446, time remaining: 13:32:24
Acceptance rates [%] =95.59
Count 1454

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005879800275546456 and: 0.0001273789950484406

Albedo ice, snow and firn: 0.31865843567646246 , 0.8761305568121243 and 0.5848309776137931

RRR mult factor is: 0.6766463768761448

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 16.4998 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 224.75964158686728; R-squared: 0.0857058064364976
	 Time required to write restart and output files:    3 minutes 48.9997 seconds 

	 Total run duration:   39 minutes 25.9174 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -194.53037981991332
206 of 300, maximal objective function=-177.446, time remaining: 12:53:12
Acceptance rates [%] =95.61
Count 1455

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005586932451807391 and: 0.00012303571972645502

Albedo ice, snow and firn: 0.31250049741793345 , 0.8732966839462603 and 0.583431137374599

RRR mult factor is: 0.6763397463280455

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 11.4021 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 233.5722714733339; R-squared: 0.10006410530674179
	 Time required to write restart and output files:    3 minutes 50.3076 seconds 

	 Total run duration:   39 minutes 15.5328 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -204.76798900212273
207 of 300, maximal objective function=-177.446, time remaining: 12:13:54
Acceptance rates [%] =95.15
Count 1456

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005807257405732378 and: 0.00012119853145063354

Albedo ice, snow and firn: 0.3148352973269348 , 0.8888079922369725 and 0.5829843014123863

RRR mult factor is: 0.6748251148345075

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 13.8018 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 210.9324300816905; R-squared: 0.08169851307156656
	 Time required to write restart and output files:    3 minutes 49.664 seconds 

	 Total run duration:   39 minutes 31.7017 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -180.83460888530615
208 of 300, maximal objective function=-177.446, time remaining: 11:34:44
Acceptance rates [%] =95.17
Count 1457

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005707144011321873 and: 0.0001267229283449435

Albedo ice, snow and firn: 0.31828119764687723 , 0.8879690765812897 and 0.5843641112141821

RRR mult factor is: 0.6760628030930617

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 17.2513 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 225.720089319254; R-squared: 0.08155085532131442
	 Time required to write restart and output files:    3 minutes 50.1024 seconds 

	 Total run duration:   39 minutes 38.1659 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -195.85042947645837
209 of 300, maximal objective function=-177.446, time remaining: 10:55:37
Acceptance rates [%] =95.19
Count 1458

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005520586270988027 and: 0.00013811790239250622

Albedo ice, snow and firn: 0.32303853896772033 , 0.8955443995055901 and 0.578326855663812

RRR mult factor is: 0.6784407400988733

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 7.00969 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 227.6264322087907; R-squared: 0.08107650588549901
	 Time required to write restart and output files:    3 minutes 49.2686 seconds 

	 Total run duration:   39 minutes 19.5951 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -197.82210624279148
210 of 300, maximal objective function=-177.446, time remaining: 10:16:21
Acceptance rates [%] =95.22
Count 1459

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005561915117642484 and: 0.00014961654787247329

Albedo ice, snow and firn: 0.3289063446715865 , 0.8799026793162399 and 0.577609545789387

RRR mult factor is: 0.6740054829856007

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 17.4215 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 250.68161532618413; R-squared: 0.08751909792742815
	 Time required to write restart and output files:    3 minutes 49.7064 seconds 

	 Total run duration:   39 minutes 27.0963 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -223.0979807712615
211 of 300, maximal objective function=-177.446, time remaining: 09:37:08
Acceptance rates [%] =95.24
Count 1460

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005552327551624733 and: 0.00011733956494933603

Albedo ice, snow and firn: 0.327144174856729 , 0.858843797574509 and 0.5751983897138002

RRR mult factor is: 0.6725017123545854

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=57.00 GB, workers=19/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.3133 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 264.4353854707182; R-squared: 0.09443228359135535
	 Time required to write restart and output files:    3 minutes 49.8425 seconds 

	 Total run duration:   38 minutes 57.3693 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -239.55112501339576
212 of 300, maximal objective function=-177.446, time remaining: 08:57:43
Acceptance rates [%] =95.26
Count 1461

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005662793882029929 and: 0.00011500996226424781

Albedo ice, snow and firn: 0.33142218886610403 , 0.8481505534164357 and 0.5694790771522938

RRR mult factor is: 0.6707565211477701

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.5102 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 265.52769328411665; R-squared: 0.1090109202184925
	 Time required to write restart and output files:    3 minutes 51.9557 seconds 

	 Total run duration:   39 minutes 6.67753 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -242.58090302520048
213 of 300, maximal objective function=-177.446, time remaining: 08:18:22
Acceptance rates [%] =95.28
Count 1462

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005445166310050077 and: 0.0001248532792721774

Albedo ice, snow and firn: 0.32967684143161935 , 0.8504715922176057 and 0.5753149146636723

RRR mult factor is: 0.6731226455658051

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 54.6517 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 261.3624622435569; R-squared: 0.10798438867341228
	 Time required to write restart and output files:    3 minutes 51.1849 seconds 

	 Total run duration:   39 minutes 1.93018 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -238.8883408600875
214 of 300, maximal objective function=-177.446, time remaining: 07:38:59
Acceptance rates [%] =95.31
Count 1463

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005189613514792471 and: 0.00011810314381768234

Albedo ice, snow and firn: 0.32842917124435067 , 0.8478018177998867 and 0.5831333824611937

RRR mult factor is: 0.6735912239342249

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 20.657 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 261.651478660831; R-squared: 0.10412285789644377
	 Time required to write restart and output files:    3 minutes 51.4297 seconds 

	 Total run duration:   39 minutes 39.8063 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -239.27378923958048
215 of 300, maximal objective function=-177.446, time remaining: 06:59:52
Acceptance rates [%] =95.33
Count 1464

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005106607176884569 and: 0.00011966390360494537

Albedo ice, snow and firn: 0.32901843700066474 , 0.8598383941531885 and 0.5878626101309449

RRR mult factor is: 0.6708054936741609

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.5039 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 250.10340123982314; R-squared: 0.10261176438596971
	 Time required to write restart and output files:    3 minutes 50.2682 seconds 

	 Total run duration:   38 minutes 54.0292 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -224.4030077613164
216 of 300, maximal objective function=-177.446, time remaining: 06:20:26
Acceptance rates [%] =95.35
Count 1465

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005498507844315633 and: 0.00011592837318393393

Albedo ice, snow and firn: 0.3316901504214061 , 0.8525996719784251 and 0.5782997117484776

RRR mult factor is: 0.662390985074027

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.9085 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 274.4272940300695; R-squared: 0.10087714012452903
	 Time required to write restart and output files:    3 minutes 50.764 seconds 

	 Total run duration:   38 minutes 45.6572 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -251.31849274753603
217 of 300, maximal objective function=-177.446, time remaining: 05:40:58
Acceptance rates [%] =95.37
Count 1466

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005157816504244634 and: 0.00016678728269935964

Albedo ice, snow and firn: 0.33173704640546836 , 0.8523286052137293 and 0.5764947035857781

RRR mult factor is: 0.6693009714117567

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 44.7133 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 277.77484348264176; R-squared: 0.10445745920998994
	 Time required to write restart and output files:    3 minutes 50.9734 seconds 

	 Total run duration:   39 minutes 10.1578 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -255.76572370874692
218 of 300, maximal objective function=-177.446, time remaining: 05:01:38
Acceptance rates [%] =94.93
Count 1467

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005223623308753009 and: 0.00010161411734932517

Albedo ice, snow and firn: 0.3283314422609207 , 0.8603403655111287 and 0.5751273508619431

RRR mult factor is: 0.6682353409995394

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 49.8858 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 268.3211574863601; R-squared: 0.10586730145843214
	 Time required to write restart and output files:    3 minutes 53.0352 seconds 

	 Total run duration:   39 minutes 6.7126 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -245.98221854912168
219 of 300, maximal objective function=-177.446, time remaining: 04:22:18
Acceptance rates [%] =94.95
Count 1468

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005288161463749791 and: 9.118388640322324e-05

Albedo ice, snow and firn: 0.3348477136474383 , 0.8659027054186744 and 0.5634675540166012

RRR mult factor is: 0.6741745010725196

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.366 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 259.59033424174936; R-squared: 0.13036522746361562
	 Time required to write restart and output files:    3 minutes 52.0639 seconds 

	 Total run duration:   39 minutes 2.81926 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -240.47821466551082
220 of 300, maximal objective function=-177.446, time remaining: 03:42:57
Acceptance rates [%] =94.98
Count 1469

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00500406384832587 and: 0.00013605147519675092

Albedo ice, snow and firn: 0.33262239493539403 , 0.8681467279104916 and 0.5605893126006648

RRR mult factor is: 0.67921216100307

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 41.9996 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 242.63326658690082; R-squared: 0.16517109760144996
	 Time required to write restart and output files:    3 minutes 51.7727 seconds 

	 Total run duration:   38 minutes 58.0776 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -230.2712831221113
221 of 300, maximal objective function=-177.446, time remaining: 03:03:34
Acceptance rates [%] =95.
Count 1470

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00523165503134199 and: 0.00012588773676387445

Albedo ice, snow and firn: 0.33166541451866316 , 0.8609975957265222 and 0.5742035725725281

RRR mult factor is: 0.6762426359542486

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 43.4114 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 236.80009829091242; R-squared: 0.16927530292088486
	 Time required to write restart and output files:    3 minutes 51.1621 seconds 

	 Total run duration:   39 minutes 2.69152 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -223.3775722641781
222 of 300, maximal objective function=-177.446, time remaining: 02:24:13
Acceptance rates [%] =95.02
Count 1471

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005497572747611063 and: 0.00013796267514781284

Albedo ice, snow and firn: 0.3428980241916691 , 0.8593073529865338 and 0.5716630813877012

RRR mult factor is: 0.6645474722389461

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 26.1062 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 282.29507047679886; R-squared: 0.15546237527036533
	 Time required to write restart and output files:    3 minutes 50.4263 seconds 

	 Total run duration:   38 minutes 44.6344 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -270.5167747280427
223 of 300, maximal objective function=-177.446, time remaining: 01:44:45
Acceptance rates [%] =95.05
Count 1472

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005018865799480328 and: 0.00013483976080777278

Albedo ice, snow and firn: 0.3431224792234253 , 0.8592974376401544 and 0.5703526985471654

RRR mult factor is: 0.6563987127654842

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 31.7816 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 273.206440604524; R-squared: 0.13463252134841042
	 Time required to write restart and output files:    3 minutes 51.4146 seconds 

	 Total run duration:   38 minutes 58.5347 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -255.8317472305936
224 of 300, maximal objective function=-177.446, time remaining: 01:05:23
Acceptance rates [%] =95.07
Count 1473

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005145068725649451 and: 0.00014009632386338534

Albedo ice, snow and firn: 0.32599036376988466 , 0.8542224800276278 and 0.5936113800282681

RRR mult factor is: 0.6624674529054617

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/200, jobs=2/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 36.0317 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 254.53790577809235; R-squared: 0.14534957833775927
	 Time required to write restart and output files:    3 minutes 49.0247 seconds 

	 Total run duration:   39 minutes 25.63 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -238.9079834782015
225 of 300, maximal objective function=-177.446, time remaining: 00:26:10
Acceptance rates [%] =95.09
Count 1474

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005428581451847142 and: 0.00013519286946107805

Albedo ice, snow and firn: 0.31049108822977584 , 0.8455142290424972 and 0.6091630943964185

RRR mult factor is: 0.6599874990969806

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 34.4051 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 276.77075772467003; R-squared: 0.18716880997181792
	 Time required to write restart and output files:    3 minutes 49.7239 seconds 

	 Total run duration:   38 minutes 54.057 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -268.15236516623094
226 of 300, maximal objective function=-177.446, time remaining: 23:46:47
Acceptance rates [%] =95.11
Count 1475

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005515702794583354 and: 0.00013844331724954464

Albedo ice, snow and firn: 0.3132947652132935 , 0.8430901297333632 and 0.5954772164811238

RRR mult factor is: 0.6655641150504968

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 33.0905 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 278.65744671301604; R-squared: 0.20542420490346147
	 Time required to write restart and output files:    3 minutes 54.0567 seconds 

	 Total run duration:   38 minutes 16.7094 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -274.0694107736599
227 of 300, maximal objective function=-177.446, time remaining: 23:07:12
Acceptance rates [%] =95.13
Count 1476

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005185752654055365 and: 0.00012083806116249144

Albedo ice, snow and firn: 0.30036888518599475 , 0.8474891803882505 and 0.5971205034501238

RRR mult factor is: 0.6670235986028483

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 36.3187 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 289.6094891015173; R-squared: 0.15224730052278312
	 Time required to write restart and output files:    3 minutes 53.1878 seconds 

	 Total run duration:   39 minutes 2.13172 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -278.6041873643879
228 of 300, maximal objective function=-177.446, time remaining: 22:27:52
Acceptance rates [%] =95.15
Count 1477

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005131326180831079 and: 0.0001463311750866827

Albedo ice, snow and firn: 0.3125974176813115 , 0.8493695943702035 and 0.6171242129710074

RRR mult factor is: 0.6634636106501107

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/200, jobs=2/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 37.1069 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 261.2212172164636; R-squared: 0.14479206542646525
	 Time required to write restart and output files:    3 minutes 49.9743 seconds 

	 Total run duration:   38 minutes 48.7717 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -245.07557767791968
229 of 300, maximal objective function=-177.446, time remaining: 21:48:28
Acceptance rates [%] =95.18
Count 1478

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005274963472395633 and: 0.0001478500680321486

Albedo ice, snow and firn: 0.28646303028890224 , 0.8414665186702583 and 0.6264607393242347

RRR mult factor is: 0.6648291031167575

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 36.7034 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 299.14556596944624; R-squared: 0.12016191836574766
	 Time required to write restart and output files:    3 minutes 47.1613 seconds 

	 Total run duration:   38 minutes 42.6963 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -280.6712237309114
230 of 300, maximal objective function=-177.446, time remaining: 21:09:02
Acceptance rates [%] =95.2
Count 1479

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0050228944967487315 and: 0.00013847397564599904

Albedo ice, snow and firn: 0.2852859471414012 , 0.8362762756371632 and 0.6296529703244974

RRR mult factor is: 0.6618649133930328

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 30.4861 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 295.0566169805415; R-squared: 0.146724005876765
	 Time required to write restart and output files:    3 minutes 51.5862 seconds 

	 Total run duration:   38 minutes 15.5804 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -283.4072457115752
231 of 300, maximal objective function=-177.446, time remaining: 20:29:29
Acceptance rates [%] =95.22
Count 1480

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005204058751671531 and: 0.00012836151787909937

Albedo ice, snow and firn: 0.29712621970798947 , 0.8322661617090586 and 0.6440572596327948

RRR mult factor is: 0.6623067353132595

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 24.8717 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 291.1054420271942; R-squared: 0.1645892330061953
	 Time required to write restart and output files:    3 minutes 50.3329 seconds 

	 Total run duration:   38 minutes 31.4142 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -284.15638578239276
232 of 300, maximal objective function=-177.446, time remaining: 19:50:01
Acceptance rates [%] =95.24
Count 1481

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005567092233438792 and: 0.00012611953039551394

Albedo ice, snow and firn: 0.2994827636899637 , 0.833569547005695 and 0.6426959029194775

RRR mult factor is: 0.6618186482268305

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 26.9687 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 288.98316830268374; R-squared: 0.14219617164176712
	 Time required to write restart and output files:    3 minutes 51.8276 seconds 

	 Total run duration:   38 minutes 42.8655 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -273.5877747445931
233 of 300, maximal objective function=-177.446, time remaining: 19:10:37
Acceptance rates [%] =95.26
Count 1482

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005218600569827333 and: 0.000143962558198899

Albedo ice, snow and firn: 0.31259025493612697 , 0.8332134051380999 and 0.6449325481360108

RRR mult factor is: 0.6569647946091112

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.0496 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 290.92880510389534; R-squared: 0.15155482451400254
	 Time required to write restart and output files:    3 minutes 52.3822 seconds 

	 Total run duration:   39 minutes 5.42696 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -279.51228431073883
234 of 300, maximal objective function=-177.446, time remaining: 18:31:20
Acceptance rates [%] =95.28
Count 1483

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005477697440198887 and: 0.00015192893533287226

Albedo ice, snow and firn: 0.3249710302732948 , 0.8148017848392556 and 0.6353758404079702

RRR mult factor is: 0.6515815237749372

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.9539 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 289.0906956318813; R-squared: 0.1920133087106766
	 Time required to write restart and output files:    3 minutes 49.655 seconds 

	 Total run duration:   38 minutes 25.5757 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -283.4500805641465
235 of 300, maximal objective function=-177.446, time remaining: 17:51:51
Acceptance rates [%] =95.3
Count 1484

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005474594627953789 and: 0.00016455383366957782

Albedo ice, snow and firn: 0.3394698226706227 , 0.8060255570712512 and 0.6438988009943497

RRR mult factor is: 0.6550045278181276

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 27.0722 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 305.4408725816088; R-squared: 0.1732751206668705
	 Time required to write restart and output files:    3 minutes 52.313 seconds 

	 Total run duration:   38 minutes 23.3696 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -299.46914136905167
236 of 300, maximal objective function=-177.446, time remaining: 17:12:23
Acceptance rates [%] =95.32
Count 1485

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005566410957310051 and: 0.00016916806378794352

Albedo ice, snow and firn: 0.3357373808634209 , 0.7951849144173572 and 0.6470137011835746

RRR mult factor is: 0.6627767847928815

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 27.1978 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 313.33401892013796; R-squared: 0.16654592932352807
	 Time required to write restart and output files:    3 minutes 50.6812 seconds 

	 Total run duration:   38 minutes 51.616 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.4151622370409
237 of 300, maximal objective function=-177.446, time remaining: 16:33:02
Acceptance rates [%] =95.34
Count 1486

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005429078734769046 and: 0.00015882399954893428

Albedo ice, snow and firn: 0.34550654899450695 , 0.7907475139044056 and 0.6462199307245

RRR mult factor is: 0.667842677088667

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 32.4644 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 318.25009171119467; R-squared: 0.15393842976345615
	 Time required to write restart and output files:    3 minutes 51.0497 seconds 

	 Total run duration:   38 minutes 49.2542 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -311.00529744910773
238 of 300, maximal objective function=-177.446, time remaining: 15:53:41
Acceptance rates [%] =95.36
Count 1487

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0054977877480897695 and: 0.00015737480608325275

Albedo ice, snow and firn: 0.3569164222530133 , 0.7862941184632247 and 0.6468349477685821

RRR mult factor is: 0.6685238755722801

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 28.003 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 305.2463722917289; R-squared: 0.21001197235994373
	 Time required to write restart and output files:    3 minutes 52.0961 seconds 

	 Total run duration:   38 minutes 48.0129 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -303.62184377722343
239 of 300, maximal objective function=-177.446, time remaining: 15:14:21
Acceptance rates [%] =95.38
Count 1488

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0054220718926587565 and: 0.00015533854806202028

Albedo ice, snow and firn: 0.3552209919792852 , 0.7897271209477297 and 0.6240130804493096

RRR mult factor is: 0.6692563754468359

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 30.4545 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 317.90712496726627; R-squared: 0.16595342987341916
	 Time required to write restart and output files:    3 minutes 51.6985 seconds 

	 Total run duration:   38 minutes 51.5299 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -313.3835502812209
240 of 300, maximal objective function=-177.446, time remaining: 14:35:01
Acceptance rates [%] =95.4
Count 1489

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005701789489177784 and: 0.00014633605415175117

Albedo ice, snow and firn: 0.35121646405665924 , 0.7935658523000754 and 0.6304336074776365

RRR mult factor is: 0.6688649678402276

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 35.0527 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 321.1150280799689; R-squared: 0.14675840363244874
	 Time required to write restart and output files:    3 minutes 51.125 seconds 

	 Total run duration:   38 minutes 59.2295 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -312.89557170309706
241 of 300, maximal objective function=-177.446, time remaining: 13:55:43
Acceptance rates [%] =95.42
Count 1490

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005749167713818815 and: 0.00013525502075672883

Albedo ice, snow and firn: 0.3444888859333518 , 0.7843101596532193 and 0.6329552046737771

RRR mult factor is: 0.6668979173886013

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.7129 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 336.8401465617219; R-squared: 0.11362696313295308
	 Time required to write restart and output files:    3 minutes 50.3538 seconds 

	 Total run duration:   38 minutes 45.2302 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -323.09587680685405
242 of 300, maximal objective function=-177.446, time remaining: 13:16:22
Acceptance rates [%] =95.44
Count 1491

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005371951178654225 and: 0.00013400390715063992

Albedo ice, snow and firn: 0.3517253853335917 , 0.7864399890376237 and 0.6181030158335362

RRR mult factor is: 0.6722394929841724

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.9933 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 342.15446875580693; R-squared: 0.09911705972610335
	 Time required to write restart and output files:    3 minutes 51.0532 seconds 

	 Total run duration:   38 minutes 16.8823 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -325.75693259287215
243 of 300, maximal objective function=-177.446, time remaining: 12:36:55
Acceptance rates [%] =95.45
Count 1492

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005269663511733641 and: 0.0001349685604853353

Albedo ice, snow and firn: 0.36197554092550605 , 0.7843688358986179 and 0.631240434815511

RRR mult factor is: 0.6664939242031331

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 21.1883 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 338.19712860587794; R-squared: 0.11030939123702052
	 Time required to write restart and output files:    3 minutes 50.1485 seconds 

	 Total run duration:   38 minutes 41.019 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -323.9941333581503
244 of 300, maximal objective function=-177.446, time remaining: 11:57:34
Acceptance rates [%] =95.47
Count 1493

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005349285645839315 and: 0.0001298753851203128

Albedo ice, snow and firn: 0.3603383790533564 , 0.7864821850938538 and 0.6278743216956697

RRR mult factor is: 0.6637488040885968

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 25.6157 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 335.9574545367303; R-squared: 0.1148307168736276
	 Time required to write restart and output files:    3 minutes 47.6387 seconds 

	 Total run duration:   38 minutes 35.1345 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -322.5916441959468
245 of 300, maximal objective function=-177.446, time remaining: 11:18:12
Acceptance rates [%] =95.49
Count 1494

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005579679296167792 and: 9.451104345284849e-05

Albedo ice, snow and firn: 0.3499804715005343 , 0.7793128130619342 and 0.6234102204004304

RRR mult factor is: 0.6563465256914417

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 11.0431 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 345.4911466487171; R-squared: 0.09913822619454442
	 Time required to write restart and output files:    3 minutes 50.0802 seconds 

	 Total run duration:   38 minutes 18.9566 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -329.2688390006903
246 of 300, maximal objective function=-177.446, time remaining: 10:38:47
Acceptance rates [%] =95.51
Count 1495

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005739428737599072 and: 8.667240282135985e-05

Albedo ice, snow and firn: 0.3366688506956874 , 0.7858001916827873 and 0.6380547028011287

RRR mult factor is: 0.6559783292178322

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.1063 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 343.9007427648039; R-squared: 0.09649430410380311
	 Time required to write restart and output files:    3 minutes 50.8906 seconds 

	 Total run duration:   38 minutes 29.4182 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -327.073442087065
247 of 300, maximal objective function=-177.446, time remaining: 09:59:24
Acceptance rates [%] =95.53
Count 1496

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005804055759612721 and: 5.802623480048616e-05

Albedo ice, snow and firn: 0.3383049458244706 , 0.7738145554990028 and 0.6346881902930832

RRR mult factor is: 0.6510635634430509

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 13.0204 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 413.77653481262155; R-squared: 0.10192098880901718
	 Time required to write restart and output files:    3 minutes 50.5791 seconds 

	 Total run duration:   38 minutes 24.1892 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -404.1180415001443
248 of 300, maximal objective function=-177.446, time remaining: 09:20:01
Acceptance rates [%] =95.14
Count 1497

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005453132955664464 and: 5.1961608004082905e-05

Albedo ice, snow and firn: 0.33983197898562734 , 0.7925246388067073 and 0.6280005150127422

RRR mult factor is: 0.6525753195940026

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.2283 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 339.1047060177942; R-squared: 0.10886482113821468
	 Time required to write restart and output files:    3 minutes 50.1023 seconds 

	 Total run duration:   38 minutes 39.8827 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -323.88996559655135
249 of 300, maximal objective function=-177.446, time remaining: 08:40:42
Acceptance rates [%] =95.16
Count 1498

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005535459683540983 and: 5.848817497596987e-05

Albedo ice, snow and firn: 0.3428647304635746 , 0.7900618107838678 and 0.6362594997099387

RRR mult factor is: 0.6552056235354022

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 19.0881 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 341.9189339779904; R-squared: 0.10070047218479504
	 Time required to write restart and output files:    3 minutes 51.1766 seconds 

	 Total run duration:   38 minutes 44.1999 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -326.1558809492351
250 of 300, maximal objective function=-177.446, time remaining: 08:01:24
Acceptance rates [%] =95.18
Count 1499

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005126088367462229 and: 7.593009403458872e-05

Albedo ice, snow and firn: 0.3523911106028183 , 0.7909131986512892 and 0.64489123962732

RRR mult factor is: 0.6552669518829656

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 10.3246 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 338.86232130064377; R-squared: 0.10635382881567718
	 Time required to write restart and output files:    3 minutes 50.2699 seconds 

	 Total run duration:   38 minutes 34.5509 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -323.608137814224
251 of 300, maximal objective function=-177.446, time remaining: 07:22:04
Acceptance rates [%] =95.2
Count 1500

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005261786323181459 and: 6.953121658375329e-05

Albedo ice, snow and firn: 0.3562539636746903 , 0.7869597109721465 and 0.6468381419092256

RRR mult factor is: 0.6550641271593871

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.8555 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 341.7032502900714; R-squared: 0.09980012462117074
	 Time required to write restart and output files:    3 minutes 49.0511 seconds 

	 Total run duration:   38 minutes 24.4326 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -326.0974427996927
252 of 300, maximal objective function=-177.446, time remaining: 06:42:42
Acceptance rates [%] =95.22
Count 1501

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005121420350431179 and: 9.059944405868387e-05

Albedo ice, snow and firn: 0.3532071440562244 , 0.8023199177659264 and 0.6385341082768464

RRR mult factor is: 0.6527701622184569

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 28.1275 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 320.9834223330628; R-squared: 0.12699280346476635
	 Time required to write restart and output files:    3 minutes 51.8618 seconds 

	 Total run duration:   38 minutes 51.2457 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -307.9676500064558
253 of 300, maximal objective function=-177.446, time remaining: 06:03:26
Acceptance rates [%] =95.24
Count 1502

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005090411882239788 and: 6.906740382780317e-05

Albedo ice, snow and firn: 0.3582863422398358 , 0.8049201589069407 and 0.6486038687663972

RRR mult factor is: 0.6560942257489107

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 45.4075 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 302.98153585681723; R-squared: 0.1372327580074326
	 Time required to write restart and output files:    3 minutes 49.3731 seconds 

	 Total run duration:   39 minutes 5.80421 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -289.2538439502627
254 of 300, maximal objective function=-177.446, time remaining: 05:24:13
Acceptance rates [%] =95.26
Count 1503

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005112471592561884 and: 6.0112032654798173e-05

Albedo ice, snow and firn: 0.36782486557708605 , 0.8158443644462586 and 0.6370166782563946

RRR mult factor is: 0.6467225866595295

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 47.4339 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 304.57404605726714; R-squared: 0.12851638969544027
	 Time required to write restart and output files:    3 minutes 48.6691 seconds 

	 Total run duration:   39 minutes 7.32183 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -289.87302155662326
255 of 300, maximal objective function=-177.446, time remaining: 04:45:00
Acceptance rates [%] =95.28
Count 1504

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005070390441722365 and: 4.615739327821231e-05

Albedo ice, snow and firn: 0.3572107594424803 , 0.8016651379944211 and 0.6433176378291167

RRR mult factor is: 0.6402115311169474

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.7595 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 326.29101821302334; R-squared: 0.12617626606399981
	 Time required to write restart and output files:    3 minutes 50.5981 seconds 

	 Total run duration:   38 minutes 34.2295 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -312.6575323599417
256 of 300, maximal objective function=-177.446, time remaining: 04:05:41
Acceptance rates [%] =95.29
Count 1505

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005138440285771053 and: 4.3317084545343313e-05

Albedo ice, snow and firn: 0.347674269279148 , 0.8113260760600738 and 0.6419657409743581

RRR mult factor is: 0.6409197555761525

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.6562 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 306.8874817498609; R-squared: 0.1267848068636757
	 Time required to write restart and output files:    3 minutes 49.618 seconds 

	 Total run duration:   38 minutes 33.4963 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -292.08347264096085
257 of 300, maximal objective function=-177.446, time remaining: 03:26:23
Acceptance rates [%] =95.31
Count 1506

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005562661393138221 and: 3.7241848620352244e-05

Albedo ice, snow and firn: 0.3605211176396502 , 0.810829234801192 and 0.6470716747977399

RRR mult factor is: 0.6448627593025839

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 17.943 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 308.60187121323435; R-squared: 0.12371170000778721
	 Time required to write restart and output files:    3 minutes 52.3002 seconds 

	 Total run duration:   38 minutes 37.243 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -292.32140408368576
258 of 300, maximal objective function=-177.446, time remaining: 02:47:06
Acceptance rates [%] =95.33
Count 1507

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005568375753402271 and: 2.4757043490875845e-05

Albedo ice, snow and firn: 0.3820221215523042 , 0.8080214217549062 and 0.6410580851567881

RRR mult factor is: 0.6504092868163909

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 24.1106 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 300.2655006393239; R-squared: 0.18168946237629494
	 Time required to write restart and output files:    3 minutes 50.7546 seconds 

	 Total run duration:   38 minutes 0.725714 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -296.6336500030555
259 of 300, maximal objective function=-177.446, time remaining: 02:07:43
Acceptance rates [%] =95.35
Count 1508

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005644621709598255 and: 2.425354876067625e-05

Albedo ice, snow and firn: 0.3818417056165991 , 0.8125418715358392 and 0.6386639663772582

RRR mult factor is: 0.6513310829466544

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 18.1184 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 304.9778767401417; R-squared: 0.1340857117746176
	 Time required to write restart and output files:    3 minutes 49.5973 seconds 

	 Total run duration:   38 minutes 20.977 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -291.06406353397875
260 of 300, maximal objective function=-177.446, time remaining: 01:28:24
Acceptance rates [%] =95.37
Count 1509

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005918195569802436 and: 8.637294981765264e-06

Albedo ice, snow and firn: 0.376742912807529 , 0.832904559346017 and 0.63394843700175

RRR mult factor is: 0.647994300647054

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 31.212 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 258.7638516114334; R-squared: 0.1289659598394523
	 Time required to write restart and output files:    3 minutes 51.3591 seconds 

	 Total run duration:   38 minutes 49.1768 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -238.96770219914637
261 of 300, maximal objective function=-177.446, time remaining: 00:49:09
Acceptance rates [%] =95.38
Count 1510

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005886896647842194 and: 4.024822328502575e-07

Albedo ice, snow and firn: 0.37932978778974596 , 0.8169217140748544 and 0.6242427702142287

RRR mult factor is: 0.6534652170245717

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 14.2436 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 310.45092748749863; R-squared: 0.12616989157231986
	 Time required to write restart and output files:    3 minutes 50.9082 seconds 

	 Total run duration:   38 minutes 33.7086 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -295.05642640473064
262 of 300, maximal objective function=-177.446, time remaining: 00:09:53
Acceptance rates [%] =95.4
Count 1511

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005473043047071487 and: 1.413182850926826e-05

Albedo ice, snow and firn: 0.36790931740364596 , 0.8261825941614565 and 0.6259325510253652

RRR mult factor is: 0.6369707058891965

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 22.8234 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 309.0024139701608; R-squared: 0.12139379021733844
	 Time required to write restart and output files:    3 minutes 52.8453 seconds 

	 Total run duration:   38 minutes 45.7613 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -292.62719532632025
263 of 300, maximal objective function=-177.446, time remaining: 23:30:38
Acceptance rates [%] =95.42
Count 1512

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005776834304915825 and: 2.1892681424845654e-05

Albedo ice, snow and firn: 0.36905858208469566 , 0.823162106915558 and 0.6264340255626242

RRR mult factor is: 0.6414990975902944

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 12.4169 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 304.23920168082645; R-squared: 0.13042799462538562
	 Time required to write restart and output files:    3 minutes 51.3559 seconds 

	 Total run duration:   38 minutes 34.5507 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -288.34423357413874
264 of 300, maximal objective function=-177.446, time remaining: 22:51:22
Acceptance rates [%] =95.44
Count 1513

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0053787605800788936 and: 2.4345792103693006e-06

Albedo ice, snow and firn: 0.37460822431064017 , 0.8222865171072038 and 0.6321828540723948

RRR mult factor is: 0.6418681626726714

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 20.717 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 300.7697041197961; R-squared: 0.13784087014833404
	 Time required to write restart and output files:    3 minutes 48.6509 seconds 

	 Total run duration:   38 minutes 27.0475 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -285.98257037481284
265 of 300, maximal objective function=-177.446, time remaining: 22:12:06
Acceptance rates [%] =95.45
Count 1514

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005392198322783504 and: 5.216672917005189e-06

Albedo ice, snow and firn: 0.36181332500284863 , 0.8326598729355269 and 0.6267533075676547

RRR mult factor is: 0.6430051369002308

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 16.5324 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 252.03562403230822; R-squared: 0.12498877461688701
	 Time required to write restart and output files:    3 minutes 51.8086 seconds 

	 Total run duration:   38 minutes 31.4182 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -229.6288569621184
266 of 300, maximal objective function=-177.446, time remaining: 21:32:50
Acceptance rates [%] =95.47
Count 1515

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005030542999052316 and: 1.060404387528355e-06

Albedo ice, snow and firn: 0.3641391668540728 , 0.8542541758590664 and 0.6270947334388568

RRR mult factor is: 0.6500873237312508

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 42.9917 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 218.30055380075208; R-squared: 0.09002689794625895
	 Time required to write restart and output files:    3 minutes 51.2079 seconds 

	 Total run duration:   39 minutes 1.934 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -190.8883429182596
267 of 300, maximal objective function=-177.446, time remaining: 20:53:39
Acceptance rates [%] =95.49
Count 1516

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00506470888468962 and: 1.9909240113228358e-05

Albedo ice, snow and firn: 0.3513357695333643 , 0.8502462019534466 and 0.6415990106840881

RRR mult factor is: 0.6481756013708745

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 53.03 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 218.26202729505155; R-squared: 0.0895968171966098
	 Time required to write restart and output files:    3 minutes 50.6955 seconds 

	 Total run duration:   39 minutes 16.788 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -189.91650775176058
268 of 300, maximal objective function=-177.446, time remaining: 20:14:29
Acceptance rates [%] =95.51
Count 1517

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005262502983558608 and: 1.6617098681612852e-06

Albedo ice, snow and firn: 0.34454685672930857 , 0.845261302219679 and 0.6286951310956475

RRR mult factor is: 0.6464213687038172

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 39.4245 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 241.0911795937993; R-squared: 0.10377621912443821
	 Time required to write restart and output files:    3 minutes 51.5047 seconds 

	 Total run duration:   39 minutes 26.9189 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -213.89393463633834
269 of 300, maximal objective function=-177.446, time remaining: 19:35:20
Acceptance rates [%] =95.15
Count 1518

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005176282928532138 and: 2.6927634825725307e-05

Albedo ice, snow and firn: 0.3429273443362373 , 0.8547697926507385 and 0.6366380892699843

RRR mult factor is: 0.649266784189777

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=57.00 GB, workers=19/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 55.4824 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 221.9057549569673; R-squared: 0.08916958381552832
	 Time required to write restart and output files:    3 minutes 47.3412 seconds 

	 Total run duration:   39 minutes 3.48651 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -194.38357788125595
270 of 300, maximal objective function=-177.446, time remaining: 18:56:09
Acceptance rates [%] =95.17
Count 1519

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005365897356186496 and: 1.780569677037843e-05

Albedo ice, snow and firn: 0.3479345940709418 , 0.8582222065891486 and 0.6299132100103516

RRR mult factor is: 0.6545642197001887

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 2.72188 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 216.14565871000877; R-squared: 0.08838344625406548
	 Time required to write restart and output files:    3 minutes 51.1826 seconds 

	 Total run duration:   39 minutes 22.9421 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -188.44134761770246
271 of 300, maximal objective function=-177.446, time remaining: 18:17:00
Acceptance rates [%] =95.19
Count 1520

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005097907563716098 and: 6.0205170860640954e-05

Albedo ice, snow and firn: 0.3431733266795007 , 0.856054330607871 and 0.6166576904665336

RRR mult factor is: 0.6575197191339898

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 15.0452 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 221.32697845204933; R-squared: 0.0881601220575858
	 Time required to write restart and output files:    3 minutes 51.189 seconds 

	 Total run duration:   39 minutes 26.6248 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -192.4687572283076
272 of 300, maximal objective function=-177.446, time remaining: 17:37:50
Acceptance rates [%] =95.2
Count 1521

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0050416879442373545 and: 4.832238979333209e-05

Albedo ice, snow and firn: 0.33075826703959743 , 0.8708905032238254 and 0.6027160126129536

RRR mult factor is: 0.6520410990703812

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 7.07047 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 179.62558168823662; R-squared: 0.14447267055528998
	 Time required to write restart and output files:    3 minutes 50.7361 seconds 

	 Total run duration:   39 minutes 30.33 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -165.28827082585346
273 of 300, maximal objective function=-165.288, time remaining: 16:58:42
Acceptance rates [%] =95.22
Count 1522

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0052644716417194716 and: 6.377148030179959e-05

Albedo ice, snow and firn: 0.34466331147040036 , 0.8692672867251011 and 0.6147508031001879

RRR mult factor is: 0.6497282431837319

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 4.83903 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 187.22232665159723; R-squared: 0.11111432011120007
	 Time required to write restart and output files:    3 minutes 51.553 seconds 

	 Total run duration:   39 minutes 32.2043 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -163.68487419667858
274 of 300, maximal objective function=-163.685, time remaining: 16:19:33
Acceptance rates [%] =95.24
Count 1523

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0052504658523726015 and: 5.968784253740013e-05

Albedo ice, snow and firn: 0.3602057211567198 , 0.8612161731105962 and 0.6414909133967871

RRR mult factor is: 0.6467686713229776

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 14.8158 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 191.08073222698087; R-squared: 0.13262701293960327
	 Time required to write restart and output files:    3 minutes 50.4472 seconds 

	 Total run duration:   39 minutes 3.1409 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -169.21251463805848
275 of 300, maximal objective function=-163.685, time remaining: 15:40:21
Acceptance rates [%] =95.26
Count 1524

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0054189764673978034 and: 9.476250476204287e-05

Albedo ice, snow and firn: 0.37354806443536936 , 0.8656568968190971 and 0.6431433098468375

RRR mult factor is: 0.6440086819127737

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 5.05212 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 171.66187421616735; R-squared: 0.16170974501113375
	 Time required to write restart and output files:    3 minutes 52.3682 seconds 

	 Total run duration:   39 minutes 30.7594 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -154.69282714327426
276 of 300, maximal objective function=-154.693, time remaining: 15:01:12
Acceptance rates [%] =95.27
Count 1525

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.0051399580092900835 and: 7.969683105431597e-05

Albedo ice, snow and firn: 0.3610934861130627 , 0.8475771166201912 and 0.6477119827064185

RRR mult factor is: 0.6488185333258534

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 49.6205 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 214.56470376143002; R-squared: 0.11438465314173638
	 Time required to write restart and output files:    3 minutes 50.178 seconds 

	 Total run duration:   39 minutes 3.3664 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -189.22948799101087
277 of 300, maximal objective function=-154.693, time remaining: 14:22:01
Acceptance rates [%] =95.29
Count 1526

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005315079558791205 and: 5.833191800401403e-05

Albedo ice, snow and firn: 0.361487038012745 , 0.8659221920377442 and 0.644964495085045

RRR mult factor is: 0.6435359688663521

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 7.80944 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 187.19408783376224; R-squared: 0.1085388183832156
	 Time required to write restart and output files:    3 minutes 50.4674 seconds 

	 Total run duration:   39 minutes 28.6566 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -162.8907259759263
278 of 300, maximal objective function=-154.693, time remaining: 13:42:51
Acceptance rates [%] =95.31
Count 1527

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005184893606826376 and: 3.493588161697003e-05

Albedo ice, snow and firn: 0.3750359575836903 , 0.8571660227746458 and 0.6294342020698844

RRR mult factor is: 0.6377630555861633

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 55.8598 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 202.7072125586733; R-squared: 0.16012028201122908
	 Time required to write restart and output files:    3 minutes 51.9309 seconds 

	 Total run duration:   39 minutes 16.3863 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -186.03963327223425
279 of 300, maximal objective function=-154.693, time remaining: 13:03:40
Acceptance rates [%] =95.32
Count 1528

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00524966608614132 and: 4.568914149643396e-05

Albedo ice, snow and firn: 0.39215561438546076 , 0.8614404516359917 and 0.6248805658868549

RRR mult factor is: 0.634106825660488

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 4.28626 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 202.6981974283986; R-squared: 0.139059110642708
	 Time required to write restart and output files:    3 minutes 50.2795 seconds 

	 Total run duration:   39 minutes 9.99293 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -180.9716577914729
280 of 300, maximal objective function=-154.693, time remaining: 12:24:29
Acceptance rates [%] =95.34
Count 1529

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005558671442569186 and: 3.232724431600301e-05

Albedo ice, snow and firn: 0.3958327050654633 , 0.8832753832502765 and 0.6130471183244215

RRR mult factor is: 0.6305715386987566

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 12.1819 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 180.74279376922004; R-squared: 0.08594025232111745
	 Time required to write restart and output files:    3 minutes 50.9488 seconds 

	 Total run duration:   39 minutes 24.9008 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -158.77324364323104
281 of 300, maximal objective function=-154.693, time remaining: 11:45:19
Acceptance rates [%] =95.36
Count 1530

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005426808305642997 and: 2.289865768914705e-05

Albedo ice, snow and firn: 0.39677749231288273 , 0.8699727850372213 and 0.6177714695592897

RRR mult factor is: 0.6393177678787004

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 56.8258 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 192.22373937055343; R-squared: 0.11527247579403842
	 Time required to write restart and output files:    3 minutes 48.6766 seconds 

	 Total run duration:   39 minutes 13.4685 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -169.52381761756695
282 of 300, maximal objective function=-154.693, time remaining: 11:06:08
Acceptance rates [%] =95.37
Count 1531

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005552972620193879 and: 3.017950421991274e-05

Albedo ice, snow and firn: 0.39871272144335085 , 0.8706519653167314 and 0.6183527927173254

RRR mult factor is: 0.63212312176067

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 5.26073 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 198.6628868739784; R-squared: 0.11424874002236801
	 Time required to write restart and output files:    3 minutes 49.8488 seconds 

	 Total run duration:   39 minutes 28.8378 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -175.09198201956238
283 of 300, maximal objective function=-154.693, time remaining: 10:26:58
Acceptance rates [%] =95.39
Count 1532

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00570045941778173 and: 4.602077812916284e-05

Albedo ice, snow and firn: 0.39701548599206615 , 0.871180931593152 and 0.6174489238470661

RRR mult factor is: 0.6344453506771857

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 58.4413 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 205.25921278776062; R-squared: 0.11175411740388204
	 Time required to write restart and output files:    3 minutes 47.5503 seconds 

	 Total run duration:   39 minutes 8.33311 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -179.7518815950531
284 of 300, maximal objective function=-154.693, time remaining: 09:47:47
Acceptance rates [%] =95.41
Count 1533

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005631917327523196 and: 3.7128017641706686e-05

Albedo ice, snow and firn: 0.3981522576466868 , 0.8564742480892129 and 0.5940680171845036

RRR mult factor is: 0.6305926038477149

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 32.586 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 231.00047276226758; R-squared: 0.141429110547325
	 Time required to write restart and output files:    3 minutes 51.1794 seconds 

	 Total run duration:   38 minutes 56.2206 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -211.79554072186866
285 of 300, maximal objective function=-154.693, time remaining: 09:08:35
Acceptance rates [%] =95.42
Count 1534

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005501381238860204 and: 4.57950013014947e-05

Albedo ice, snow and firn: 0.3906203889937657 , 0.8693970953841991 and 0.6114002509114306

RRR mult factor is: 0.632189711288294

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=57.00 GB, workers=19/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 0.149071 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 202.50512416581176; R-squared: 0.10028913546762824
	 Time required to write restart and output files:    3 minutes 48.3471 seconds 

	 Total run duration:   38 minutes 56.6442 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -174.77588866444893
286 of 300, maximal objective function=-154.693, time remaining: 08:29:24
Acceptance rates [%] =95.44
Count 1535

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005502243763374194 and: 2.9160375597812166e-05

Albedo ice, snow and firn: 0.3700566934664555 , 0.8760077380628024 and 0.6335984183548883

RRR mult factor is: 0.6317807177318786

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   15 minutes 11.3766 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 175.8312655498563; R-squared: 0.08400465774506138
	 Time required to write restart and output files:    3 minutes 48.8138 seconds 

	 Total run duration:   40 minutes 20.8404 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -157.4881457599678
287 of 300, maximal objective function=-154.693, time remaining: 07:50:15
Acceptance rates [%] =95.45
Count 1536

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005320038346611827 and: 3.267742776983954e-05

Albedo ice, snow and firn: 0.3744214377388725 , 0.8742383033292502 and 0.6328985151254329

RRR mult factor is: 0.6316723771174755

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 11.9691 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 169.71547259213514; R-squared: 0.12298555960205015
	 Time required to write restart and output files:    3 minutes 52.1669 seconds 

	 Total run duration:   39 minutes 36.1762 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -157.20515015969116
288 of 300, maximal objective function=-154.693, time remaining: 07:11:05
Acceptance rates [%] =95.47
Count 1537

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005142035037967615 and: 4.182310268193365e-05

Albedo ice, snow and firn: 0.3681553655635097 , 0.8568289153102641 and 0.62169152818253

RRR mult factor is: 0.6344117112063434

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=117.00 GB, workers=39/200, jobs=2/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   13 minutes 57.8616 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 190.33280976093246; R-squared: 0.18838738532773522
	 Time required to write restart and output files:    3 minutes 50.089 seconds 

	 Total run duration:   39 minutes 13.6646 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -179.59352625803075
289 of 300, maximal objective function=-154.693, time remaining: 06:31:54
Acceptance rates [%] =95.49
Count 1538

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005171621628743511 and: 4.690966241355197e-05

Albedo ice, snow and firn: 0.3662126117928032 , 0.8631580862273466 and 0.620137590986628

RRR mult factor is: 0.6353978823539795

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 6.98157 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 192.54097620002864; R-squared: 0.11010840607532651
	 Time required to write restart and output files:    3 minutes 51.7796 seconds 

	 Total run duration:   39 minutes 24.6143 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -168.05506156289024
290 of 300, maximal objective function=-154.693, time remaining: 05:52:43
Acceptance rates [%] =95.5
Count 1539

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005211075705536267 and: 5.377765371987003e-05

Albedo ice, snow and firn: 0.3624244275851192 , 0.8792481721600948 and 0.6318342909988992

RRR mult factor is: 0.6303726358435847

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 14.9263 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 167.6214598552114; R-squared: 0.12113809147576152
	 Time required to write restart and output files:    3 minutes 48.7654 seconds 

	 Total run duration:   39 minutes 23.8229 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -157.28553199223214
291 of 300, maximal objective function=-154.693, time remaining: 05:13:32
Acceptance rates [%] =95.52
Count 1540

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005593225486970651 and: 6.132645402497131e-05

Albedo ice, snow and firn: 0.37144907908235547 , 0.8882528701636812 and 0.6480489524659974

RRR mult factor is: 0.6320907596523059

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 25.7487 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 170.1413626326798; R-squared: 0.0919295601360076
	 Time required to write restart and output files:    3 minutes 51.5693 seconds 

	 Total run duration:   39 minutes 46.0971 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -160.05664218295493
292 of 300, maximal objective function=-154.693, time remaining: 04:34:21
Acceptance rates [%] =95.53
Count 1541

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005572499456368333 and: 8.002061814028498e-05

Albedo ice, snow and firn: 0.3597528204579492 , 0.8741992517592582 and 0.6400134484583689

RRR mult factor is: 0.6302848422909404

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/200, jobs=1/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 14.1697 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 177.13041974169428; R-squared: 0.1172292193578271
	 Time required to write restart and output files:    3 minutes 48.5108 seconds 

	 Total run duration:   39 minutes 31.8796 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -156.06068996194114
293 of 300, maximal objective function=-154.693, time remaining: 03:55:10
Acceptance rates [%] =95.55
Count 1542

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005407015622514151 and: 8.459142772735709e-05

Albedo ice, snow and firn: 0.3642727712653079 , 0.8777605443923433 and 0.6476288201158908

RRR mult factor is: 0.6301625017204919

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 14.7669 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 175.86910370264522; R-squared: 0.07902965198479832
	 Time required to write restart and output files:    3 minutes 50.7995 seconds 

	 Total run duration:   39 minutes 29.3635 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -154.60164767557873
294 of 300, maximal objective function=-154.602, time remaining: 03:15:59
Acceptance rates [%] =95.56
Count 1543

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005342989596476174 and: 9.461628986931094e-05

Albedo ice, snow and firn: 0.36101231179605253 , 0.8893687512874959 and 0.6437688519001525

RRR mult factor is: 0.6301660759093323

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 25.1217 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 170.73083279106535; R-squared: 0.08813964040067666
	 Time required to write restart and output files:    3 minutes 48.195 seconds 

	 Total run duration:   39 minutes 32.5242 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -154.16442648114804
295 of 300, maximal objective function=-154.164, time remaining: 02:36:47
Acceptance rates [%] =95.58
Count 1544

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005526604344858719 and: 9.979604501474384e-05

Albedo ice, snow and firn: 0.3610898614973925 , 0.8793788243023993 and 0.6487658806142286

RRR mult factor is: 0.6342602664155613

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 16.1661 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 175.16591942920707; R-squared: 0.08024526329032065
	 Time required to write restart and output files:    5 minutes 53.7556 seconds 

	 Total run duration:   41 minutes 45.1165 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -152.90939506899963
296 of 300, maximal objective function=-152.909, time remaining: 01:57:37
Acceptance rates [%] =95.59
Count 1545

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005455776935053722 and: 8.87185182058654e-05

Albedo ice, snow and firn: 0.37053848024207187 , 0.8737485504765446 and 0.6437747002204973

RRR mult factor is: 0.6377980207664553

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 19.3163 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 171.9877203857419; R-squared: 0.10535379736330776
	 Time required to write restart and output files:    5 minutes 52.1822 seconds 

	 Total run duration:   41 minutes 43.6296 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -152.9733479182856
297 of 300, maximal objective function=-152.909, time remaining: 01:18:26
Acceptance rates [%] =95.61
Count 1546

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005511981325375006 and: 6.698983421188607e-05

Albedo ice, snow and firn: 0.3690497944140717 , 0.8735656791542521 and 0.643602463211219

RRR mult factor is: 0.6395987957475809

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=177.00 GB, workers=59/200, jobs=3/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 11.5221 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 168.29485715512547; R-squared: 0.1310620623242298
	 Time required to write restart and output files:    5 minutes 48.6654 seconds 

	 Total run duration:   41 minutes 22.7983 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -154.18827639493264
298 of 300, maximal objective function=-152.909, time remaining: 00:39:13
Acceptance rates [%] =95.62
Count 1547

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.005568919697860239 and: 5.2801558623263124e-05

Albedo ice, snow and firn: 0.3733860114998694 , 0.8583181335390951 and 0.6438820565059773

RRR mult factor is: 0.6402941217946579

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/200, jobs=0/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 7.35976 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 183.31567617485584; R-squared: 0.1539882127793913
	 Time required to write restart and output files:    5 minutes 52.0825 seconds 

	 Total run duration:   41 minutes 32.1175 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -164.93724967557569
299 of 300, maximal objective function=-152.909, time remaining: 00:00:00
Acceptance rates [%] =95.64
Count 1548

 Maximum available time interval from 1982-10-01T00:00 until 2019-09-30T23:00. Time steps: 324336 


--------------------------------------------------------------
	 Integration from 1998-10-01T00:00 to 2019-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

#--------------------------------------#

Starting run with lapse rates: -0.00539041442497015 and: 2.1206600204437414e-05

Albedo ice, snow and firn: 0.36868245738222877 , 0.8540220046715138 and 0.6457255756909676

RRR mult factor is: 0.6410613059629465

#--------------------------------------#
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.9:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/200, jobs=4/10)
<Client: scheduler='tcp://192.168.1.9:8786' processes=0 cores=0>
999 200 4
	 Time required to do calculations:   14 minutes 0.384204 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 198.56196069863876; R-squared: 0.12100839747063513
	 Time required to write restart and output files:    5 minutes 49.7783 seconds 

	 Total run duration:   41 minutes 10.2271 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------
RMSE is:  -174.18825666056782
300 of 300, maximal objective function=-152.909, time remaining: 23:20:46
Acceptance rates [%] =95.65

*** Final SPOTPY summary ***
Total Duration: 708592.41 seconds
Total Repetitions: 300
Maximal objective value: -152.909
Corresponding parameter setting:
lr_T: -0.0055266
lr_RRR: 9.9796e-05
lr_RH: 0.00403746
RRR_factor: 0.63426
alb_ice: 0.36109
alb_snow: 0.879379
alb_firn: 0.648766
albedo_aging: 19.9795
albedo_depth: 4.82658
******************************

Best parameter set:
lr_T=-0.005527, lr_RRR=9.98e-05, lr_RH=0.004036, RRR_factor=0.6343, alb_ice=0.361, alb_snow=0.8794, alb_firn=0.649, albedo_aging=19.98, albedo_depth=4.83
Best param: [(-0.005527, 9.98e-05, 0.004036, 0.6343, 0.361, 0.8794, 0.649, 19.98, 4.83)]
Run number 295 has the highest objectivefunction with: -152.9
