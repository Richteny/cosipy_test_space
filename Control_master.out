20
No temperature lapse rate used in AWS2cosipy.
No precipitation lapse rate used in AWS2cosipy.

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/240, jobs=0/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 28.3817 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 197.9886385980653; R-squared: 0.5050597745068955
	 Time required to write restart and output files:    3 minutes 15.585 seconds 

	 Total run duration:   28 minutes 43.3802 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/240, jobs=0/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 30.5092 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 192.10917288569394; R-squared: 0.5085728392195553
	 Time required to write restart and output files:    3 minutes 17.7615 seconds 

	 Total run duration:   57 minutes 59.9088 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 42.9416 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 173.79751145433585; R-squared: 0.5015928529849404
	 Time required to write restart and output files:    3 minutes 15.6952 seconds 

	 Total run duration:   87 minutes 19.8669 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 33.8183 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 168.5076585590943; R-squared: 0.5029080980238837
	 Time required to write restart and output files:    3 minutes 13.3776 seconds 

	 Total run duration:  116 minutes 29.2767 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 29.382 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 191.87172703294502; R-squared: 0.5210066157181978
	 Time required to write restart and output files:    3 minutes 21.3801 seconds 

	 Total run duration:  145 minutes 38.1782 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 26.5962 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 185.88760718794342; R-squared: 0.5249274345926487
	 Time required to write restart and output files:    3 minutes 15.9641 seconds 

	 Total run duration:  174 minutes 38.1794 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 38.8325 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 167.7054132670171; R-squared: 0.5176337562948317
	 Time required to write restart and output files:    3 minutes 15.6877 seconds 

	 Total run duration:  203 minutes 49.9469 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/240, jobs=0/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 46.1507 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 162.1154795021676; R-squared: 0.5217419811095186
	 Time required to write restart and output files:    3 minutes 14.7265 seconds 

	 Total run duration:  233 minutes 11.9502 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 44.4731 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 171.01291670684407; R-squared: 0.5473292540533606
	 Time required to write restart and output files:    3 minutes 22.3132 seconds 

	 Total run duration:  262 minutes 44.6878 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 24.6022 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 164.80974871755217; R-squared: 0.5546180580228349
	 Time required to write restart and output files:    3 minutes 14.7859 seconds 

	 Total run duration:  291 minutes 55.2903 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 57.7891 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 145.78552108429446; R-squared: 0.5435513325390082
	 Time required to write restart and output files:    3 minutes 21.5711 seconds 

	 Total run duration:  321 minutes 51.2132 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   16 minutes 45.3425 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 139.98121156056516; R-squared: 0.5483783852945084
	 Time required to write restart and output files:    3 minutes 16.573 seconds 

	 Total run duration:  355 minutes 5.75749 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   17 minutes 10.6103 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 164.94921446033044; R-squared: 0.5666598381642132
	 Time required to write restart and output files:    3 minutes 17.2626 seconds 

	 Total run duration:  388 minutes 54.228 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 41.9908 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 159.2522800871489; R-squared: 0.5705228417847055
	 Time required to write restart and output files:    3 minutes 15.8859 seconds 

	 Total run duration:  418 minutes 7.7588 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/240, jobs=0/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 29.387 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 140.5286596148449; R-squared: 0.561488150767086
	 Time required to write restart and output files:    3 minutes 12.103 seconds 

	 Total run duration:  446 minutes 48.8023 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 47.9738 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 135.78638611840952; R-squared: 0.5642929816910055
	 Time required to write restart and output files:    3 minutes 14.3308 seconds 

	 Total run duration:  475 minutes 51.701 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 37.8275 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 153.25370094354344; R-squared: 0.5744011012390065
	 Time required to write restart and output files:    3 minutes 16.3503 seconds 

	 Total run duration:  504 minutes 49.4597 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 27.146 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 147.86137730857675; R-squared: 0.5760406381017261
	 Time required to write restart and output files:    3 minutes 13.6306 seconds 

	 Total run duration:  533 minutes 21.4404 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 38.1359 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 130.82233826945472; R-squared: 0.5490027477408114
	 Time required to write restart and output files:    3 minutes 12.932 seconds 

	 Total run duration:  562 minutes 28.0854 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 47.2344 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 126.71591443896197; R-squared: 0.5515354715267031
	 Time required to write restart and output files:    3 minutes 13.3541 seconds 

	 Total run duration:  591 minutes 22.0487 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 29.5736 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 148.7482396766968; R-squared: 0.5889763833463718
	 Time required to write restart and output files:    3 minutes 14.4168 seconds 

	 Total run duration:  619 minutes 58.3028 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=207.00 GB, workers=69/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 27.959 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 143.6358152968394; R-squared: 0.5904211474561677
	 Time required to write restart and output files:    3 minutes 13.5218 seconds 

	 Total run duration:  648 minutes 32.2977 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=0 B, workers=0/240, jobs=0/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 44.8233 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 127.10476828711865; R-squared: 0.5638064107318027
	 Time required to write restart and output files:    3 minutes 20.6011 seconds 

	 Total run duration:  677 minutes 45.9293 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0061 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 29.5524 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 123.54155141540566; R-squared: 0.5637950817056671
	 Time required to write restart and output files:    3 minutes 21.9802 seconds 

	 Total run duration:  706 minutes 43.4117 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 35.5073 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 197.10355491148024; R-squared: 0.5056825388435701
	 Time required to write restart and output files:    3 minutes 17.4044 seconds 

	 Total run duration:  736 minutes 0.612482 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 56.1262 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 191.16219321627003; R-squared: 0.509710302004409
	 Time required to write restart and output files:    3 minutes 19.7213 seconds 

	 Total run duration:  765 minutes 34.4617 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 45.7838 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 172.7197701177749; R-squared: 0.5017880025883146
	 Time required to write restart and output files:    3 minutes 19.5763 seconds 

	 Total run duration:  795 minutes 1.80156 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 53.8196 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 167.5015112780318; R-squared: 0.5026487228371026
	 Time required to write restart and output files:    3 minutes 16.4181 seconds 

	 Total run duration:  824 minutes 39.486 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 41.5702 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 190.8995243801077; R-squared: 0.5217568018417297
	 Time required to write restart and output files:    3 minutes 15.6938 seconds 

	 Total run duration:  854 minutes 2.5126 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 45.331 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 184.93361503431626; R-squared: 0.5269321824544622
	 Time required to write restart and output files:    3 minutes 25.0923 seconds 

	 Total run duration:  883 minutes 41.7829 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 47.2899 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 166.93660831745777; R-squared: 0.5172244967215205
	 Time required to write restart and output files:    3 minutes 18.2331 seconds 

	 Total run duration:  913 minutes 5.57253 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0013
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   13 minutes 9.49626 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 161.30581708435753; R-squared: 0.5216051999652855
	 Time required to write restart and output files:    3 minutes 14.6775 seconds 

	 Total run duration:  942 minutes 53.403 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 35.6969 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 169.9895000660019; R-squared: 0.5489051439597766
	 Time required to write restart and output files:    3 minutes 15.4205 seconds 

	 Total run duration:  972 minutes 7.98538 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 28.4987 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 163.74050063501318; R-squared: 0.5552357904284003
	 Time required to write restart and output files:    3 minutes 23.3414 seconds 

	 Total run duration: 1001 minutes 27.5936 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 34.0988 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 144.59082363837837; R-squared: 0.5439782693169545
	 Time required to write restart and output files:    3 minutes 22.0669 seconds 

	 Total run duration: 1030 minutes 46.2653 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 44.954 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 138.88507713234617; R-squared: 0.549861224378268
	 Time required to write restart and output files:    3 minutes 17.3377 seconds 

	 Total run duration: 1060 minutes 27.9146 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 31.4162 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 163.6562608138488; R-squared: 0.5690754266698292
	 Time required to write restart and output files:    3 minutes 24.596 seconds 

	 Total run duration: 1089 minutes 43.8261 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 35.0483 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 158.6423947203612; R-squared: 0.5707759276292331
	 Time required to write restart and output files:    3 minutes 14.7619 seconds 

	 Total run duration: 1118 minutes 55.7109 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 37.0493 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 139.83494154940595; R-squared: 0.5605264557361422
	 Time required to write restart and output files:    3 minutes 16.319 seconds 

	 Total run duration: 1148 minutes 4.52877 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0009
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 38.6106 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 134.73592553918448; R-squared: 0.5646185420902596
	 Time required to write restart and output files:    3 minutes 14.7703 seconds 

	 Total run duration: 1177 minutes 17.3385 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=240.00 GB, workers=80/240, jobs=4/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 28.1482 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 152.7321884406263; R-squared: 0.5731104600760645
	 Time required to write restart and output files:    3 minutes 13.5371 seconds 

	 Total run duration: 1206 minutes 21.7274 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 19.6313 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 147.61803291903166; R-squared: 0.5733818810643978
	 Time required to write restart and output files:    3 minutes 15.0456 seconds 

	 Total run duration: 1235 minutes 5.86118 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=120.00 GB, workers=40/240, jobs=2/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 36.5257 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 130.54871762507625; R-squared: 0.54527378770013
	 Time required to write restart and output files:    3 minutes 20.0957 seconds 

	 Total run duration: 1264 minutes 12.7848 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 44.4154 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 127.13568540365786; R-squared: 0.5420471581595798
	 Time required to write restart and output files:    3 minutes 14.9945 seconds 

	 Total run duration: 1293 minutes 14.7408 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=180.00 GB, workers=60/240, jobs=3/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 30.0472 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 147.99102474345256; R-squared: 0.5879863456426939
	 Time required to write restart and output files:    3 minutes 15.7509 seconds 

	 Total run duration: 1322 minutes 20.1418 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 35.3717 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 143.55472518106646; R-squared: 0.5867877492478837
	 Time required to write restart and output files:    3 minutes 14.9291 seconds 

	 Total run duration: 1351 minutes 31.7937 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
#!/bin/bash

#!/usr/bin/env bash
#SBATCH -J WoEraAbr
#SBATCH -n 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=56G
#SBATCH -t 00:30:00
#SBATCH --qos=short
#SBATCH --output=Output_nodes.output
#SBATCH --error=Error_nodes.err
#SBATCH --time=1-00:00:00
#SBATCH --account=morsanat
JOB_ID=${SLURM_JOB_ID%;*}



/programs/anaconda/2019.07/bin/python -m distributed.cli.dask_worker tcp://192.168.1.11:8786 --nthreads 0 --nprocs 20 --memory-limit 3.00GB --name WoEraAbr--${JOB_ID}-- --death-timeout 60 --local-directory logs/dask-worker-space

You are using SLURM!

SLURMCluster(cores=0, memory=0 B, workers=0/0, jobs=0/0)
--------------------------------------------------------------
	 Starting clients and submit jobs ... 

-------------------------------------------------------------- 

SLURMCluster(cores=0, memory=60.00 GB, workers=20/240, jobs=1/12)
<Client: scheduler='tcp://192.168.1.11:8786' processes=0 cores=0>
999 240 4
	 Time required to do calculations:   12 minutes 29.803 seconds 



--------------------------------------------------------------
Write results ...
-------------------------------------------------------------- 

TSLA Observed vs. Modelled RMSE: 127.02931017249739; R-squared: 0.5576515910119539
	 Time required to write restart and output files:    3 minutes 16.4911 seconds 

	 Total run duration: 1380 minutes 51.8502 seconds 

--------------------------------------------------------------
	 SIMULATION WAS SUCCESSFUL
--------------------------------------------------------------

 Maximum available time interval from 1999-10-01T00:00 until 2018-09-30T23:00. Time steps: 166560 


--------------------------------------------------------------
	 Integration from 1999-10-01T00:00 to 2018-09-30T00:00
--------------------------------------------------------------

--------------------------------------------------------------
Checking input data .... 

Temperature data (T2) ... ok 
Relative humidity data (RH2) ... ok 
Shortwave data (G) ... ok 
Wind velocity data (U2) ... ok 
Precipitation data (RRR) ... ok 
Pressure data (PRES) ... ok 
Incoming longwave data (LWin) ... ok 
Please check the input data, its seems they are out of range Lwin MAX: 365.04 MIN: 86.83 


 Glacier gridpoints: 287 




Output dataset ... ok
Restart ddataset ... ok 

--------------------------------------------------------------

Starting run with lapse rates: -0.0057 and: 0.0005
