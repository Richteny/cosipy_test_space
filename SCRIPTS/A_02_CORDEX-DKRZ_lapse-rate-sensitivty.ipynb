{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c16455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import salem\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "import sys\n",
    "\n",
    "plt.rcParams['font.size'] = 22\n",
    "\n",
    "if 'win' in sys.platform:\n",
    "    path = \"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/\"\n",
    "    aws_path = \"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/AWS_Obleitner/\"\n",
    "else:\n",
    "    import geopandas as gpd\n",
    "    path = \"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/\"\n",
    "    aws_path = \"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/AWS_Obleitner/\"\n",
    "extra = \"CORDEX-DKRZ/\"\n",
    "\n",
    "def fix_netcdf_dates(ds):\n",
    "    ds = ds.sel(time=slice(\"1999-01-01\",\"2010-01-01T01:00\"))\n",
    "\n",
    "    ## Shift values by +1 and add new timestamp\n",
    "    missing_time = ds.isel(time= [-1]) #sel using list to preserve time dimension\n",
    "    if missing_time.time != np.datetime64(\"2010-01-01T00:00\"):\n",
    "        # replace time value with next day\n",
    "        timestep = np.datetime64(\"2010-01-01T00:00\")\n",
    "        missing_time[\"time\"] = (\"time\", np.reshape(timestep, (1)))\n",
    "        fixed = xr.concat([ds, missing_time], dim=\"time\", data_vars=\"minimal\", coords=\"minimal\")\n",
    "        return fixed\n",
    "    else:\n",
    "        return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47db7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load every single field individually\n",
    "prec = xr.open_dataset(path+extra+\"cosmo_1999_2010_1h_RRR.nc\")\n",
    "snowfall = xr.open_dataset(path+extra+\"cosmo_1999_2010_1h_SNOWFALL-CSPYfix.nc\")\n",
    "pressure = xr.open_dataset(path+extra+\"cosmo_1999_2010_1h_PRESlinint.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d65bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First load AWS data\n",
    "aws_lower = pd.read_csv(aws_path+\"Fix_HEFlower_01102003_24102004.csv\", parse_dates=True, index_col=\"time\")\n",
    "aws_upper = pd.read_csv(aws_path+\"Fix_HEFupper_01102003_24102004.csv\", parse_dates=True, index_col=\"time\")\n",
    "aws_upper['T'] = aws_upper['T']+273.15\n",
    "aws_lower['T'] = aws_lower['T']+273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proj and outlines\n",
    "if 'win' in sys.platform:\n",
    "    dsr = salem.open_metum_dataset(\"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/for_Niklas/cosmo_2009_1h.nc\")\n",
    "    try:\n",
    "        hef = gpd.read_file(\"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Static/RGI6/HEF_RGI6.shp\")\n",
    "    except:\n",
    "        hef = salem.read_shapefile(\"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Static/RGI6/HEF_RGI6.shp\")\n",
    "else:\n",
    "    dsr = salem.open_metum_dataset(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/for_Niklas/cosmo_2009_1h.nc\")\n",
    "    hef = gpd.read_file(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Static/RGI6/HEF_RGI6.shp\")\n",
    "reproj_hef = hef.to_crs(dsr.pyproj_srs)\n",
    "bounds = reproj_hef.bounds\n",
    "print(bounds)\n",
    "\n",
    "centroid = reproj_hef.dissolve().centroid\n",
    "print(centroid)\n",
    "\n",
    "idx_lat = np.argmin(np.abs(prec.rlat.values  - centroid.y.values))\n",
    "idx_lon = np.argmin(np.abs(prec.rlon.values  - centroid.x.values))\n",
    "print(idx_lat, idx_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7393148",
   "metadata": {},
   "outputs": [],
   "source": [
    "## figure out how to get solid precipitation from AWSs\n",
    "#sfc\n",
    "snowcover = aws_lower[['sfc']].join(aws_upper[['sfc']], lsuffix='low', rsuffix='high')\n",
    "snowcover['adj_sfclow'] = snowcover['sfclow'] - snowcover['sfclow'][0]\n",
    "snowcover['adj_sfchigh'] = snowcover['sfchigh'] - snowcover['sfchigh'][0]\n",
    "print(snowcover)\n",
    "#get differences since its cumulative\n",
    "snowcover['incr_low'] =  snowcover['adj_sfclow'].diff()\n",
    "snowcover['incr_high'] =  snowcover['adj_sfchigh'].diff()\n",
    "    \n",
    "## Get only dates with positive increment in both\n",
    "snowcover['incr_high'].loc[snowcover['incr_high'] <= 0] = np.nan\n",
    "snowcover['incr_low'].loc[snowcover['incr_low'] <= 0] = np.nan\n",
    "\n",
    "aws_lower['SF'] = snowcover['incr_low']\n",
    "aws_upper['SF'] = snowcover['incr_high']\n",
    "aws_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028692fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_comb = aws_lower[['T','RH','LWI','SF','SWI','P']].join(aws_upper[['T','RH','LWI','SF','SWI','P']], lsuffix='low', rsuffix='high')\n",
    "elev_diff = 3048 - 2640 \n",
    "print(elev_diff)\n",
    "\n",
    "##!! Note that we do not apply any corrections so far !!##\n",
    "aws_comb['lapse_t2m'] = (aws_comb['Thigh'] - aws_comb['Tlow']) / elev_diff\n",
    "aws_comb['lapse_rh'] = (aws_comb['RHhigh'] - aws_comb['RHlow']) / elev_diff\n",
    "aws_comb['lapse_lw'] = (aws_comb['LWIhigh'] - aws_comb['LWIlow']) / elev_diff\n",
    "#difference with NaN results in NaNs\n",
    "aws_comb['lapse_sf'] = (aws_comb['SFhigh'] - aws_comb['SFlow']) / elev_diff\n",
    "aws_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_sf = snowfall.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))\n",
    "box_size = 1\n",
    "cosmo_sf = cosmo_sf.isel(rlat= slice(idx_lat-box_size,idx_lat+box_size+1), rlon=slice(idx_lon-box_size, idx_lon+box_size+1))\n",
    "cosmo_sf\n",
    "#3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First quick check: compare snowfall snowfall - units both in [m]\n",
    "fig, axes = plt.subplots(2,1, sharex=True, figsize=(16,9), dpi=300)\n",
    "axes[0].plot(cosmo_sf['time'], cosmo_sf['SNOW'].mean(dim=['rlat','rlon']), label=\"COSMO-DKRZ Snowfall [m]\")\n",
    "axes[1].plot(snowcover['incr_low'], label=\"SFC increment at lower AWS\")\n",
    "axes[1].plot(snowcover['incr_high'], label=\"SFC increment at upper AWS\")\n",
    "for ax in axes.flatten():\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 0.18)\n",
    "    ax.set_ylabel(\"Snowfall [m]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load REL HUM\n",
    "relhum = xr.open_dataset(path+extra+\"cosmo_1998-2010_1h_hurs.nc\") #values in 0-100\n",
    "relhumfix = fix_netcdf_dates(relhum)\n",
    "print(relhumfix.time)\n",
    "\n",
    "## Load tas\n",
    "tas = xr.open_dataset(path+extra+\"cosmo_1998-2010_1h_tas.nc\")\n",
    "tasfix = fix_netcdf_dates(tas)\n",
    "print(tasfix.time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given at every half-hour - time_bnds from 00h to 01h -> values should be assigned to next hour\n",
    "time_range = pd.date_range(\"1998-11-01T01:00:00\", \"2010-01-01\", freq=\"1H\")\n",
    "clt = xr.open_dataset(path+extra+\"cosmo_1998-2010_1h_clt.nc\") #values in 0-100\n",
    "clt['time'] = ('time', time_range)\n",
    "cltfix = fix_netcdf_dates(clt)\n",
    "print(cltfix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given at every half-hour - time_bnds from 00h to 01h -> values should be assigned to next hour\n",
    "time_range = pd.date_range(\"1998-11-01T01:00:00\", \"2010-01-01\", freq=\"1H\")\n",
    "## Load Inc SW and CloudCover\n",
    "incsw = xr.open_dataset(path+extra+\"cosmo_1998-2010_1h_rsds.nc\")\n",
    "incsw['time'] = ('time', time_range)\n",
    "incswfix = fix_netcdf_dates(incsw)\n",
    "print(incswfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "incsw = xr.open_dataset(path+extra+\"cosmo_1998-2010_1h_rsds.nc\")\n",
    "incsw['time'] = ('time', time_range)\n",
    "incsw.sel(time=slice(\"1999-01-01\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load static\n",
    "static = xr.open_dataset(path+extra+\"cosmo_1998-2010_fx_orog.nc\")\n",
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21310fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec['SNOWFALL'] = snowfall['SNOW'] #[in units m]  \n",
    "try:\n",
    "    prec['PRES'] = pressure['ps'] / 100 #Pa to hPa\n",
    "except:\n",
    "    prec['PRES'] = pressure['ps_fixed'] / 100 #Pa to hPa\n",
    "prec['RH2'] = relhumfix['hurs']\n",
    "prec['T2'] = tasfix['tas']\n",
    "prec['N'] = cltfix['clt']/100\n",
    "prec['orog'] = static['orog']\n",
    "prec['RAIN'] = prec['RRR'] - prec['SNOWFALL']/1000 #to kg/m2 == mm\n",
    "prec['G'] = incswfix['rsds']\n",
    "\n",
    "\n",
    "print(\"Assigned the data to a singular file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451eb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy polyfit to get linear regr slope\n",
    "def lin_regr(x,y):\n",
    "    #fit = np.polyfit(x,y,1)\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "    \n",
    "    #r_value ** 2 in case of simple linear regression is equal to coefficient of determination\n",
    "    return xr.DataArray(slope)\n",
    "\n",
    "def lin_regr_r2(x,y):\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    return xr.DataArray(r_value**2)\n",
    "\n",
    "\n",
    "\n",
    "## Load box size for lapse rates\n",
    "box_size=1\n",
    "\n",
    "def create_box_sized_ds(ds, box_size, centroid):\n",
    "    dsr_hef = ds.isel(rlat= slice(idx_lat-box_size,idx_lat+box_size+1), rlon=slice(idx_lon-box_size, idx_lon+box_size+1))\n",
    "    \n",
    "    print(f\"Using boxsize {box_size}, dataset consists of {len(dsr_hef.rlat) * len(dsr_hef.rlon)} grid cells.\")\n",
    "    \n",
    "    #calculate lapse rates\n",
    "    hsurf2 = dsr_hef.orog.values\n",
    "    hsurf2_new = np.expand_dims(hsurf2, axis=0)\n",
    "    hsurf2_new = np.repeat(hsurf2_new, len(dsr_hef.time.values), axis=0)\n",
    "    dsr_hef['OROG2'] = (('time','rlat','rlon'), hsurf2_new)\n",
    "\n",
    "    # get r2 as well and only apply lapse rate where clear relationship visible?\n",
    "\n",
    "    #combine dim into one\n",
    "    stack_ds = dsr_hef.stack(latlon=['rlat','rlon'])\n",
    "    \n",
    "    # calculate lapse rates over time\n",
    "    lr_t2m = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.T2,dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_rh2 = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.RH2,dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    #lr_lwin = xr.apply_ufunc(lin_regr, stack_ds.HSURF2, stack_ds.ATHB_S ,dask='parallelized',\n",
    "    #                         vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_clt = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.N ,dask='parallelized',\n",
    "                             vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_tp = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.RRR, dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    #lr_rain = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.RAIN, dask='parallelized',\n",
    "    #                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_sf = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.SNOWFALL, dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    \n",
    "    # calculate r2 values over time\n",
    "    \n",
    "    lr_t2m_r2 = xr.apply_ufunc(lin_regr_r2, stack_ds.OROG2, stack_ds.T2,dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_rh2_r2 = xr.apply_ufunc(lin_regr_r2, stack_ds.OROG2, stack_ds.RH2,dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    #lr_lwin = xr.apply_ufunc(lin_regr, stack_ds.HSURF2, stack_ds.ATHB_S ,dask='parallelized',\n",
    "    #                         vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_clt_r2 = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.N ,dask='parallelized',\n",
    "                            vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_tp_r2 = xr.apply_ufunc(lin_regr_r2, stack_ds.OROG2, stack_ds.RRR, dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    #lr_rain_r2 = xr.apply_ufunc(lin_regr, stack_ds.OROG2, stack_ds.RAIN, dask='parallelized',\n",
    "    #                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    lr_sf_r2 = xr.apply_ufunc(lin_regr_r2, stack_ds.OROG2, stack_ds.SNOWFALL, dask='parallelized',\n",
    "                        vectorize=True, input_core_dims=[['latlon'], ['latlon']])\n",
    "    \n",
    "    # Create single file at centroid from which to distribute using lapse rates \n",
    "    x_cords, y_cords = centroid.iloc[0].xy\n",
    "    x_cord = x_cords[0]\n",
    "    y_cord = y_cords[0]\n",
    "    print(x_cord, y_cord)\n",
    "\n",
    "    ds_closest = dsr_hef.sel(rlat=y_cord, rlon=x_cord, method='nearest')\n",
    "    # add lapse rates\n",
    "    ds_closest['lr_t2m'] = lr_t2m\n",
    "    ds_closest['lr_rh2'] = lr_rh2\n",
    "    ds_closest['lr_clt'] = lr_clt\n",
    "    #ds_closest['lr_rain'] = lr_rain\n",
    "    ds_closest['lr_tp'] = lr_tp \n",
    "    ds_closest['lr_sf'] = lr_sf\n",
    "    # add r2 scores\n",
    "    ds_closest['lr_t2m_r2'] = lr_t2m_r2\n",
    "    ds_closest['lr_rh2_r2'] = lr_rh2_r2\n",
    "    ds_closest['lr_clt_r2'] = lr_clt_r2\n",
    "    #ds_closest['lr_rain'] = lr_rain\n",
    "    ds_closest['lr_tp_r2'] = lr_tp_r2 \n",
    "    ds_closest['lr_sf_r2'] = lr_sf_r2\n",
    "\n",
    "    return ds_closest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_box1 = create_box_sized_ds(prec, box_size=1, centroid=centroid)\n",
    "ds_box2 = create_box_sized_ds(prec, box_size=2, centroid=centroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot mean diurnal cycles to ensure which time format files are in\n",
    "aws_comb['mean_t2m'] = aws_comb[['Tlow','Thigh']].mean(axis=1)\n",
    "mean_diurnal_aws = aws_comb.groupby(aws_comb.index.hour).mean()\n",
    "\n",
    "mean_diurnal_cosmo = ds_box1.groupby(ds_box1.time.dt.hour).mean()\n",
    "mean_diurnal_aws.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ebd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_comb_wintertime = aws_comb.loc[\"2003-10-26\":\"2004-03-28\"]\n",
    "print(aws_comb_wintertime.head(5))\n",
    "print(\"\\n---------------------------\")\n",
    "aws_comb_wintertime['new_time'] = aws_comb_wintertime.reset_index()['time'].dt.tz_localize('UTC').dt.tz_convert('Europe/Berlin')\n",
    "print(aws_comb_wintertime.new_time.head(5))\n",
    "winter_diurnal_aws = aws_comb_wintertime.groupby(aws_comb_wintertime.index.hour).mean()\n",
    "aws_comb_summertime = aws_comb.loc[\"2004-03-29\":\"2004-10-24\"]\n",
    "summer_diurnal_aws = aws_comb_summertime.groupby(aws_comb_summertime.index.hour).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb50249",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, sharex=True, figsize=(16,9), dpi=150)\n",
    "#ax.plot(mean_diurnal_aws.index, mean_diurnal_aws.Thigh, label=\"AWSmean\")\n",
    "ax[0].plot(mean_diurnal_aws.index, mean_diurnal_aws.SWIhigh, label=\"AWS SWin\")\n",
    "#ax.plot(winter_diurnal_aws.shift(1).index, winter_diurnal_aws.shift(1).SWIhigh, label=\"AWS SWI Winter\")\n",
    "#ax.plot(summer_diurnal_aws.shift(1).index, summer_diurnal_aws.shift(1).SWIhigh, label=\"AWS SWI Summer\")\n",
    "ax[0].plot(mean_diurnal_cosmo.hour, mean_diurnal_cosmo.G, label=\"COSMO SWin\")\n",
    "#ax.plot(mean_diurnal_cosmo.shift(hour=-1).hour, mean_diurnal_cosmo.shift(hour=-1).G, label=\"COSMO-1h\")\n",
    "#ax.plot(mean_diurnal_cosmo.shift(hour=-2).hour, mean_diurnal_cosmo.shift(hour=-2).T2, label=\"COSMO\")\n",
    "ax[0].set_xticks(np.arange(0,23+1))\n",
    "ax[0].set_ylabel(\"Inc. SW [Wm-2]\")\n",
    "#ax.grid()\n",
    "#ax.legend()\n",
    "\n",
    "ax[1].plot(mean_diurnal_aws.index, mean_diurnal_aws.Thigh-273.15, label=\"AWS T2M\")\n",
    "#ax.plot(winter_diurnal_aws.shift(1).index, winter_diurnal_aws.shift(1).SWIhigh, label=\"AWS SWI Winter\")\n",
    "#ax.plot(summer_diurnal_aws.shift(1).index, summer_diurnal_aws.shift(1).SWIhigh, label=\"AWS SWI Summer\")\n",
    "ax[1].plot(mean_diurnal_cosmo.hour, mean_diurnal_cosmo.T2-273.15, label=\"COSMO T2M\")\n",
    "ax[1].set_ylabel(\"2m air temp. [°C]\")\n",
    "\n",
    "for xs in ax:\n",
    "    xs.grid()\n",
    "    xs.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make files comparable\n",
    "cosmo_hef_box1 = ds_box1.isel(time=slice(None, -2)) #.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\")) # UTC to local time - but AWS data seems more in UTC time than COSMO does .. unclear about actual timestamp\n",
    "cosmo_hef_box2 = ds_box2.isel(time=slice(None, -2)) #.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\")) # UTC to local time\n",
    "cosmo_hef_box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot monthly lapse rates\n",
    "monthly_lr_box1 = cosmo_hef_box1[['lr_t2m','lr_t2m_r2']].resample(time=\"1MS\").mean()\n",
    "monthly_lr_box2 = cosmo_hef_box2[['lr_t2m','lr_t2m_r2']].resample(time=\"1MS\").mean()\n",
    "monthly_aws = aws_comb.resample(\"1MS\").mean()\n",
    "\n",
    "print(aws_comb['lapse_t2m'].mean())\n",
    "print(monthly_aws['lapse_t2m'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02443736",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First plot: compare monthly lapse rates\n",
    "fig, ax = plt.subplots(3,1, figsize=(16,9), dpi=300)\n",
    "ax[0].plot(monthly_aws.index, monthly_aws['lapse_t2m'], color=\"red\", marker='.', alpha=0.5, label=\"AWS\")\n",
    "ax[0].plot(monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\")).time, monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'],\n",
    "           marker='.', color=\"blue\",  alpha=0.5, label=\"COSMO 9-cell\")\n",
    "ax[0].plot(monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\")).time, monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'] - monthly_aws['lapse_t2m'],\n",
    "           marker='.', color=\"orange\", label=\"COSMO - AWS\", zorder=-1)\n",
    "ax[0].axhline(y=np.nanmean(monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'] - monthly_aws['lapse_t2m']), color=\"magenta\", linestyle=\"dashed\",label=\"Mean Bias °Cm$^{-1}$\")\n",
    "ax[0].axhline(y=-0.0065, color=\"black\", linestyle=\"dashed\",label=\"-0.0065 °Cm$^{-1}$\")\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"T2M Lapse Rates for: \" + \"9-cell-box\" + \" in °C/m\")\n",
    "ax[0].grid()\n",
    "\n",
    "r2 = r2_score(monthly_aws['lapse_t2m'], monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'])\n",
    "mae = mean_absolute_error(monthly_aws['lapse_t2m'], monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'])\n",
    "rmse = root_mean_squared_error(monthly_aws['lapse_t2m'],monthly_lr_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'])\n",
    "ax[0].annotate(\"R²: {},\\nMAE: {}°C/km,\\nRMSE: {}°C/km\".format(round(r2,2),round(mae*1000,4),round(rmse*1000,4)),\n",
    "             xy=(0.73,0.72), xycoords='axes fraction', fontsize=13)\n",
    "\n",
    "ax[1].plot(monthly_aws.index, monthly_aws['lapse_t2m'], color=\"red\",marker='.', alpha=0.5, label=\"AWS\")\n",
    "ax[1].plot(monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\")).time, monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'],\n",
    "           marker='.',color=\"green\", alpha=0.5, label=\"COSMO 25-cell\")\n",
    "ax[1].plot(monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\")).time, monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'] - monthly_aws['lapse_t2m'],\n",
    "           marker='.',color=\"orange\", label=\"COSMO - AWS\", zorder=-1)\n",
    "ax[1].axhline(y=np.nanmean(monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'] - monthly_aws['lapse_t2m']), color=\"magenta\", linestyle=\"dashed\",label=\"Mean Bias °Cm$^{-1}$\")\n",
    "ax[1].axhline(y=-0.0065, color=\"black\", linestyle=\"dashed\",label=\"-0.0065 °Cm$^{-1}$\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"T2M Lapse Rates for: \" + \"25-cell-box\" + \" in °C/m\")\n",
    "ax[1].grid()\n",
    "\n",
    "r2 = r2_score(monthly_aws['lapse_t2m'], monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'])\n",
    "mae = mean_absolute_error(monthly_aws['lapse_t2m'], monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'])\n",
    "rmse = root_mean_squared_error(monthly_aws['lapse_t2m'],monthly_lr_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))['lr_t2m'])\n",
    "ax[1].annotate(\"R²: {},\\nMAE: {}°C/m,\\nRMSE: {}°C/km\".format(round(r2,2),round(mae*1000,4),round(rmse*1000,4)),\n",
    "             xy=(0.73,0.72), xycoords='axes fraction', fontsize=13)\n",
    "\n",
    "ax[2].plot(monthly_lr_box1.time, monthly_lr_box1['lr_t2m'],marker='.', color=\"blue\",label=\"9-cell-box\")\n",
    "ax[2].plot(monthly_lr_box2.time, monthly_lr_box2['lr_t2m'],marker='.', color=\"green\",label=\"25-cell-box\")\n",
    "ax[2].axhline(y=-0.0065, color=\"black\", linestyle=\"dashed\",label=\"-0.0065 °Cm$^{-1}$\")\n",
    "ax[2].legend()\n",
    "ax[2].set_title(\"T2M Lapse Rates for: \" + \"9-cell-box and 25-cell-box\" + \" in °C/m\")\n",
    "ax[2].grid()\n",
    "ax[2].set_xticks(pd.date_range(\"1999-01-01\",\"2010-01-01T00:00:00\", freq=\"6MS\"))\n",
    "for label in ax[2].get_xticklabels():\n",
    "    label.set_rotation(45)\n",
    "\n",
    "x_axis_ticks = pd.date_range(\"2003-10-01\",\"2004-10-24T00:00:00\", freq=\"2M\")\n",
    "for axes in [ax[0], ax[1]]:\n",
    "    axes.set_xticks(x_axis_ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "debf8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hef_box1_crop = cosmo_hef_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))\n",
    "hef_box2_crop = cosmo_hef_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))\n",
    "\n",
    "dict_labels_9cell = {\n",
    "    \"lapse_t2m\": \"T2M Lapse Rates for: \" + \"9-cell-box\" + \" in °C m$^{-1}$\",\n",
    "    \"lapse_sf\": \"SF Lapse Rates for: \" + \"9-cell-box\" + \" in m m$^{-1}$\",\n",
    "    \"lapse_rh\": \"RH2 Lapse Rates for: \" + \"9-cell-box\" + \" in % m$^{-1}$\"\n",
    "    }\n",
    "\n",
    "dict_labels_25cell = {\n",
    "    \"lapse_t2m\": \"T2M Lapse Rates for: \" + \"25-cell-box\" + \" in °C m$^{-1}$\",\n",
    "    \"lapse_sf\": \"SF Lapse Rates for: \" + \"25-cell-box\" + \" in m m$^{-1}$\",\n",
    "    \"lapse_rh\": \"RH2 Lapse Rates for: \" + \"25-cell-box\" + \" in % m$^{-1}$\"\n",
    "    }\n",
    "\n",
    "dict_labels_both = {\n",
    "    \"lapse_t2m\": \"T2M Lapse Rates for: \" + \"9-cell-box and 25-cell-box\" + \" in °C m$^{-1}$\",\n",
    "    \"lapse_sf\": \"SF Lapse Rates for: \" + \"9-cell-box and 25-cell-box\" + \" in m m$^{-1}$\",\n",
    "    \"lapse_rh\": \"RH2 Lapse Rates for: \" + \"9-cell-box and 25-cell-box\" + \" in % m$^{-1}$\"\n",
    "    }\n",
    "\n",
    "dict_units = {\n",
    "    \"lapse_t2m\": \"°C m$^{-1}$\",\n",
    "    \"lapse_sf\": \"m m$^{-1}$\",\n",
    "    \"lapse_rh\": \"% m$^{-1}$\"\n",
    "    }\n",
    "\n",
    "dict_units_km = {\n",
    "    \"lapse_t2m\": \"K km⁻¹\",\n",
    "    \"lapse_sf\": \"m km⁻¹\",\n",
    "    \"lapse_rh\": \"% km⁻¹\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be7f73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- The Final Plotting Function ---\n",
    "def plot_lapse_rate_comparison(aws_comb, hef_box1_crop, hef_box2_crop, aws_var, cosmo_var,\n",
    "                             variable_name=\"T2M Lapse Rate\", r2_filter=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive 6-panel plot to compare COSMO model lapse rates\n",
    "    and optionally saves the figure to a file.\n",
    "    \"\"\"\n",
    "    scaling_factor = 1000.0\n",
    "    cosmo_time = hef_box1_crop.time\n",
    "    \n",
    "    aws_data_aligned = aws_comb[aws_var].reindex(cosmo_time, method='nearest') * scaling_factor\n",
    "\n",
    "    if r2_filter is None:\n",
    "        box1_data = hef_box1_crop[cosmo_var] * scaling_factor\n",
    "        box2_data = hef_box2_crop[cosmo_var] * scaling_factor\n",
    "    else:\n",
    "        print(f\"Applying R² filter >= {r2_filter}\")\n",
    "        box1_data = hef_box1_crop[cosmo_var].where(hef_box1_crop[cosmo_var + \"_r2\"] >= r2_filter) * scaling_factor\n",
    "        box2_data = hef_box2_crop[cosmo_var].where(hef_box2_crop[cosmo_var + \"_r2\"] >= r2_filter) * scaling_factor\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 3,\n",
    "        figsize=(24, 13),\n",
    "        dpi=300,\n",
    "        gridspec_kw={'width_ratios': [3, 1.5, 1.5]}\n",
    "    )\n",
    "    \n",
    "    plot_data = [\n",
    "        {'cosmo': box1_data, 'label': 'COSMO 9-cell', 'ax_row': axes[0], 'color': 'blue'},\n",
    "        {'cosmo': box2_data, 'label': 'COSMO 25-cell', 'ax_row': axes[1], 'color': 'green'}\n",
    "    ]\n",
    "\n",
    "    for item in plot_data:\n",
    "        cosmo_d = item['cosmo']\n",
    "        label = item['label']\n",
    "        ax_row = item['ax_row']\n",
    "\n",
    "        valid_mask = (~np.isnan(cosmo_d) & ~np.isnan(aws_data_aligned)).to_numpy()\n",
    "        aws_clean = aws_data_aligned[valid_mask]\n",
    "        cosmo_clean = cosmo_d.to_numpy()[valid_mask]\n",
    "        \n",
    "        unit_str = dict_units_km.get(aws_var, \"\")\n",
    "\n",
    "        ax = ax_row[0]\n",
    "        ax.plot(cosmo_time, aws_data_aligned, color='black', alpha=0.8, label='AWS', linewidth=2.0)\n",
    "        ax.plot(cosmo_time, cosmo_d, color=item['color'], alpha=0.7, label=label)\n",
    "        \n",
    "        if aws_var == \"lapse_t2m\":\n",
    "            ax.axhline(-6.5, color='orange', linestyle='--', label=f'Environm. Lapse Rate (-6.5 {unit_str})')\n",
    "        \n",
    "        ax.set_ylabel(f'{variable_name} ({unit_str})')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.legend(fontsize=18)\n",
    "        \n",
    "        locator = mdates.AutoDateLocator(minticks=5, maxticks=10)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        ax.xaxis.set_major_locator(locator)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        \n",
    "        ax = ax_row[1]\n",
    "        \n",
    "        xmax = max(aws_clean.max(), cosmo_clean.max())\n",
    "        \n",
    "        # Plot COSMO CDF\n",
    "        sorted_cosmo = np.sort(cosmo_clean)\n",
    "        y_cosmo = np.linspace(0, 1, len(cosmo_clean))\n",
    "        ax.plot(np.append(sorted_cosmo, xmax), np.append(y_cosmo, 1.0), color=item['color'], label=label, lw=2)\n",
    "\n",
    "        # Plot AWS CDF\n",
    "        sorted_aws = np.sort(aws_clean)\n",
    "        y_aws = np.linspace(0, 1, len(aws_clean))\n",
    "        ax.plot(np.append(sorted_aws, xmax), np.append(y_aws, 1.0), color='black', label='AWS', lw=2)\n",
    "        \n",
    "        ax.set_xlabel(f'Lapse Rate ({unit_str})')\n",
    "        ax.set_ylabel('Probability (%)')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        ax = ax_row[2]\n",
    "        xy = np.vstack([aws_clean, cosmo_clean])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        \n",
    "        idx = z.argsort()\n",
    "        aws_clean, cosmo_clean, z = aws_clean[idx], cosmo_clean[idx], z[idx]\n",
    "        \n",
    "        ax.scatter(aws_clean, cosmo_clean, c=z, s=20, alpha=0.6, cmap='viridis')\n",
    "        \n",
    "        lim_min = min(aws_clean.min(), cosmo_clean.min())\n",
    "        lim_max = max(aws_clean.max(), cosmo_clean.max())\n",
    "        lims = [lim_min, lim_max]\n",
    "        \n",
    "        ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "        ax.set_xlabel(f'AWS ({unit_str})')\n",
    "        ax.set_ylabel(f'{label} ({unit_str})')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_ylim(lims)\n",
    "\n",
    "        mean_bias = np.mean(cosmo_clean - aws_clean)\n",
    "        rmse = np.sqrt(mean_squared_error(aws_clean, cosmo_clean))\n",
    "        stats_text = f\"Mean Bias: {mean_bias:.3f} {unit_str}\\nRMSE: {rmse:.3f} {unit_str}\"\n",
    "        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=18,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    subplot_labels = ['a)', 'b)', 'c)', 'd)', 'e)', 'f)']\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.text(-0.11, 1.0, subplot_labels[i], transform=ax.transAxes, \n",
    "                fontsize=22, va='bottom', ha='left')\n",
    "\n",
    "    fig.tight_layout(pad=1.5)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        print(f\"Plot successfully saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Call the new plotting function ---\n",
    "print(\"--- Plotting without R² filter ---\")\n",
    "plot_lapse_rate_comparison(\n",
    "    aws_comb=aws_comb, \n",
    "    hef_box1_crop=hef_box1_crop, \n",
    "    hef_box2_crop=hef_box2_crop, \n",
    "    aws_var=\"lapse_t2m\", \n",
    "    cosmo_var=\"lr_t2m\",\n",
    "    save_path=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Call the new plotting function ---\n",
    "plot_lapse_rate_comparison(\n",
    "    aws_comb=aws_comb, \n",
    "    hef_box1_crop=hef_box1_crop, \n",
    "    hef_box2_crop=hef_box2_crop, \n",
    "    aws_var=\"lapse_t2m\", \n",
    "    cosmo_var=\"lr_t2m\",\n",
    "    r2_filter=0.7,\n",
    "    save_path=\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/lapse_rates_t2m.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910989eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lapse_rate_comparison(\n",
    "    aws_comb=aws_comb, \n",
    "    hef_box1_crop=hef_box1_crop, \n",
    "    hef_box2_crop=hef_box2_crop, \n",
    "    aws_var=\"lapse_sf\", \n",
    "    cosmo_var=\"lr_sf\",\n",
    "    variable_name=\"SF Lapse Rate\"\n",
    "    #r2_filter=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lapse_rate_comparison(\n",
    "    aws_comb=aws_comb, \n",
    "    hef_box1_crop=hef_box1_crop, \n",
    "    hef_box2_crop=hef_box2_crop, \n",
    "    aws_var=\"lapse_sf\", \n",
    "    cosmo_var=\"lr_sf\",\n",
    "    variable_name=\"SF Lapse Rate\",\n",
    "    r2_filter=0.7,\n",
    "    save_path=\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/lapse_rates_sf.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e253372",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lapse_rate_comparison(\n",
    "    aws_comb=aws_comb, \n",
    "    hef_box1_crop=hef_box1_crop, \n",
    "    hef_box2_crop=hef_box2_crop, \n",
    "    aws_var=\"lapse_rh\", \n",
    "    cosmo_var=\"lr_rh2\",\n",
    "    variable_name=\"RH2 Lapse Rate\"\n",
    "    #r2_filter=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lapse_rate_comparison(\n",
    "    aws_comb=aws_comb, \n",
    "    hef_box1_crop=hef_box1_crop, \n",
    "    hef_box2_crop=hef_box2_crop, \n",
    "    aws_var=\"lapse_rh\", \n",
    "    cosmo_var=\"lr_rh2\",\n",
    "    variable_name=\"RH2 Lapse Rate\",\n",
    "    r2_filter=0.7,\n",
    "    save_path=\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/lapse_rates_rh2.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f2c6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_hef_box1 = cosmo_hef_box1.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))\n",
    "cosmo_hef_box2 = cosmo_hef_box2.sel(time=slice(\"2003-10-01\",\"2004-10-24T00:00:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3612bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Daytime, nighttime\n",
    "joint_df_box1 = cosmo_hef_box1.to_dataframe().join(aws_comb)\n",
    "joint_df_box1['hour'] = joint_df_box1.index.hour\n",
    "joint_df_box2 = cosmo_hef_box2.to_dataframe().join(aws_comb)\n",
    "joint_df_box2['hour'] = joint_df_box2.index.hour\n",
    "joint_df_box1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bcdd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's proceed with box1 because so far there has been no clear merit to using a larger grid box?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e196fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## daytime 9 to 18 local time, nighttime 21 to 3am\n",
    "daytime_box1 = joint_df_box1.loc[joint_df_box1.hour.isin(np.arange(9,18+1,1))]\n",
    "nighttime_box1 = joint_df_box1.loc[joint_df_box1.hour.isin([21,22,23,0,1,2,3])]\n",
    "#\n",
    "daytime_box2 = joint_df_box2.loc[joint_df_box2.hour.isin(np.arange(9,18+1,1))]\n",
    "nighttime_box2 = joint_df_box2.loc[joint_df_box2.hour.isin([21,22,23,0,1,2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403688ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Histogram plot\n",
    "bins = np.linspace(-0.015, 0.015, 100)\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(16,9), dpi=300)\n",
    "ax[0].hist(joint_df_box1['lapse_t2m'], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[0].hist(joint_df_box1[\"lr_t2m\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[0].set_title(\"Full timeseries LR (°C/m)\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box1[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box1[\"lr_t2m\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "ax[0].axvline(-0.0065, color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "ax[1].hist(daytime_box1[\"lapse_t2m\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[1].hist(daytime_box1[\"lr_t2m\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[1].set_title(\"Daytime LR (°C/m)\")\n",
    "ax[1].axvline(-0.0065, color=\"black\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_box1[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_box1[\"lr_t2m\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "\n",
    "ax[2].hist(nighttime_box1[\"lapse_t2m\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[2].hist(nighttime_box1[\"lr_t2m\"], bins, alpha=0.5, label='COSMO 9-cell', color=\"blue\")\n",
    "ax[2].set_title(\"Nighttime LR (°C/m)\")\n",
    "ax[2].axvline(-0.0065, color=\"black\", linestyle=\"dashed\", label=\"-0.0065 °Cm$^{-1}$\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box1[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\", label=\"AWS Mean\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box1[\"lr_t2m\"]), color=\"deepskyblue\", linestyle=\"dashed\", label=\"COSMO Mean\")\n",
    "\n",
    "ax[2].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Histogram plot for box 2\n",
    "fig, ax = plt.subplots(3,1, figsize=(16,9), dpi=300)\n",
    "ax[0].hist(joint_df_box2['lapse_t2m'], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[0].hist(joint_df_box2[\"lr_t2m\"], bins, alpha=0.5, label='COSMO', color=\"green\")\n",
    "ax[0].set_title(\"Full timeseries LR (°C/m)\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box2[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box2[\"lr_t2m\"]), color=\"springgreen\", linestyle=\"dashed\")\n",
    "ax[0].axvline(-0.0065, color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "ax[1].hist(daytime_box2[\"lapse_t2m\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[1].hist(daytime_box2[\"lr_t2m\"], bins, alpha=0.5, label='COSMO', color=\"green\")\n",
    "ax[1].set_title(\"Daytime LR (°C/m)\")\n",
    "ax[1].axvline(-0.0065, color=\"black\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_box2[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_box2[\"lr_t2m\"]), color=\"springgreen\", linestyle=\"dashed\")\n",
    "\n",
    "ax[2].hist(nighttime_box2[\"lapse_t2m\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[2].hist(nighttime_box2[\"lr_t2m\"], bins, alpha=0.5, label='COSMO 25-cell', color=\"green\")\n",
    "ax[2].set_title(\"Nighttime LR (°C/m)\")\n",
    "ax[2].axvline(-0.0065, color=\"black\", linestyle=\"dashed\", label=\"-0.0065 °Cm$^{-1}$\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box2[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\", label=\"AWS Mean\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box2[\"lr_t2m\"]), color=\"springgreen\", linestyle=\"dashed\", label=\"COSMO Mean\")\n",
    "\n",
    "ax[2].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_box1 = joint_df_box1[['lapse_t2m','lr_t2m','lr_t2m_r2','hour']]\n",
    "t2m_box1 = t2m_box1.loc[t2m_box1['lr_t2m_r2'] > 0.7]\n",
    "\n",
    "## daytime 9 to 18 local time, nighttime 21 to 3am\n",
    "daytime_t2m_box1 = t2m_box1.loc[joint_df_box1.hour.isin(np.arange(9,18+1,1))]\n",
    "nighttime_t2m_box1 = t2m_box1.loc[joint_df_box1.hour.isin([21,22,23,0,1,2,3])]\n",
    "\n",
    "t2m_box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat histogram where r2 > 0.8\n",
    "fig, ax = plt.subplots(3,1, figsize=(16,9), dpi=300)\n",
    "ax[0].hist(t2m_box1['lapse_t2m'], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[0].hist(t2m_box1[\"lr_t2m\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[0].set_title(\"Full timeseries LR (°C/m), conditioned on R² > 0.7\")\n",
    "ax[0].axvline(np.nanmean(t2m_box1[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[0].axvline(np.nanmean(t2m_box1[\"lr_t2m\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "ax[0].axvline(-0.0065, color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "ax[1].hist(daytime_t2m_box1[\"lapse_t2m\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[1].hist(daytime_t2m_box1[\"lr_t2m\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[1].set_title(\"Daytime LR (°C/m)\")\n",
    "ax[1].axvline(-0.0065, color=\"black\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_t2m_box1[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_t2m_box1[\"lr_t2m\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "\n",
    "ax[2].hist(nighttime_t2m_box1[\"lapse_t2m\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[2].hist(nighttime_t2m_box1[\"lr_t2m\"], bins, alpha=0.5, label='COSMO 9-cell', color=\"blue\")\n",
    "ax[2].set_title(\"Nighttime LR (°C/m)\")\n",
    "ax[2].axvline(-0.0065, color=\"black\", linestyle=\"dashed\", label=\"-0.0065 °Cm$^{-1}$\")\n",
    "ax[2].axvline(np.nanmean(nighttime_t2m_box1[\"lapse_t2m\"]), color=\"darkred\", linestyle=\"dashed\", label=\"AWS Mean\")\n",
    "ax[2].axvline(np.nanmean(nighttime_t2m_box1[\"lr_t2m\"]), color=\"deepskyblue\", linestyle=\"dashed\", label=\"COSMO Mean\")\n",
    "\n",
    "ax[2].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42907d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat plots for snowfall\n",
    "## Add Histogram plot - not really helpful\n",
    "bins = np.linspace(-0.00001, 0.00001, 100)\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(16,9), dpi=300)\n",
    "ax[0].hist(joint_df_box1['lapse_sf'], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[0].hist(joint_df_box1[\"lr_sf\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[0].set_title(\"Full timeseries LR (m/m)\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box1[\"lapse_sf\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box1[\"lr_sf\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "\n",
    "ax[1].hist(daytime_box1[\"lapse_sf\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[1].hist(daytime_box1[\"lr_sf\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[1].set_title(\"Daytime LR (m/m)\")\n",
    "ax[1].axvline(np.nanmean(daytime_box1[\"lapse_sf\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_box1[\"lr_sf\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "\n",
    "ax[2].hist(nighttime_box1[\"lapse_sf\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[2].hist(nighttime_box1[\"lr_sf\"], bins, alpha=0.5, label='COSMO 9-cell', color=\"blue\")\n",
    "ax[2].set_title(\"Nighttime LR (m/m)\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box1[\"lapse_sf\"]), color=\"darkred\", linestyle=\"dashed\", label=\"AWS Mean\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box1[\"lr_sf\"]), color=\"deepskyblue\", linestyle=\"dashed\", label=\"COSMO Mean\")\n",
    "\n",
    "ax[2].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a98563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat plots for relative humidity\n",
    "## Add Histogram plot\n",
    "bins = np.linspace(-0.05, 0.05, 100)\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(16,9), dpi=300)\n",
    "ax[0].hist(joint_df_box1['lapse_rh'], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[0].hist(joint_df_box1[\"lr_rh2\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[0].set_title(\"Full timeseries LR (%/m)\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box1[\"lapse_rh\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[0].axvline(np.nanmean(joint_df_box1[\"lr_rh2\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "\n",
    "ax[1].hist(daytime_box1[\"lapse_rh\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[1].hist(daytime_box1[\"lr_rh2\"], bins, alpha=0.5, label='COSMO', color=\"blue\")\n",
    "ax[1].set_title(\"Daytime LR (%/m)\")\n",
    "ax[1].axvline(np.nanmean(daytime_box1[\"lapse_rh\"]), color=\"darkred\", linestyle=\"dashed\")\n",
    "ax[1].axvline(np.nanmean(daytime_box1[\"lr_rh2\"]), color=\"deepskyblue\", linestyle=\"dashed\")\n",
    "\n",
    "ax[2].hist(nighttime_box1[\"lapse_rh\"], bins, alpha=0.5, label='AWS', color=\"red\")\n",
    "ax[2].hist(nighttime_box1[\"lr_rh2\"], bins, alpha=0.5, label='COSMO 9-cell', color=\"blue\")\n",
    "ax[2].set_title(\"Nighttime LR (%/m)\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box1[\"lapse_rh\"]), color=\"darkred\", linestyle=\"dashed\", label=\"AWS Mean\")\n",
    "ax[2].axvline(np.nanmean(nighttime_box1[\"lr_rh2\"]), color=\"deepskyblue\", linestyle=\"dashed\", label=\"COSMO Mean\")\n",
    "\n",
    "ax[2].legend(loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
