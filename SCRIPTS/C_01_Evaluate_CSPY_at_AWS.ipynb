{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca144ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517eccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'win' in sys.platform:\n",
    "    path = \"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Output/aws_comp/bestfiles/\"\n",
    "    aws_path = \"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/AWS_Obleitner/\"\n",
    "else:\n",
    "    path = \"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Output/aws_comp/bestfiles/\"\n",
    "    aws_path = \"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/AWS_Obleitner/\"\n",
    "    \n",
    "aws_lower = pd.read_csv(aws_path+\"Fix_HEFlower_01102003_24102004.csv\", parse_dates=True, index_col=\"time\")\n",
    "aws_lower = aws_lower.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "aws_upper = pd.read_csv(aws_path+\"Fix_HEFupper_01102003_24102004.csv\", parse_dates=True, index_col=\"time\")\n",
    "aws_upper = aws_upper.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "aws_upper['T'] = aws_upper['T']+273.15\n",
    "aws_lower['T'] = aws_lower['T']+273.15\n",
    "aws_upper['sfc'] = aws_upper['sfc'] - aws_upper['sfc'][0]\n",
    "aws_lower['sfc'] =  aws_lower['sfc'] - aws_lower['sfc'][0]\n",
    "print(aws_lower)\n",
    "\n",
    "aws_lower_copy = aws_lower.copy()\n",
    "aws_upper_copy = aws_upper.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302d8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_lower_u2 = aws_lower[['Dir', 'U']]\n",
    "aws_upper_u2 = aws_upper[['Dir', 'U']]\n",
    "\n",
    "cos_u2_lower = pd.read_csv(path+\"cosipy_at_loweraws_grid_merged-U2.csv\", parse_dates=True, index_col=\"time\")\n",
    "cos_u2_lower = cos_u2_lower.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "if (cos_u2_lower.std(axis=1) > 1e-9).any():\n",
    "    print(\"Warning. Windspeed not the same between runs\")\n",
    "cos_u2_lower = cos_u2_lower.median(axis=1)\n",
    "\n",
    "    \n",
    "cos_u2_upper = pd.read_csv(path+\"cosipy_at_upperaws_grid_merged-U2.csv\", parse_dates=True, index_col=\"time\")\n",
    "cos_u2_upper = cos_u2_upper.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "if (cos_u2_upper.std(axis=1) > 1e-9).any():\n",
    "    print(\"Warning. Windspeed not the same between runs\")\n",
    "cos_u2_upper = cos_u2_upper.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e4cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Short windspeed analysis.\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(15, 10),\n",
    "    sharex=True,\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "dir_labels = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "\n",
    "def direction_to_category(deg):\n",
    "    shifted_deg = (deg + 22.5) % 360\n",
    "    return np.floor(shifted_deg / 45)\n",
    "\n",
    "# Apply this function to the data\n",
    "aws_lower_u2['Dir_Cat'] = direction_to_category(aws_lower_u2['Dir'])\n",
    "aws_upper_u2['Dir_Cat'] = direction_to_category(aws_upper_u2['Dir'])\n",
    "\n",
    "# Create a discrete colormap with 8 distinct colors\n",
    "cmap_discrete = mcolors.ListedColormap(plt.get_cmap('Paired').colors[:8])\n",
    "\n",
    "#color for NaN values\n",
    "cmap_discrete.set_bad(color='lightgray', alpha=1.0)\n",
    "\n",
    "ax1.plot(cos_u2_lower.index, cos_u2_lower, color='crimson', label='COSMO', zorder=6)\n",
    "ax1.plot(aws_lower_u2.index, aws_lower_u2['U'], color='black', alpha=0.7, label='Lower AWS', zorder=7)\n",
    "ax1.set_ylabel('Wind Speed ($m\\ s^{-1}$)')\n",
    "ax1.grid(linestyle='--', alpha=0.6)\n",
    "ax1.legend(loc='upper left', fontsize=18).set_zorder(9)\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "ax1_dir = divider.append_axes(\"top\", size=\"6%\", pad=0.05)\n",
    "dir_data_lower = aws_lower_u2['Dir_Cat'].values[np.newaxis, :]\n",
    "date_start, date_end = mdates.date2num(aws_lower_u2.index[0]), mdates.date2num(aws_lower_u2.index[-1])\n",
    "norm_discrete = mcolors.BoundaryNorm(np.arange(-0.5, 8.5, 1), cmap_discrete.N)\n",
    "img1 = ax1_dir.imshow(dir_data_lower, cmap=cmap_discrete, norm=norm_discrete, aspect='auto', extent=[date_start, date_end, 0, 1])\n",
    "\n",
    "ax1_dir.yaxis.set_visible(False)\n",
    "ax1_dir.xaxis.set_visible(False)\n",
    "\n",
    "ax2.plot(cos_u2_upper.index, cos_u2_upper, color='crimson', label='COSMO', zorder=6)\n",
    "ax2.plot(aws_upper_u2.index, aws_upper_u2['U'], color='black', alpha=0.7, label='Upper AWS', zorder=7)\n",
    "ax2.set_ylabel('Wind Speed ($m\\ s^{-1}$)')\n",
    "ax2.grid(linestyle='--', alpha=0.6)\n",
    "ax2.legend(loc='upper left', fontsize=18).set_zorder(9)\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "ax2_dir = divider.append_axes(\"top\", size=\"6%\", pad=0.05)\n",
    "dir_data_upper = aws_upper_u2['Dir_Cat'].values[np.newaxis, :]\n",
    "img2 = ax2_dir.imshow(dir_data_upper, cmap=cmap_discrete, norm=norm_discrete, aspect='auto', extent=[date_start, date_end, 0, 1])\n",
    "ax2_dir.yaxis.set_visible(False)\n",
    "ax2_dir.xaxis.set_visible(False)\n",
    "\n",
    "ax2.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(1, 2, 3,4,5,6,7,8,9,10,11,12)))\n",
    "days = mdates.DayLocator(interval=7)\n",
    "ax2.xaxis.set_minor_locator(days)\n",
    "ax2.xaxis.set_major_formatter(\n",
    "    mdates.ConciseDateFormatter(ax2.xaxis.get_major_locator()))\n",
    "ax2.set_xlim(pd.to_datetime(\"2003-10-01\"), pd.to_datetime(\"2004-09-30\"))\n",
    "plt.setp(ax2.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "\n",
    "fig.subplots_adjust(top=0.88)\n",
    "cbar_ax = fig.add_axes([0.15, 0.93, 0.7, 0.03])\n",
    "cbar = fig.colorbar(img1, cax=cbar_ax, orientation='horizontal')\n",
    "\n",
    "tick_locs = np.arange(len(dir_labels))\n",
    "cbar.set_ticks(tick_locs)\n",
    "cbar.set_ticklabels(dir_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commented part did not account for nans!\n",
    "#aws_lower = aws_lower.resample(\"1D\").agg(T=('T', \"mean\"),Dir=('Dir', \"mean\"),U=('U', \"mean\"),SWIsum=('SWI', \"sum\"), SWImean=(\"SWI\",\"mean\"),SWOsum=('SWO', \"sum\"),SWOmean=(\"SWO\",\"mean\"),\n",
    "#                                         LWO=('LWO','mean'),LWI=('LWI','mean'),sfc=('sfc', \"mean\"),RH= ('RH', \"mean\"),P=('P', \"mean\"))\n",
    "aws_lower = aws_lower.resample(\"1D\").agg(\n",
    "    T=('T', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    Dir=('Dir', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    U=('U', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    SWIsum=('SWI', lambda x: x.sum(min_count=len(x)) if x.notna().all() else np.nan),\n",
    "    SWImean=('SWI', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    SWOsum=('SWO', lambda x: x.sum(min_count=len(x)) if x.notna().all() else np.nan),\n",
    "    SWOmean=('SWO', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    LWO=('LWO', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    LWI=('LWI', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    sfc=('sfc', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    RH=('RH', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    P=('P', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    ")\n",
    "aws_lower['alpha'] = aws_lower['SWOsum'] / aws_lower['SWIsum']\n",
    "aws_lower['sfc'] =  aws_lower['sfc'] - aws_lower['sfc'][0]\n",
    "\n",
    "#aws_upper = aws_upper.resample(\"1D\").agg(T=('T', \"mean\"),Dir=('Dir', \"mean\"),U=('U', \"mean\"),SWIsum=('SWI', \"sum\"), SWImean=(\"SWI\",\"mean\"),SWOsum=('SWO', \"sum\"),SWOmean=(\"SWO\",\"mean\"),\n",
    "#                                         LWO=('LWO','mean'),LWI=('LWI','mean'),sfc=('sfc', \"mean\"),RH= ('RH', \"mean\"),P=('P', \"mean\"))\n",
    "aws_upper = aws_upper.resample(\"1D\").agg(\n",
    "    T=('T', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    Dir=('Dir', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    U=('U', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    SWIsum=('SWI', lambda x: x.sum(min_count=len(x)) if x.notna().all() else np.nan),\n",
    "    SWImean=('SWI', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    SWOsum=('SWO', lambda x: x.sum(min_count=len(x)) if x.notna().all() else np.nan),\n",
    "    SWOmean=('SWO', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    LWO=('LWO', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    LWI=('LWI', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    sfc=('sfc', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    RH=('RH', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    "    P=('P', lambda x: x.mean() if x.notna().all() else np.nan),\n",
    ")\n",
    "aws_upper['alpha'] = aws_upper['SWOsum'] / aws_upper['SWIsum']\n",
    "aws_upper['sfc'] = aws_upper['sfc'] - aws_upper['sfc'][0]\n",
    "aws_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85671e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_of_interest = ['TOTALHEIGHT','SNOWHEIGHT','MB',\"SWnet\", 'G','surfMB','HGT','T2','U2','RH2','LWin','MASK','RAIN', 'SNOWFALL', 'RRR', 'ME','surfM','subM', 'LWout', 'TS', 'ALBEDO','PRES']\n",
    "dic_sum_lower = {}\n",
    "dic_sum_upper = {}\n",
    "dic_sum_lower_full = {}\n",
    "dic_sum_upper_full = {}\n",
    "for var in vars_of_interest:\n",
    "    if var not in [\"HGT\", \"MASK\"]:\n",
    "        for fp in pathlib.Path(path).glob('*{}.csv'.format(var)):\n",
    "            print(fp)\n",
    "            location = str(fp.stem).split('_')[2]\n",
    "            if location == \"upperaws\":\n",
    "                print(location)\n",
    "                if var in [\"RAIN\",\"SNOWFALL\",\"RRR\",\"surfM\",\"subM\",\"MB\"]:\n",
    "                    df_og = pd.read_csv(fp, parse_dates=True, index_col=\"time\")\n",
    "                    df_upper = df_og.resample(\"1D\").sum()\n",
    "                else:\n",
    "                    df_og = pd.read_csv(fp, parse_dates=True, index_col=\"time\")\n",
    "                    df_upper = df_og.resample(\"1D\").mean()\n",
    "                df_og = df_og.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "                df_upper = df_upper.loc[\"2003-10-01\":\"2004-09-30\"]    \n",
    "                if var == \"TOTALHEIGHT\":\n",
    "                    df_og = df_og - df_og.iloc[0]\n",
    "                    df_upper = df_upper - df_upper.iloc[0]\n",
    "                \n",
    "                summary_upper = pd.DataFrame(index=df_upper.index)\n",
    "                summary_upper['ENS_MEAN'] = df_upper.mean(axis=1)\n",
    "                summary_upper['ENS_MEDIAN'] = df_upper.median(axis=1)\n",
    "                summary_upper['ENS_STD'] = df_upper.std(axis=1)\n",
    "                summary_upper['CI_lower'] = df_upper.quantile(0.025, axis=1)\n",
    "                summary_upper['CI_upper'] = df_upper.quantile(0.975, axis=1)   \n",
    "                summary_upper['ENS_MIN'] = df_upper.min(axis=1)\n",
    "                summary_upper['ENS_MAX'] = df_upper.max(axis=1)\n",
    "                #\n",
    "                summary_full_upper = pd.DataFrame(index=df_og.index)\n",
    "                summary_full_upper['ENS_MEAN'] = df_og.mean(axis=1)\n",
    "                summary_full_upper['ENS_MEDIAN'] = df_og.median(axis=1)\n",
    "                summary_full_upper['ENS_STD'] = df_og.std(axis=1)\n",
    "                summary_full_upper['CI_lower'] = df_og.quantile(0.025, axis=1)\n",
    "                summary_full_upper['CI_upper'] = df_og.quantile(0.975, axis=1)   \n",
    "                summary_full_upper['ENS_MIN'] = df_og.min(axis=1)\n",
    "                summary_full_upper['ENS_MAX'] = df_og.max(axis=1)\n",
    "                #\n",
    "                dic_sum_upper[var] = summary_upper.copy()\n",
    "                dic_sum_upper_full[var] = summary_full_upper.copy()\n",
    "            else:\n",
    "                print(location)\n",
    "                if var in [\"RAIN\",\"SNOWFALL\",\"RRR\",\"surfM\",\"subM\",\"MB\"]:\n",
    "                    df_og = pd.read_csv(fp, parse_dates=True, index_col=\"time\")\n",
    "                    df_lower = df_og.resample(\"1D\").sum()\n",
    "                else:\n",
    "                    df_og = pd.read_csv(fp, parse_dates=True, index_col=\"time\")\n",
    "                    df_lower = df_og.resample(\"1D\").mean()\n",
    "                df_og = df_og.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "                df_lower = df_lower.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "                if var == \"TOTALHEIGHT\":\n",
    "                    df_og = df_og - df_og.iloc[0]\n",
    "                    df_lower = df_lower - df_lower.iloc[0]\n",
    "                    \n",
    "                summary_lower = pd.DataFrame(index=df_lower.index)\n",
    "                summary_lower['ENS_MEAN'] = df_lower.mean(axis=1)\n",
    "                summary_lower['ENS_MEDIAN'] = df_lower.median(axis=1)\n",
    "                summary_lower['ENS_STD'] = df_lower.std(axis=1)\n",
    "                summary_lower['CI_lower'] = df_lower.quantile(0.025, axis=1)\n",
    "                summary_lower['CI_upper'] = df_lower.quantile(0.975, axis=1)               \n",
    "                summary_lower['ENS_MIN'] = df_lower.min(axis=1)\n",
    "                summary_lower['ENS_MAX'] = df_lower.max(axis=1)\n",
    "                #\n",
    "                summary_full_lower = pd.DataFrame(index=df_og.index)\n",
    "                summary_full_lower['ENS_MEAN'] = df_og.mean(axis=1)\n",
    "                summary_full_lower['ENS_MEDIAN'] = df_og.median(axis=1)\n",
    "                summary_full_lower['ENS_STD'] = df_og.std(axis=1)\n",
    "                summary_full_lower['CI_lower'] = df_og.quantile(0.025, axis=1)\n",
    "                summary_full_lower['CI_upper'] = df_og.quantile(0.975, axis=1)               \n",
    "                summary_full_lower['ENS_MIN'] = df_og.min(axis=1)\n",
    "                summary_full_lower['ENS_MAX'] = df_og.max(axis=1)\n",
    "                #\n",
    "                dic_sum_lower[var] = summary_lower.copy()\n",
    "                dic_sum_lower_full[var] = summary_full_lower.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b282f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sum_lower['LWout']['ENS_MEAN'] = dic_sum_lower['LWout']['ENS_MEAN']*-1\n",
    "dic_sum_upper['LWout']['ENS_MEAN'] = dic_sum_upper['LWout']['ENS_MEAN']*-1\n",
    "dic_sum_lower['LWout']['ENS_MEDIAN'] = dic_sum_lower['LWout']['ENS_MEDIAN']*-1\n",
    "dic_sum_upper['LWout']['ENS_MEDIAN'] = dic_sum_upper['LWout']['ENS_MEDIAN']*-1\n",
    "dic_sum_lower['LWout']['ENS_MAX'] = dic_sum_lower['LWout']['ENS_MAX']*-1\n",
    "dic_sum_upper['LWout']['ENS_MAX'] = dic_sum_upper['LWout']['ENS_MAX']*-1\n",
    "dic_sum_lower['LWout']['ENS_MIN'] = dic_sum_lower['LWout']['ENS_MIN']*-1\n",
    "dic_sum_upper['LWout']['ENS_MIN'] = dic_sum_upper['LWout']['ENS_MIN']*-1\n",
    "dic_sum_lower['LWout']['CI_lower'] = dic_sum_lower['LWout']['CI_lower']*-1\n",
    "dic_sum_upper['LWout']['CI_lower'] = dic_sum_upper['LWout']['CI_lower']*-1\n",
    "dic_sum_lower['LWout']['CI_upper'] = dic_sum_lower['LWout']['CI_upper']*-1\n",
    "dic_sum_upper['LWout']['CI_upper'] = dic_sum_upper['LWout']['CI_upper']*-1\n",
    "#\n",
    "dic_sum_lower_full['LWout']['ENS_MEAN'] = dic_sum_lower_full['LWout']['ENS_MEAN']*-1\n",
    "dic_sum_upper_full['LWout']['ENS_MEAN'] = dic_sum_upper_full['LWout']['ENS_MEAN']*-1\n",
    "dic_sum_lower_full['LWout']['ENS_MEDIAN'] = dic_sum_lower_full['LWout']['ENS_MEDIAN']*-1\n",
    "dic_sum_upper_full['LWout']['ENS_MEDIAN'] = dic_sum_upper_full['LWout']['ENS_MEDIAN']*-1\n",
    "dic_sum_lower_full['LWout']['ENS_MAX'] = dic_sum_lower_full['LWout']['ENS_MAX']*-1\n",
    "dic_sum_upper_full['LWout']['ENS_MAX'] = dic_sum_upper_full['LWout']['ENS_MAX']*-1\n",
    "dic_sum_lower_full['LWout']['ENS_MIN'] = dic_sum_lower_full['LWout']['ENS_MIN']*-1\n",
    "dic_sum_upper_full['LWout']['ENS_MIN'] = dic_sum_upper_full['LWout']['ENS_MIN']*-1\n",
    "dic_sum_lower_full['LWout']['CI_lower'] = dic_sum_lower_full['LWout']['CI_lower']*-1\n",
    "dic_sum_upper_full['LWout']['CI_lower'] = dic_sum_upper_full['LWout']['CI_lower']*-1\n",
    "dic_sum_lower_full['LWout']['CI_upper'] = dic_sum_lower_full['LWout']['CI_upper']*-1\n",
    "dic_sum_upper_full['LWout']['CI_upper'] = dic_sum_upper_full['LWout']['CI_upper']*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dictionary from point LHS runs\n",
    "if 'win' in sys.platform:\n",
    "    filename = 'E:/OneDrive/PhD/PhD/Data/Hintereisferner/COSIPY/point_scale/LHS-weighted-tenbestrmse-ens.pkl'\n",
    "else:\n",
    "    filename = '/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/COSIPY/point_scale/LHS-weighted-tenbestrmse-ens.pkl'\n",
    "\n",
    "# Open the file in read-binary mode ('rb')\n",
    "with open(filename, 'rb') as f:\n",
    "    # Use pickle.load to load the object from the file\n",
    "    loaded_results = pickle.load(f)\n",
    "df_lwo = loaded_results['LWO']\n",
    "df_sfc = loaded_results['SFC']\n",
    "df_alb = loaded_results['ALB']\n",
    "df_alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'win' in sys.platform:\n",
    "    alb_obs = xr.open_dataset(\"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/HEF_processed_HRZ-30CC-filter_albedos.nc\")\n",
    "else:\n",
    "    alb_obs = xr.open_dataset(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/HEF_processed_HRZ-30CC-filter_albedos.nc\")\n",
    "df_satellite_obs = alb_obs[['median_albedo']].to_dataframe()\n",
    "df_satellite_obs = df_satellite_obs.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "df_satellite_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit LWout to 316 ..\n",
    "def adjust_ticks(ax, hide_x_ticks, hide_y_ticks, label):\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(1, 2, 3,4,5,6,7,8,9,10,11,12)))\n",
    "    days = mdates.DayLocator(interval=7)\n",
    "    ax.xaxis.set_minor_locator(days)\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "    ax.set_xlim(aws_upper.index[0],aws_upper.index[-1])\n",
    "    \n",
    "    if hide_x_ticks:\n",
    "        ax.set_xticklabels(\"\")\n",
    "        ax.set_xlabel('', fontsize=22)\n",
    "    else:\n",
    "        ax.xaxis.set_tick_params(labelsize=18, rotation=30)\n",
    "        ax.set_xlabel('Time', fontsize=22)\n",
    "        \n",
    "    if hide_y_ticks:\n",
    "        ax.set_yticklabels(\"\")\n",
    "        ax.set_ylabel('', fontsize=22)\n",
    "    else:\n",
    "        ax.yaxis.set_tick_params(labelsize=18)\n",
    "        ax.set_ylabel(label, fontsize=22)\n",
    "        \n",
    "\n",
    "def plot_sfc(ax, location, hide_x_ticks, hide_y_ticks, legend=False, handles_n_labels=None):\n",
    "    \n",
    "    if location == \"upper\":\n",
    "        data_aws = aws_upper\n",
    "        data_cos = dic_sum_upper\n",
    "        df_ensemble_holder = df_upper\n",
    "        label = \"AWS\"\n",
    "    else:\n",
    "        data_aws = aws_lower\n",
    "        data_cos = dic_sum_lower\n",
    "        df_ensemble_holder = df_lower\n",
    "        label = \"AWS\"\n",
    "        \n",
    "    ax.plot(data_aws['sfc'], color=\"black\", label=label, zorder=6)\n",
    "    ax.plot(data_cos['TOTALHEIGHT']['ENS_MEDIAN'], color=\"red\", label=\"Posterior Ens. Median\", zorder=6)\n",
    "    ax.fill_between(data_cos['TOTALHEIGHT'].index, data_cos['TOTALHEIGHT']['CI_lower'],\n",
    "                    data_cos['TOTALHEIGHT']['CI_upper'], color=\"brown\",\n",
    "                    alpha=0.5, label = \"Posterior 95% CI\")\n",
    "    if location == \"upper\":\n",
    "        ax.plot(df_sfc['median'], color=\"steelblue\", label=\"AWS-assisted Ens. Median\", zorder=6)\n",
    "        ax.fill_between(df_sfc['median'].index, df_sfc['lower_ci_95'],\n",
    "                        df_sfc['upper_ci_95'], color=\"lightsteelblue\",\n",
    "                        alpha=0.5, label = \"AWS-assisted 95% CI\")\n",
    "    #ax.plot(data_cos['TOTALHEIGHT']['ENS_MAX'], color=\"red\", linestyle=\"dashed\",linewidth=0.8, alpha=.75, label=\"ENS MAX\", zorder=5)\n",
    "    #ax.plot(data_cos['TOTALHEIGHT']['ENS_MIN'], color=\"red\", linestyle=\"dashed\",linewidth=0.8, alpha=.75, label=\"ENS MIN\", zorder=5)\n",
    "    #get dates where snowfall occurred\n",
    "    snowfall_dates = data_cos['SNOWFALL']['ENS_MEDIAN'].loc[data_cos['SNOWFALL']['ENS_MEDIAN'] > 0]\n",
    "    \n",
    "    #scale values from 0.1 to 1\n",
    "    snowfall_dates = (snowfall_dates - np.nanmin(snowfall_dates)) / (np.nanmax(snowfall_dates) - np.nanmin(snowfall_dates)) * (1 - 0.1) + 0.1\n",
    "    for xc in snowfall_dates.index:\n",
    "        ax.axvline(x=xc, linewidth=0.4, alpha=snowfall_dates[xc], color=\"darkblue\", zorder=-1)\n",
    "    '''\n",
    "    ax2 = ax.twinx()\n",
    "    cum_mb = (np.cumsum(data_cos['MB']['ENS_MEAN']) - np.cumsum(data_cos['MB']['ENS_MEAN'][0]))\n",
    "    ax2.plot(data_cos['MB'].index, cum_mb, zorder=-1, color=\"darkolivegreen\", alpha=1)\n",
    "    ax3 = ax.twinx()\n",
    "    ax3.bar(data_cos['SNOWFALL']['ENS_MEAN'].index,data_cos['SNOWFALL']['ENS_MEAN'],\n",
    "            alpha=0.3,width=0.2, color=\"darkblue\", zorder=-1)\n",
    "    # right, left, top, bottom\n",
    "    ax3.spines['right'].set_position(('outward', 80))\n",
    "    '''\n",
    "    ax.set_xlabel(\"Time\")\n",
    "                     \n",
    "    ax.yaxis.label.set_color(\"black\")\n",
    "    if legend is True:\n",
    "        if handles_n_labels is not None:\n",
    "            handles, labels = handles_n_labels\n",
    "            ax.legend(handles, labels, prop={'size': 16}, loc=\"lower center\", ncol=1)\n",
    "    ax.grid()\n",
    "\n",
    "    adjust_ticks(ax, hide_x_ticks, hide_y_ticks, label=\"Height Change (m)\")\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    return (handles, labels)\n",
    "     \n",
    "def snowfall_lines(ax, location):\n",
    "    if location == \"upper\":\n",
    "        data_cos = dic_sum_upper\n",
    "    else:\n",
    "        data_cos = dic_sum_lower\n",
    "        \n",
    "    #get dates where snowfall occurred\n",
    "    snowfall_dates = data_cos['SNOWFALL']['ENS_MEDIAN'].loc[data_cos['SNOWFALL']['ENS_MEDIAN'] > 0]\n",
    "    \n",
    "    min_alpha = 0.1\n",
    "    max_alpha = 0.6 # <-- Capping the max alpha below 1.0 is the key fix\n",
    "    \n",
    "    # Scale values to the new [min_alpha, max_alpha] range\n",
    "    snowfall_values = snowfall_dates.values\n",
    "    scaled_alphas = (snowfall_values - np.nanmin(snowfall_values)) / (np.nanmax(snowfall_values) - np.nanmin(snowfall_values)) * (max_alpha - min_alpha) + min_alpha\n",
    "    \n",
    "    # Create a new series with the dates and scaled alphas\n",
    "    snowfall_alphas = pd.Series(scaled_alphas, index=snowfall_dates.index)\n",
    "    \n",
    "    for xc, alpha_val in snowfall_alphas.items():\n",
    "        ax.axvline(x=xc, linewidth=0.4, alpha=alpha_val, color=\"darkblue\", zorder=-1)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,2, figsize=(18,12), dpi=300)\n",
    "hand, labl = plot_sfc(ax=axes[0,0], location = \"upper\", hide_x_ticks=True, hide_y_ticks=False)\n",
    "#axes[0,0].set_ylim(-5, 5)\n",
    "axes[0,0].set_yticks(np.arange(-1, 5+1, 1))\n",
    "plot_sfc(ax=axes[0,1], location = \"lower\", hide_x_ticks=True, hide_y_ticks=False, legend=True, handles_n_labels=(hand,labl))\n",
    "axes[0,1].set_ylim(-5, 5)\n",
    "axes[0,1].set_yticks(np.arange(-5, 5+1, 1))\n",
    "axes[0,1].set_ylabel('', fontsize=22)\n",
    "axes[0,0].set_title(\"Upper AWS\")\n",
    "axes[0,1].set_title(\"Lower AWS\")\n",
    "\n",
    "axes[1,0].plot(aws_upper['LWO'], color=\"black\", label = \"AWS U\", zorder=6)\n",
    "axes[1,0].plot(dic_sum_upper['LWout']['ENS_MEDIAN'], color=\"red\", label=\"Posterior. ENS MEAN\", zorder=4)\n",
    "axes[1,0].fill_between(dic_sum_upper['LWout'].index, dic_sum_upper['LWout']['CI_lower'],\n",
    "                dic_sum_upper['LWout']['CI_upper'], color=\"brown\",\n",
    "                alpha=0.5, label = \"95% CI\")\n",
    "axes[1,0].plot(df_lwo['median'], color=\"steelblue\", label=\"Point MEDIAN\", zorder=5)\n",
    "axes[1,0].fill_between(df_lwo['median'].index, df_lwo['lower_ci_95'],\n",
    "                df_lwo['upper_ci_95'], color=\"lightsteelblue\",\n",
    "                alpha=0.5, label = \"Point 95% CI\")\n",
    "#axes[1,0].plot(dic_sum_upper['LWout']['ENS_MAX'], color=\"red\", linestyle=\"dashed\", label=\"ENS MAX\",linewidth=0.8, alpha=.75, zorder=5)\n",
    "#axes[1,0].plot(dic_sum_upper['LWout']['ENS_MIN'], color=\"red\", linestyle=\"dashed\", label=\"ENS MIN\",linewidth=0.8, alpha=.75, zorder=5)\n",
    "axes[1,0].set_ylim(170, 317)\n",
    "axes[1,0].set_yticks(np.arange(180, 305+25, 25))\n",
    "ax1 = axes[1,0].twinx()\n",
    "ax1.set_ylabel(\"Surf. Temp. (K)\")\n",
    "sigma = 5.670374419e-08\n",
    "\n",
    "# set twin scale (convert LWO to degree celsius with emissivity of 0.99)\n",
    "T_s = lambda LWo: (LWo/(sigma*0.99))**(1/4)\n",
    "# get left axis limits\n",
    "ymin, ymax = axes[1,0].get_ylim()\n",
    "# apply function and set transformed values to right axis limits\n",
    "ax1.set_ylim((T_s(ymin),T_s(ymax)))\n",
    "# set an invisible artist to twin axes \n",
    "# to prevent falling back to initial values on rescale events\n",
    "ax1.plot([],[])\n",
    "ax1.set_yticklabels(\"\")\n",
    "ax1.set_ylabel('', fontsize=22)\n",
    "snowfall_lines(axes[1,0], location=\"upper\")\n",
    "\n",
    "adjust_ticks(axes[1,0], hide_x_ticks=True, hide_y_ticks=False, label=r\"$Q_{LWout}$\"+ \" (Wm$^{-2}$)\")\n",
    "\n",
    "axes[1,1].plot(aws_lower['LWO'], color=\"black\", label = \"AWS U\", zorder=6)\n",
    "axes[1,1].plot(dic_sum_lower['LWout']['ENS_MEDIAN'], color=\"red\", label=\"ENS MEDIAN\", zorder=5)\n",
    "axes[1,1].fill_between(dic_sum_lower['LWout'].index, dic_sum_lower['LWout']['CI_lower'],\n",
    "                dic_sum_lower['LWout']['CI_upper'], color=\"brown\",\n",
    "                alpha=0.5, label = \"95% CI\")\n",
    "#axes[1,1].plot(dic_sum_lower['LWout']['ENS_MAX'], color=\"red\", linestyle=\"dashed\", label=\"ENS MAX\",linewidth=0.8, alpha=.75, zorder=5)\n",
    "#axes[1,1].plot(dic_sum_lower['LWout']['ENS_MIN'], color=\"red\", linestyle=\"dashed\", label=\"ENS MIN\",linewidth=0.8, alpha=.75, zorder=5)\n",
    "axes[1,1].set_ylim(170, 317)\n",
    "axes[1,1].set_yticks(np.arange(180, 305+25, 25))\n",
    "#(dic_sum_lower['LWout']['ENS_MEAN']*-1/(sigma*0.99))**(1/4)\n",
    "ax2 = axes[1,1].twinx()\n",
    "ax2.set_ylabel(\"Surf. Temp. (K)\")\n",
    "\n",
    "ymin, ymax = axes[1,1].get_ylim()\n",
    "ax2.set_ylim((T_s(ymin),T_s(ymax)))\n",
    "ax2.plot([],[])\n",
    "snowfall_lines(axes[1,1], location=\"lower\")\n",
    "\n",
    "adjust_ticks(axes[1,1], hide_x_ticks=True, hide_y_ticks=True, label=r\"$Q_{LWout}$\"+ \" (Wm$^{-2}$)\")\n",
    "\n",
    "axes[2,0].plot(aws_upper['alpha'], color=\"black\", label = \"AWS U\", zorder=5)\n",
    "axes[2,0].plot(dic_sum_upper['ALBEDO']['ENS_MEDIAN'], color=\"red\", label=\"ENS MEDIAN\", zorder=6)\n",
    "axes[2,0].fill_between(dic_sum_upper['ALBEDO'].index, dic_sum_upper['ALBEDO']['CI_lower'],\n",
    "                dic_sum_upper['ALBEDO']['CI_upper'], color=\"brown\",\n",
    "                alpha=0.5, label = \"95% CI\")\n",
    "axes[2,0].plot(df_alb['median'], color=\"steelblue\", label=\"Point MEDIAN\", zorder=5)\n",
    "axes[2,0].fill_between(df_alb['median'].index, df_alb['lower_ci_95'],\n",
    "                df_alb['upper_ci_95'], color=\"lightsteelblue\",\n",
    "                alpha=0.5, label = \"Point 95% CI\")\n",
    "\n",
    "## Markers for Landsat\n",
    "axes[2,0].plot(df_satellite_obs.index, [1.03] * len(df_satellite_obs), # Plot just above the 1.0 line\n",
    "               marker='|', markersize=14, ls='none', color='darkgreen', \n",
    "               label='Satellite Obs.', clip_on=False, zorder=10)\n",
    "axes[2,1].plot(df_satellite_obs.index, [1.03] * len(df_satellite_obs), # Plot just above the 1.0 line\n",
    "               marker='|', markersize=14, ls='none', color='darkgreen', \n",
    "               label='Satellite Obs.', clip_on=False, zorder=10)\n",
    "\n",
    "#axes[2,0].plot(dic_sum_upper['ALBEDO']['ENS_MAX'], color=\"red\", linestyle=\"dashed\", linewidth=0.8, alpha=.75, label=\"ENS MAX\", zorder=6)\n",
    "#axes[2,0].plot(dic_sum_upper['ALBEDO']['ENS_MIN'], color=\"red\", linestyle=\"dashed\", linewidth=0.8, alpha=.75, label=\"ENS MIN\", zorder=6)\n",
    "snowfall_lines(axes[2,0], location=\"lower\")\n",
    "axes[2,0].set_ylim(0,1)\n",
    "axes[2,0].set_yticks(np.arange(0,1+0.2,0.2))\n",
    "\n",
    "adjust_ticks(axes[2,0], hide_x_ticks=False, hide_y_ticks=False, label=\"Albedo (-)\")\n",
    "axes[2,1].plot(aws_lower['alpha'], color=\"black\", label = \"AWS U\", zorder=5)\n",
    "axes[2,1].plot(dic_sum_lower['ALBEDO']['ENS_MEDIAN'], color=\"red\", label=\"ENS MEDIAN\", zorder=6)\n",
    "axes[2,1].fill_between(dic_sum_lower['ALBEDO'].index, dic_sum_lower['ALBEDO']['CI_lower'],\n",
    "                dic_sum_lower['ALBEDO']['CI_upper'], color=\"brown\",\n",
    "                alpha=0.5, label = \"95% CI\")\n",
    "#axes[2,1].plot(dic_sum_lower['ALBEDO']['ENS_MAX'], color=\"red\", linestyle=\"dashed\", linewidth=0.8, alpha=.75, label=\"ENS MAX\", zorder=6)\n",
    "#axes[2,1].plot(dic_sum_lower['ALBEDO']['ENS_MIN'], color=\"red\", linestyle=\"dashed\", linewidth=0.8, alpha=.75, label=\"ENS MIN\", zorder=6)\n",
    "snowfall_lines(axes[2,1], location=\"lower\")\n",
    "adjust_ticks(axes[2,1], hide_x_ticks=False, hide_y_ticks=True, label=\"Albedo (-)\")\n",
    "axes[2,1].set_ylim(0,1)\n",
    "axes[2,1].set_yticks(np.arange(0,1+0.2,0.2))\n",
    "\n",
    "#calculate metrics like r2 and rmse\n",
    "try:\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "except:\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "def calc_metrics(obs, mod):\n",
    "    cleaned = obs.dropna()\n",
    "    mod = mod.loc[mod.index.isin(cleaned.index)]\n",
    "    try:\n",
    "        rmse = root_mean_squared_error(cleaned, mod)\n",
    "    except:\n",
    "        rmse = mean_squared_error(cleaned, mod, squared=False)\n",
    "    r2 = r2_score(cleaned, mod)\n",
    "    print(rmse,r2)\n",
    "    return (rmse,r2)\n",
    "\n",
    "rmse, r2 = calc_metrics(aws_upper['sfc'], dic_sum_upper['TOTALHEIGHT']['ENS_MEDIAN'])\n",
    "axes[0,0].annotate(\"R²: {},\\nRMSE: {} m\".format(round(r2, 2), round(rmse,2)), xy=(0.69, 0.78), xytext=(0.69, 0.78),\n",
    "                   textcoords='axes fraction', xycoords='axes fraction', size=20)\n",
    "rmse_new, r2_new = calc_metrics(aws_upper['sfc'], df_sfc['median'])\n",
    "axes[0,0].annotate(\n",
    "    f\"R²: {r2_new:.2f},\\nRMSE: {rmse_new:.2f} m\",\n",
    "    xy=(0.4, 0.125),  # slight vertical offset\n",
    "    textcoords='axes fraction',\n",
    "    xycoords='axes fraction',\n",
    "    size=20,\n",
    "    color='royalblue'\n",
    ")\n",
    "rmse, r2 = calc_metrics(aws_lower['sfc'], dic_sum_lower['TOTALHEIGHT']['ENS_MEDIAN'])\n",
    "axes[0,1].annotate(\"R²: {},\\nRMSE: {} m\".format(round(r2, 2), round(rmse,2)), xy=(0.69, 0.78), xytext=(0.69, 0.78),\n",
    "                   textcoords='axes fraction', xycoords='axes fraction', size=20)\n",
    "\n",
    "aws_lower['LWO'].loc[aws_lower['LWO'] > 316] = 316\n",
    "aws_upper['LWO'].loc[aws_upper['LWO'] > 316] = 316\n",
    "rmse, r2 = calc_metrics(aws_upper['LWO'], dic_sum_upper['LWout']['ENS_MEDIAN'])\n",
    "axes[1,0].annotate(\"R²: \" +str(round(r2,2))+\",\\nRMSE: \"+str(round(rmse,2))+\" Wm$^{-2}$\", xy=(0.57, 0.28), xytext=(0.57, 0.28),\n",
    "                   textcoords='axes fraction', xycoords='axes fraction', size=20)\n",
    "rmse_new, r2_new = calc_metrics(aws_upper['LWO'], df_lwo['median'])\n",
    "axes[1,0].annotate(\n",
    "    f\"R²: {r2_new:.2f},\\nRMSE: {rmse_new:.2f} Wm$^{{-2}}$\",\n",
    "    xy=(0.57, 0.05),  # slight vertical offset\n",
    "    textcoords='axes fraction',\n",
    "    xycoords='axes fraction',\n",
    "    size=20,\n",
    "    color='royalblue'\n",
    ")\n",
    "rmse, r2 = calc_metrics(aws_lower['LWO'], dic_sum_lower['LWout']['ENS_MEDIAN'])\n",
    "axes[1,1].annotate(\"R²: \" +str(round(r2,2))+\",\\nRMSE: \"+str(round(rmse,2))+\" Wm$^{-2}$\", xy=(0.57, 0.28), xytext=(0.57, 0.28),\n",
    "                   textcoords='axes fraction', xycoords='axes fraction', size=20)\n",
    "rmse, r2 = calc_metrics(aws_upper['alpha'], dic_sum_upper['ALBEDO']['ENS_MEDIAN'])\n",
    "axes[2,0].annotate(\"R²: {},\\nRMSE: {}\".format(round(r2, 2), round(rmse,2)), xy=(0.3, 0.36), xytext=(0.3, 0.36),\n",
    "                   textcoords='axes fraction', xycoords='axes fraction', size=20)\n",
    "rmse_new, r2_new = calc_metrics(aws_upper['alpha'], df_alb['median'])\n",
    "axes[2,0].annotate(\n",
    "    f\"R²: {r2_new:.2f},\\nRMSE: {rmse_new:.2f}\",\n",
    "    xy=(0.3, 0.12),  # slight vertical offset\n",
    "    textcoords='axes fraction',\n",
    "    xycoords='axes fraction',\n",
    "    size=20,\n",
    "    color='royalblue'\n",
    ")\n",
    "rmse, r2 = calc_metrics(aws_lower['alpha'], dic_sum_lower['ALBEDO']['ENS_MEDIAN'])\n",
    "axes[2,1].annotate(\"R²: {},\\nRMSE: {}\".format(round(r2, 2), round(rmse,2)), xy=(0.3, 0.36), xytext=(0.3, 0.36),\n",
    "                   textcoords='axes fraction', xycoords='axes fraction', size=20)\n",
    "\n",
    "## add labels\n",
    "fig.text(0.01, 0.95, 'a)', transform=fig.transFigure, fontsize=24)\n",
    "fig.text(0.01, 0.65, 'c)', transform=fig.transFigure, fontsize=24)\n",
    "fig.text(0.01, 0.36, 'e)', transform=fig.transFigure, fontsize=24)\n",
    "#\n",
    "fig.text(0.49, 0.95, 'b)', transform=fig.transFigure, fontsize=24)\n",
    "fig.text(0.49, 0.65, 'd)', transform=fig.transFigure, fontsize=24)\n",
    "fig.text(0.49, 0.36, 'f)', transform=fig.transFigure, fontsize=24)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if 'win' in sys.platform:\n",
    "    plt.savefig(\"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/Fig08_aws_comp_lrtest.png\", bbox_inches=\"tight\")\n",
    "else:\n",
    "    plt.savefig(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/Fig08_aws_comp_lrtest.png\", bbox_inches=\"tight\")\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c492c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define functions to calculate stats here\n",
    "def calc_cdf(vals):\n",
    "    x = np.sort(vals)\n",
    "    y = np.arange(1, len(x)+1)/len(x)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def sc_stats(expected_vals, predicted_vals, drop_nan=False):\n",
    "    if drop_nan:\n",
    "        exp_nans = np.isnan(expected_vals)\n",
    "        expected_vals = expected_vals[~exp_nans]\n",
    "        predicted_vals = predicted_vals[~np.isnan(predicted_vals)]\n",
    "        predicted_vals = predicted_vals[~exp_nans]\n",
    "        expected_vals = expected_vals.loc[expected_vals.index.isin(predicted_vals.index)]\n",
    "        predicted_vals = predicted_vals.loc[predicted_vals.index.isin(expected_vals.index)]\n",
    "        expected_vals = expected_vals.loc[expected_vals.index.isin(predicted_vals.index)]\n",
    "    xy = np.vstack([expected_vals, predicted_vals])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    #sort points by density, so that densest points are plotted last\n",
    "    idx = z.argsort()\n",
    "    expected, predicted, z = expected_vals[idx], predicted_vals[idx], z[idx]\n",
    "    return expected, predicted, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97654555",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lookup tables for bigplot .. \n",
    "aws_var_lookup = {'T2': 'T',\n",
    "                 'RH2': 'RH',\n",
    "                 'LWout': 'LWO',\n",
    "                 'LWin': 'LWI',\n",
    "                 'G': 'SWI',\n",
    "                 'ALBEDO': 'alpha',\n",
    "                 'TOTALHEIGHT': 'sfc',\n",
    "                 'SWnet': 'SWnet',\n",
    "                 'Q2': 'Q2',\n",
    "                 'PRES': 'P',\n",
    "                 'U2': 'U',\n",
    "                 'Td': 'Td'}\n",
    "\n",
    "minmax_lookup = {'T2': [245, 290],\n",
    "                 'RH2': [0,100],\n",
    "                 'LWout': [150, 350],\n",
    "                 'LWin': [0, 400],\n",
    "                 'G': [0, 1200],\n",
    "                 'ALBEDO': [0,1],\n",
    "                 'TOTALHEIGHT': [-1, 4],\n",
    "                 'TOTALHEIGHT_lower': [-3.5,4],\n",
    "                 'SWnet': [0, 900],\n",
    "                 'Q2': [0, 14],\n",
    "                 'U2': [0, 16],\n",
    "                 'PRES': [670, 760],\n",
    "                 'Td': [-40, 15]}\n",
    "\n",
    "label_lookup = {'T2': \"2m air temperature (K)\",\n",
    "               'RH2': '2m relative humidity (%)',\n",
    "               'LWout': r'$Q_{LWout}$' + \" (Wm$^{-2}$)\",\n",
    "               'LWin': r'$Q_{LWin}$' + \" (Wm$^{-2}$)\",\n",
    "               'G': r'$Q_{SWin}$' + \" (Wm$^{-2}$)\",\n",
    "               'ALBEDO': 'Albedo (-)',\n",
    "               'TOTALHEIGHT': 'Surface Height (m)',\n",
    "               'SWnet': r'$Q_{SWnet}$' + \" (Wm$^{-2}$)\",\n",
    "               'Q2': \"Specific humidity (gkg$^{-1}$)\",\n",
    "               'U2': \"Wind speed (ms$^{-1}$)\",\n",
    "               'PRES': \"Surface pressure (hPa)\",\n",
    "               'Td': \"Dewpoint Temperature (°C)\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b358d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba713d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate other fields to compare, e.g. SWnet and LWnet\n",
    "#aws_upper['SWnet'] = aws_upper['SWImean'] - aws_upper['SWOmean']\n",
    "#aws_lower['SWnet'] = aws_lower['SWImean'] - aws_lower['SWOmean']\n",
    "#\n",
    "aws_upper_copy['SWnet'] = aws_upper_copy['SWI'] - aws_upper_copy['SWO']\n",
    "aws_lower_copy['SWnet'] = aws_lower_copy['SWI'] - aws_lower_copy['SWO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e195e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_lower_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f76b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_EW_Sonntag(T: float) -> float:\n",
    "    # Create output array with the same shape as T\n",
    "    Ew = np.empty_like(T, dtype=float)\n",
    "    \n",
    "    # Condition for water phase\n",
    "    water_mask = T >= 273.16\n",
    "    # Condition for ice phase\n",
    "    ice_mask = T < 273.16\n",
    "    \n",
    "    # Calculate over water where condition is met\n",
    "    Ew[water_mask] = 6.112 * np.exp((17.67 * (T[water_mask] - 273.16)) / (T[water_mask] - 29.66))\n",
    "    \n",
    "    # Calculate over ice where condition is met\n",
    "    Ew[ice_mask] = 6.112 * np.exp((22.46 * (T[ice_mask] - 273.16)) / (T[ice_mask] - 0.55))\n",
    "    \n",
    "    return Ew\n",
    "\n",
    "def calculate_specific_humidity(relative_humidity, temperature_celsius, pressure_hpa):\n",
    "    # Convert temperature from Celsius to Kelvin for your function\n",
    "    temperature_kelvin = temperature_celsius + 273.15\n",
    "    \n",
    "    # Step 1: Calculate saturation vapor pressure (es) using YOUR function\n",
    "    es = method_EW_Sonntag(temperature_kelvin)\n",
    "    \n",
    "    # Step 2: Calculate actual vapor pressure (e) from relative humidity\n",
    "    e = (relative_humidity / 100.0) * es\n",
    "    \n",
    "    # Step 3: Calculate specific humidity (q)\n",
    "    # This part of the formula remains the same\n",
    "    q = (0.622 * e) / (pressure_hpa - (1 - 0.622) * e)\n",
    "    \n",
    "    return q\n",
    "\n",
    "def calculate_dew_point(relative_humidity, temperature_celsius):\n",
    "    temperature_kelvin = temperature_celsius + 273.15\n",
    "    es = method_EW_Sonntag(temperature_kelvin.values)\n",
    "    \n",
    "    # vapor pressure (e)\n",
    "    e = (relative_humidity.values / 100.0) * es\n",
    "    \n",
    "    # Create an output array for the results\n",
    "    dew_point_celsius = np.empty_like(e, dtype=float)\n",
    "    \n",
    "    # ChatGPT approach following here\n",
    "    e_safe = np.where(e > 0, e, 1e-10)\n",
    "    val = np.log(e_safe / 6.112)\n",
    "\n",
    "    # --- Condition 1: Dew point is above freezing (e >= 6.112 hPa) ---\n",
    "    water_mask = e >= 6.112\n",
    "    dew_point_celsius[water_mask] = (243.5 * val[water_mask]) / (17.67 - val[water_mask])\n",
    "\n",
    "    # --- Condition 2: Frost point is below freezing (e < 6.112 hPa) ---\n",
    "    ice_mask = e < 6.112\n",
    "    dew_point_celsius[ice_mask] = (272.61 * val[ice_mask]) / (22.46 - val[ice_mask])\n",
    "    \n",
    "    return pd.Series(dew_point_celsius, index=temperature_celsius.index, name='dew_point')\n",
    "\n",
    "aws_Td_upper = calculate_dew_point(aws_upper_copy['RH'], aws_upper_copy['T'] - 273.15)\n",
    "aws_Td_lower = calculate_dew_point(aws_lower_copy['RH'], aws_lower_copy['T'] - 273.15)\n",
    "# cos\n",
    "cos_Td_upper = calculate_dew_point(dic_sum_upper_full['RH2']['ENS_MEDIAN'], dic_sum_upper_full['T2']['ENS_MEDIAN'] - 273.15)\n",
    "cos_Td_lower = calculate_dew_point(dic_sum_lower_full['RH2']['ENS_MEDIAN'], dic_sum_lower_full['T2']['ENS_MEDIAN'] - 273.15)\n",
    "# ci upper\n",
    "cos_Td_upper_ciu = calculate_dew_point(dic_sum_upper_full['RH2']['CI_upper'], dic_sum_upper_full['T2']['CI_upper'] - 273.15)\n",
    "cos_Td_lower_ciu = calculate_dew_point(dic_sum_lower_full['RH2']['CI_upper'], dic_sum_lower_full['T2']['CI_upper'] - 273.15)\n",
    "# ci lower\n",
    "cos_Td_upper_cil = calculate_dew_point(dic_sum_upper_full['RH2']['CI_lower'], dic_sum_upper_full['T2']['CI_lower'] - 273.15)\n",
    "cos_Td_lower_cil = calculate_dew_point(dic_sum_lower_full['RH2']['CI_lower'], dic_sum_lower_full['T2']['CI_lower'] - 273.15)\n",
    "\n",
    "\n",
    "# Calculate q\n",
    "aws_q_upper = calculate_specific_humidity(aws_upper_copy['RH'], aws_upper_copy['T']-273.15, aws_upper_copy['P']) * 1000 #g/kg\n",
    "aws_q_lower = calculate_specific_humidity(aws_lower_copy['RH'], aws_lower_copy['T']-273.15, aws_lower_copy['P']) * 1000 #g/kg\n",
    "cos_q_upper = calculate_specific_humidity(dic_sum_upper_full['RH2']['ENS_MEDIAN'], dic_sum_upper_full['T2']['ENS_MEDIAN']-273.15, dic_sum_upper_full['PRES']['ENS_MEDIAN']) * 1000 #g/kg\n",
    "cos_q_lower = calculate_specific_humidity(dic_sum_lower_full['RH2']['ENS_MEDIAN'], dic_sum_lower_full['T2']['ENS_MEDIAN']-273.15, dic_sum_lower_full['PRES']['ENS_MEDIAN']) * 1000 #g/kg\n",
    "# ci lower\n",
    "cos_q_upper_cil = calculate_specific_humidity(dic_sum_upper_full['RH2']['CI_lower'], dic_sum_upper_full['T2']['CI_lower']-273.15, dic_sum_upper_full['PRES']['CI_lower']) * 1000 #g/kg\n",
    "cos_q_lower_cil = calculate_specific_humidity(dic_sum_lower_full['RH2']['CI_lower'], dic_sum_lower_full['T2']['CI_lower']-273.15, dic_sum_lower_full['PRES']['CI_lower']) * 1000 #g/kg\n",
    "# ci upper\n",
    "cos_q_upper_ciu = calculate_specific_humidity(dic_sum_upper_full['RH2']['CI_upper'], dic_sum_upper_full['T2']['CI_upper']-273.15, dic_sum_upper_full['PRES']['CI_upper']) * 1000 #g/kg\n",
    "cos_q_lower_ciu = calculate_specific_humidity(dic_sum_lower_full['RH2']['CI_upper'], dic_sum_lower_full['T2']['CI_upper']-273.15, dic_sum_lower_full['PRES']['CI_upper']) * 1000 #g/kg\n",
    "#q_g_per_kg = q_kg_per_kg * 1000 # Convert to g/kg for easier interpretation\n",
    "\n",
    "aws_upper_copy['Q2'] = aws_q_upper\n",
    "aws_lower_copy['Q2'] = aws_q_lower\n",
    "dic_sum_upper_full['Q2'] = dic_sum_upper_full['RH2'].copy()\n",
    "dic_sum_lower_full['Q2'] = dic_sum_upper_full['RH2'].copy()\n",
    "dic_sum_upper_full['Q2']['ENS_MEDIAN'] = cos_q_upper\n",
    "dic_sum_lower_full['Q2']['ENS_MEDIAN'] = cos_q_lower\n",
    "dic_sum_upper_full['Q2']['CI_lower'] = cos_q_upper_cil\n",
    "dic_sum_lower_full['Q2']['CI_lower'] = cos_q_lower_cil\n",
    "dic_sum_upper_full['Q2']['CI_upper'] = cos_q_upper_ciu\n",
    "dic_sum_lower_full['Q2']['CI_upper'] = cos_q_lower_ciu\n",
    "#\n",
    "aws_upper_copy['Td'] = aws_Td_upper\n",
    "aws_lower_copy['Td'] = aws_Td_lower\n",
    "dic_sum_upper_full['Td'] = dic_sum_upper_full['RH2'].copy()\n",
    "dic_sum_lower_full['Td'] = dic_sum_upper_full['RH2'].copy()\n",
    "dic_sum_upper_full['Td']['ENS_MEDIAN'] = cos_Td_upper\n",
    "dic_sum_lower_full['Td']['ENS_MEDIAN'] = cos_Td_lower\n",
    "dic_sum_upper_full['Td']['CI_upper'] = cos_Td_upper_ciu\n",
    "dic_sum_lower_full['Td']['CI_upper'] = cos_Td_lower_ciu\n",
    "dic_sum_upper_full['Td']['CI_lower'] = cos_Td_upper_cil\n",
    "dic_sum_lower_full['Td']['CI_lower'] = cos_Td_lower_cil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de768559",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sum_upper_full.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9386f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(axes, var, ens_median, ci_lower, ci_upper, aws = \"upper\"):\n",
    "    if var in [\"G\",\"SWnet\",\"LWin\"]:\n",
    "        zorder_aws = 5\n",
    "        zorder_ens = 6\n",
    "    else:\n",
    "        zorder_aws = 6\n",
    "        zorder_ens = 5\n",
    "        \n",
    "    if aws == \"upper\":\n",
    "        axes.plot(aws_upper_copy[aws_var_lookup[var]], color=\"black\", label=\"AWS\", alpha=0.9, zorder=zorder_aws)\n",
    "        axes.plot(ens_median, color=\"red\", label=\"COSMO\", alpha=0.9, zorder=zorder_ens)\n",
    "        axes.fill_between(aws_upper_copy.index, ci_lower, ci_upper, color=\"brown\",\n",
    "                    alpha=0.5)#, label = \"95% CI\")\n",
    "        axes.grid()\n",
    "    else:\n",
    "        zorder_aws = 6\n",
    "        axes.plot(aws_lower_copy[aws_var_lookup[var]], color=\"black\", label=\"AWS\", alpha=0.9, zorder=zorder_aws)\n",
    "        axes.plot(ens_median, color=\"red\", label=\"COSMO\", alpha=0.9, zorder=zorder_ens)\n",
    "        axes.fill_between(aws_lower_copy.index, ci_lower, ci_upper, color=\"brown\",\n",
    "                    alpha=0.5)#, label = \"95% CI\")\n",
    "        axes.grid()        \n",
    "    \n",
    "def plot_cdf(axes, var, ens_median, ci_lower, ci_upper, aws=\"upper\"):\n",
    "    if aws == \"upper\":\n",
    "        xaws, yaws = calc_cdf(aws_upper_copy[aws_var_lookup[var]])\n",
    "        axes.plot(xaws, yaws, marker='.', color=\"black\", linestyle='none', ms=5)\n",
    "        xens, yens = calc_cdf(ens_median)\n",
    "        axes.plot(xens, yens, marker='.', color=\"red\", linestyle='none', ms=5)\n",
    "        xcil, _ = calc_cdf(ci_lower)\n",
    "        xciu, _ = calc_cdf(ci_upper)\n",
    "        axes.fill_betweenx(yens, xcil, xciu, color='brown', alpha=0.5, label='95% CI')\n",
    "    else:\n",
    "        xaws, yaws = calc_cdf(aws_lower_copy[aws_var_lookup[var]])\n",
    "        axes.plot(xaws, yaws, marker='.', color=\"black\", linestyle='none', ms=5)\n",
    "        xens, yens = calc_cdf(ens_median)\n",
    "        axes.plot(xens, yens, marker='.', color=\"red\", linestyle='none', ms=5)\n",
    "        xcil, _ = calc_cdf(ci_lower)\n",
    "        xciu, _ = calc_cdf(ci_upper)\n",
    "        axes.fill_betweenx(yens, xcil, xciu, color='brown', alpha=0.5, label='95% CI')\n",
    "\n",
    "def plot_scatter(axes, var, ens_median, ci_lower, ci_upper, aws=\"upper\"):\n",
    "    if aws == \"upper\":\n",
    "        up_aws, up_ens, up_z = sc_stats(aws_upper_copy[aws_var_lookup[var]], ens_median, drop_nan=True)\n",
    "        axes.scatter(up_aws, up_ens, c=up_z)\n",
    "        #\n",
    "        ci_upper = ci_upper.loc[ci_upper.index.isin(up_aws)]\n",
    "        ci_lower = ci_lower.loc[ci_lower.index.isin(up_aws)]\n",
    "\n",
    "        if var == \"LWout\":\n",
    "            axes.errorbar(\n",
    "                up_aws, up_ens,\n",
    "                yerr=[up_ens - ci_upper, ci_lower - up_ens],  # Switched because I had * -1\n",
    "                fmt='none', ecolor='gray', alpha=0.3, capsize=2\n",
    "            )\n",
    "        else:\n",
    "            axes.errorbar(\n",
    "                up_aws, up_ens,\n",
    "                yerr=[up_ens - ci_lower, ci_upper - up_ens],  # Switched because I had * -1\n",
    "                fmt='none', ecolor='gray', alpha=0.3, capsize=2\n",
    "            )\n",
    "    else:\n",
    "        up_aws, up_ens, up_z = sc_stats(aws_lower_copy[aws_var_lookup[var]], ens_median, drop_nan=True)\n",
    "        axes.scatter(up_aws, up_ens , c=up_z)\n",
    "        #\n",
    "        ci_upper = ci_upper.loc[ci_upper.index.isin(up_aws)]\n",
    "        ci_lower = ci_lower.loc[ci_lower.index.isin(up_aws)]\n",
    "        if var == \"LWout\":\n",
    "            axes.errorbar(\n",
    "                up_aws, up_ens, \n",
    "                yerr=[up_ens - ci_upper, ci_lower - up_ens],  # Switched because I had * -1\n",
    "                fmt='none', ecolor='gray', alpha=0.3\n",
    "            )\n",
    "        else:\n",
    "            axes.errorbar(\n",
    "                up_aws, up_ens, \n",
    "                yerr=[up_ens - ci_lower, ci_upper - up_ens],  # Switched because I had * -1\n",
    "                fmt='none', ecolor='gray', alpha=0.3\n",
    "            )\n",
    "    # calculate metrics and add to subplot\n",
    "    mbe = np.mean(up_ens - up_aws)\n",
    "    rmse = np.sqrt(mean_squared_error(up_aws, up_ens))\n",
    "    r2 = r2_score(up_aws, up_ens)\n",
    "    textstr = f'MBE = {mbe:.3f}\\nRMSE = {rmse:.3f}\\nR² = {r2:.3f}'\n",
    "    axes.text(0.05, 0.95, textstr, transform=axes.transAxes,\n",
    "            fontsize=20, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5106dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_figure(var, lims=None):\n",
    "    if var == \"TOTALHEIGHT\":\n",
    "        ylim_min, ylim_max = minmax_lookup[var+\"_lower\"]\n",
    "    else:\n",
    "        ylim_min, ylim_max = minmax_lookup[var]\n",
    "\n",
    "    fig = plt.figure(figsize=(24, 12), dpi=300) # Adjusted figsize for the new layout    \n",
    "    # Create a 2x3 grid with custom width ratios\n",
    "    # The first column will be twice as wide as the other two\n",
    "    gs = gridspec.GridSpec(2, 3, figure=fig, width_ratios=[2, 1, 1])\n",
    "\n",
    "    # Create an axes array manually to match the structure of plt.subplots\n",
    "    ax = np.array([\n",
    "        [fig.add_subplot(gs[0, 0]), fig.add_subplot(gs[0, 1]), fig.add_subplot(gs[0, 2])],\n",
    "        [fig.add_subplot(gs[1, 0]), fig.add_subplot(gs[1, 1]), fig.add_subplot(gs[1, 2])]\n",
    "    ])\n",
    "    plot_ts(ax[0,0], var=var, ens_median=dic_sum_upper_full[var]['ENS_MEDIAN'], ci_lower=dic_sum_upper_full[var]['CI_lower'], ci_upper=dic_sum_upper_full[var]['CI_upper'], aws=\"upper\")\n",
    "    plot_ts(ax[1,0], var=var, ens_median=dic_sum_lower_full[var]['ENS_MEDIAN'], ci_lower=dic_sum_lower_full[var]['CI_lower'], ci_upper=dic_sum_lower_full[var]['CI_upper'], aws=\"lower\")\n",
    "\n",
    "    for xs in [ax[0,0],ax[1,0]]:\n",
    "        xs.set_ylim(ylim_min, ylim_max)\n",
    "        xs.set_xlabel(\"Date\")\n",
    "        xs.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(10, 1, 4, 7)))\n",
    "        xs.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "        xs.xaxis.set_major_formatter(\n",
    "            mdates.ConciseDateFormatter(xs.xaxis.get_major_locator()))\n",
    "        xs.set_ylabel(label_lookup[var])\n",
    "        if var == \"T2\":\n",
    "            xs.set_yticks(np.arange(245, 290+5,5))\n",
    "        elif var == \"RH2\":\n",
    "            xs.set_yticks(np.arange(0, 100+10, 10))\n",
    "        elif var == \"LWout\":\n",
    "            xs.set_yticks(np.arange(150, 400+50, 50))\n",
    "        elif var == \"LWin\":\n",
    "            xs.set_yticks(np.arange(0, 400+50, 50))\n",
    "            \n",
    "    plot_cdf(ax[0,1], var=var, ens_median=dic_sum_upper_full[var]['ENS_MEDIAN'], ci_lower=dic_sum_upper_full[var]['CI_lower'], ci_upper=dic_sum_upper_full[var]['CI_upper'], aws=\"upper\")\n",
    "    plot_cdf(ax[1,1], var=var, ens_median=dic_sum_lower_full[var]['ENS_MEDIAN'], ci_lower=dic_sum_lower_full[var]['CI_lower'], ci_upper=dic_sum_lower_full[var]['CI_upper'], aws=\"lower\")        \n",
    "    for xs in [ax[0,1],ax[1,1]]:\n",
    "        xs.set_xlim(ylim_min, ylim_max)\n",
    "        xs.set_ylabel(\"Probability (%)\")\n",
    "        xs.set_xlabel(label_lookup[var])\n",
    "        xs.set_ylim(0, 1)\n",
    "        xs.set_yticks(np.arange(0,1+0.1,0.1))\n",
    "        if var == \"T2\":\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "            xs.set_xticks(np.arange(245, 290+10, 10))\n",
    "        elif var == \"RH2\":\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "            xs.set_xticks(np.arange(0, 100+10, 10))\n",
    "        elif var == \"LWout\":\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "            xs.set_xticks(np.arange(150, 350+50, 50))    \n",
    "        elif var == \"LWin\":\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "            xs.set_xticks(np.arange(0, 400+50, 50))        \n",
    "        xs.grid()\n",
    "        \n",
    "    plot_scatter(ax[0,2], var=var, ens_median=dic_sum_upper_full[var]['ENS_MEDIAN'], ci_lower=dic_sum_upper_full[var]['CI_lower'], ci_upper=dic_sum_upper_full[var]['CI_upper'], aws=\"upper\")\n",
    "    plot_scatter(ax[1,2], var=var, ens_median=dic_sum_lower_full[var]['ENS_MEDIAN'], ci_lower=dic_sum_lower_full[var]['CI_lower'], ci_upper=dic_sum_lower_full[var]['CI_upper'], aws=\"lower\")   \n",
    "    for xs in [ax[0,2],ax[1,2]]:\n",
    "        if var == \"T2\":\n",
    "            xs.set_ylim(245, 290)\n",
    "            xs.set_xlim(245, 290)\n",
    "            xs.plot([245, 290], [245, 290], 'k-')\n",
    "            xs.axvline(273.15, ls='-.', c='k')\n",
    "            xs.axhline(273.15, ls='-.', c='k')\n",
    "            xs.set_xticks(np.arange(245, 290+10, 10))\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "            xs.set_yticks(np.arange(245, 290+10, 10))\n",
    "            xs.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "        elif var == \"RH2\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 100+10, 10))\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "            xs.set_yticks(np.arange(0, 100+10, 10))\n",
    "            xs.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "        elif var == \"LWout\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(150, 350+50, 50))\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "            xs.set_yticks(np.arange(150, 350+50, 50))\n",
    "            xs.yaxis.set_minor_locator(MultipleLocator(10))\n",
    "        elif var == \"LWin\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 400+50, 50))\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "            xs.set_yticks(np.arange(0, 400+50, 50))\n",
    "            xs.yaxis.set_minor_locator(MultipleLocator(10))\n",
    "            xs.xaxis.set_tick_params(rotation=45) \n",
    "        elif var == \"G\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 1200+200, 200))\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(50))\n",
    "            xs.set_yticks(np.arange(0, 1200+200, 200))\n",
    "            xs.yaxis.set_minor_locator(MultipleLocator(50))\n",
    "            xs.xaxis.set_tick_params(rotation=45)  \n",
    "        elif var == \"SWnet\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 900+100, 100))\n",
    "            xs.xaxis.set_minor_locator(MultipleLocator(50))\n",
    "            xs.set_yticks(np.arange(0, 900+100, 100))\n",
    "            xs.yaxis.set_minor_locator(MultipleLocator(50))\n",
    "            xs.xaxis.set_tick_params(rotation=45)      \n",
    "        elif var == \"ALBEDO\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 1+0.2, 0.2))\n",
    "            xs.set_yticks(np.arange(0, 1+0.2, 0.2))\n",
    "            xs.xaxis.set_tick_params(rotation=45)\n",
    "        elif var == \"TOTALHEIGHT\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(-1, 4+0.5, 0.5))\n",
    "            xs.set_yticks(np.arange(-1, 4+0.5, 0.5))\n",
    "            xs.xaxis.set_tick_params(rotation=45)\n",
    "        elif var == \"U2\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 16+2, 2))\n",
    "            xs.set_yticks(np.arange(0, 16+2, 2))\n",
    "            xs.xaxis.set_tick_params(rotation=45)\n",
    "        elif var == \"Q2\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(0, 14+2, 2))\n",
    "            xs.set_yticks(np.arange(0, 14+2, 2))\n",
    "            xs.xaxis.set_tick_params(rotation=45)\n",
    "        elif var == \"Td\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(-45, 15+15, 15))\n",
    "            xs.set_yticks(np.arange(-45, 15+15, 15))\n",
    "            xs.xaxis.set_tick_params(rotation=45)\n",
    "        elif var == \"PRES\":\n",
    "            xs.set_ylim(ylim_min, ylim_max)\n",
    "            xs.set_xlim(ylim_min, ylim_max)\n",
    "            xs.plot([ylim_min, ylim_max], [ylim_min, ylim_max], 'k-')\n",
    "            xs.set_xticks(np.arange(670, 760+15, 15))\n",
    "            xs.set_yticks(np.arange(670, 760+15, 15))\n",
    "            xs.xaxis.set_tick_params(rotation=45)\n",
    "        xs.set_xlabel(\"AWS \" + label_lookup[var].split('()')[0])\n",
    "        xs.set_ylabel(\"COSIPY \" + label_lookup[var].split('()')[0])\n",
    "        xs.grid()\n",
    "    plt.figtext(0.6,0.95, \"Upper AWS\", ha=\"center\", va=\"top\", fontsize=22, color=\"black\", zorder=10)\n",
    "    plt.figtext(0.6,0.45, \"Lower AWS\", ha=\"center\", va=\"top\", fontsize=22, color=\"black\", zorder=10)\n",
    "    handles, labels = ax[0,0].get_legend_handles_labels()\n",
    "    print(handles)\n",
    "    print(labels)\n",
    "    fig.tight_layout()\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=5, bbox_to_anchor=(0.5, -0.01))\n",
    "    if 'win' in sys.platform:\n",
    "        plt.savefig(\"E:/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/\"+\"aux-fullcomp_awsvscosipy_{}.png\".format(var), bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.savefig(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/\"+\"aux-fullcomp_awsvscosipy_{}.png\".format(var), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"LWout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"RH2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738bcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"T2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53df5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"LWin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96eee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"SWnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"Q2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"Td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"PRES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a33dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_figure(\"U2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_plot = ['Q2', 'T2', 'PRES', 'LWin', 'G', 'U2'] #Q2 or Td\n",
    "aws_var_lookup = {'T2': 'T', 'LWin': 'LWI', 'G': 'SWI', 'Q2': 'Q2', 'PRES': 'P', 'U2': 'U', 'Td': 'Td'}\n",
    "unit_lookup = {'Q2': \"gkg$^{-1}$\", 'T2': \"K\", 'PRES': \"hPa\", \"LWin\": \"Wm$^{-2}$\", \"G\": \"Wm$^{-2}$\", \"U2\": \"ms$^{-1}$\", 'Td': \"°C\"}\n",
    "label_lookup = {'Q2': \"Q2\", 'T2': \"T2\", 'PRES': \"PRES\", \"LWin\": r\"$Q_{LWin}$\", \"G\": r\"$Q_{SWin}$\", \"U2\": \"U2\", 'Td': \"Td\"}\n",
    "\n",
    "axis_limits = {}\n",
    "for var in variables_to_plot:\n",
    "    # Combine modeled and observed data for both stations\n",
    "    obs_upper = aws_upper_copy[aws_var_lookup[var]].dropna()\n",
    "    mod_upper = dic_sum_upper_full[var]['ENS_MEDIAN'].dropna() # Select the correct column\n",
    "    obs_lower = aws_lower_copy[aws_var_lookup[var]].dropna()\n",
    "    mod_lower = dic_sum_lower_full[var]['ENS_MEDIAN'].dropna() # Select the correct column\n",
    "    \n",
    "    # Align data by index to ensure we only consider valid pairs\n",
    "    combined_upper = pd.concat([obs_upper, mod_upper], axis=1, join='inner').values.flatten()\n",
    "    combined_lower = pd.concat([obs_lower, mod_lower], axis=1, join='inner').values.flatten()\n",
    "    \n",
    "    all_vals = np.concatenate([combined_upper, combined_lower])\n",
    "    \n",
    "    # Check if all_vals is empty before calling min/max\n",
    "    if all_vals.size > 0:\n",
    "        var_min = all_vals.min()\n",
    "        var_max = all_vals.max()\n",
    "        axis_limits[var] = (var_min, var_max)\n",
    "    else:\n",
    "        axis_limits[var] = (0, 1) # Default fallback\n",
    "\n",
    "# --- Helper function for hydrological year ---\n",
    "def day_of_hydro_year(dt, start_month=10):\n",
    "    \"\"\"Calculates the day number within a hydrological year starting in a given month.\"\"\"\n",
    "    year = dt.year if dt.month >= start_month else dt.year - 1\n",
    "    start_of_hydro_year = pd.Timestamp(year, start_month, 1)\n",
    "    return (dt - start_of_hydro_year).days + 1\n",
    "\n",
    "## Create big scatterplot\n",
    "fig = plt.figure(figsize=(15, 20), dpi=300)\n",
    "\n",
    "# Create a 5x3 grid where the 3rd row is a small spacer.\n",
    "# This keeps the plot axes the same size but creates a vertical gap.\n",
    "gs = gridspec.GridSpec(5, 3, figure=fig, hspace=0.20, wspace=0.25, \n",
    "                       height_ratios=[1, 1, 0.005, 1, 1],\n",
    "                       top=0.97, bottom=0.15, left=0.15, right=0.97)\n",
    "\n",
    "# Manually create the list of axes, skipping the spacer row\n",
    "axes = []\n",
    "# Upper station plots (rows 0 and 1 of GridSpec)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axes.append(fig.add_subplot(gs[i, j]))\n",
    "# Lower station plots (rows 3 and 4 of GridSpec)\n",
    "for i in range(3, 5):\n",
    "    for j in range(3):\n",
    "        axes.append(fig.add_subplot(gs[i, j]))\n",
    "\n",
    "\n",
    "plot_data_sources = [\n",
    "    ('Upper', dic_sum_upper_full, aws_upper_copy),\n",
    "    ('Lower', dic_sum_lower_full, aws_lower_copy)\n",
    "]\n",
    "\n",
    "# This is needed because the last scatter plot is used for the colorbar\n",
    "scatter = None \n",
    "\n",
    "plot_index = 0\n",
    "i=0\n",
    "letters = [\"a) \",\"b) \",\"c) \",\"d) \",\"e) \",\"f) \",\"g) \",\"h) \",\"i) \",\"j) \",\"k) \",\"l) \"]\n",
    "for station_type, modeled_dic, observed_df in plot_data_sources:\n",
    "    for var in variables_to_plot:\n",
    "        ax = axes[plot_index]\n",
    "        \n",
    "        # Prepare Data for Plotting ---\n",
    "        modeled_series = modeled_dic[var]['ENS_MEDIAN']\n",
    "        observed_series = observed_df[aws_var_lookup[var]]\n",
    "        \n",
    "        aligned_mod, aligned_obs = modeled_series.align(observed_series, join='inner')\n",
    "        plot_df = pd.DataFrame({'observed': aligned_obs, 'modeled': aligned_mod}).dropna()\n",
    "        \n",
    "        x = plot_df['observed'].values\n",
    "        y = plot_df['modeled'].values\n",
    "        hydro_day = plot_df.index.to_series().apply(day_of_hydro_year)\n",
    "        \n",
    "        if len(x) == 0: # Skip if no overlapping data\n",
    "            ax.text(0.5, 0.5, f\"{var}\\n(No Data)\", ha='center', va='center', transform=ax.transAxes)\n",
    "            plot_index += 1\n",
    "            continue\n",
    "\n",
    "        # Create the Scatter Plot\n",
    "        scatter = ax.scatter(x, y, c=hydro_day, s=15, cmap='viridis', alpha=0.7)\n",
    "        \n",
    "        # Calculate and Overlay Density Contours\n",
    "        var_min, var_max = axis_limits.get(var, (np.min(x), np.max(x)))\n",
    "        xx, yy = np.mgrid[var_min:var_max:100j, var_min:var_max:100j]\n",
    "        positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "        values = np.vstack([x, y])\n",
    "        kernel = gaussian_kde(values)\n",
    "        f = np.reshape(kernel(positions).T, xx.shape)\n",
    "        ax.contour(xx, yy, f, colors='k', linewidths=0.4, alpha=0.5)\n",
    "        \n",
    "        # Formatting and Labels\n",
    "        ax.text(0.05, 0.95, f\"{letters[i]}{label_lookup[var]} ({unit_lookup[var]})\", transform=ax.transAxes, va='top', ha='left', fontsize=20)\n",
    "        i += 1\n",
    "        ax.plot([var_min, var_max], [var_min, var_max], color='k', linestyle='--', lw=1)\n",
    "        ax.set_xlim(var_min, var_max)\n",
    "        ax.set_ylim(var_min, var_max)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.grid(True, linestyle=':', alpha=0.6)\n",
    "        \n",
    "        # Statistics\n",
    "        r2 = r2_score(x, y)\n",
    "        rmse = np.sqrt(mean_squared_error(x, y))\n",
    "        mbe = np.mean(y - x) # Mean Bias Error (Observed - Modeled) -> here flipped to mod - obs, so positive means positive bias\n",
    "        stats_text = f'$R^2$ = {r2:.2f}\\nMBE = {mbe:.2f}\\nRMSE = {rmse:.2f}'\n",
    "        ax.text(0.95, 0.05, stats_text, transform=ax.transAxes, \n",
    "                fontsize=18, verticalalignment='bottom', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.8))\n",
    "\n",
    "        ax.xaxis.set_major_locator(mticker.MaxNLocator(nbins=5, prune='both'))\n",
    "        ax.set_yticks(ax.get_xticks())\n",
    "\n",
    "        plot_index += 1\n",
    "\n",
    "if scatter:\n",
    "    # Position the colorbar at the very bottom\n",
    "    cbar_ax = fig.add_axes([gs.left, 0.08, gs.right - gs.left, 0.015])\n",
    "    cbar = fig.colorbar(scatter, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar.set_label('Day of Hydrological Year', fontsize=22)\n",
    "\n",
    "fig.text((gs.left + gs.right) / 2, 0.11, 'Lower AWS', ha='center', va='center', fontsize=24)\n",
    "fig.text(0.08, 0.34, 'COSMO-CLM at Lower AWS', ha='center', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "fig.text((gs.left + gs.right) / 2, 0.55, 'Upper AWS', ha='center', va='center', fontsize=24)\n",
    "fig.text(0.08, 0.75, 'COSMO-CLM at Upper AWS', ha='center', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "if 'win' in sys.platform:\n",
    "    plt.savefig(r\"E:\\OneDrive\\PhD\\PhD\\Data\\Hintereisferner\\Figures\\FigA02_full_scatterplot_summary_forcing.png\", bbox_inches=\"tight\")\n",
    "else:\n",
    "    plt.savefig(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Figures/FigA02_full_scatterplot_summary_forcing.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load forcing and compare to SWE record from Tudes et al., 18 May 2004 reported 1463mm ± 10%\n",
    "if 'win' in sys.platform:\n",
    "    cosmo = pd.read_csv(r\"E:\\OneDrive\\PhD\\PhD\\Data\\Hintereisferner\\Climate\\COSMO_forcing_1999-2010_PRESintp.csv\", parse_dates=True, index_col=\"TIMESTAMP\")\n",
    "else:\n",
    "    cosmo = pd.read_csv(\"/mnt/C4AEBBABAEBB9500/OneDrive/PhD/PhD/Data/Hintereisferner/Climate/COSMO_forcing_1999-2010_PRESintp.csv\", parse_dates=True, index_col=\"TIMESTAMP\")\n",
    "cosmo = cosmo.loc[\"2003-10-01\":\"2004-09-30\"]\n",
    "cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SWE (m) = Snowfall Depth (m) × (Density of Snow / Density of Water)\n",
    "mult_factor_RRR = 1\n",
    "density_fresh_snow = np.maximum(109.0 + 6.0 * (cosmo['T2'] - 273.16) + 26.0 * np.sqrt(cosmo['U2']), 50.0)\n",
    "snowfall = cosmo['SNOWFALL'] * mult_factor_RRR\n",
    "swe_m = snowfall * (density_fresh_snow/1000.0)\n",
    "swe_mm = swe_m * 1000\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(np.cumsum(swe_mm))\n",
    "ax.plot(np.cumsum(cosmo['RRR']))\n",
    "ax.errorbar(pd.to_datetime(\"2004-05-18\"), 1463, yerr=146.3, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95abd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
