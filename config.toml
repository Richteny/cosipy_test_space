# This is the COSIPY configuration (init) file.
# Please make your changes here.

[SIMULATION_PERIOD]
#time_start = "1999-01-01T00:00"
#time_end = "2009-12-31T23:00"
time_start = "1987-10-01T00:00"
time_end = "2022-12-31T23:00"

[FILENAMES]
data_path = "./data/"
#input_netcdf = "HEF/HEF_COSMO_1D20m_HORAYZON_1999_2010_IntpPRES.nc"
#input_netcdf = "Halji/Halji_HARv2_1D20m_HRZ_1988_2022.nc" # 
input_netcdf = "Abramov/Abramov_HARv2_1D20m_HORAYZON_1988_2022.nc"
#output_prefix = "HEF_COSMO_1D20m_1999_2010_HORAYZON_IntpPRES_localsens" #"HEF_COSMO_1D20m_1999_2010_HORAYZON_IntpPRES"
output_prefix = "LHS-wide_Abramov_HARv2_1988-2022.nc" #"Posterior-Mean-Halji_HARv2_1988-2022.nc"

[RESTART]
restart = false # set to true if you want to start from restart file

[STAKE_DATA]
stake_evaluation = false
stakes_loc_file = "./data/input/HEF/loc_stakes.csv" # path to stake location file
stakes_data_file = "./data/input/HEF/data_stakes_hef.csv" # path to stake data file
eval_method = "rmse" # how to evaluate the simulations ("rmse")
obs_type = "snowheight" # What kind of stake data is used "mb" or "snowheight"

["TRANSIENT SNOWLINE DATA"]
time_start_cali = "1990-01-01T00:00"
time_end_cali = "2022-12-31T23:00"
time_start_mb = "2000-01-01T00:00"
time_end_mb = "2020-01-01T00:00"
tsl_evaluation = true #true
write_csv_status = false #true
csv_filename = "localsens_1D20m_1999_2010.csv"
time_col_obs = "LS_DATE"
tsla_col_obs = "TSL_normalized"
min_snowheight = 0.001 # 1mm old functionality
min_albedo_method = true #false
tsl_method = "conservative"
tsl_normalize = true
#tsl_data_file = "./data/input/HEF/snowlines/HEF-snowlines-1999-2010_manual_filtered.csv"
#tsl_data_file = "./data/input/Halji/snowlines/Halji_TSLA_fixed-1990-2025.csv"
tsl_data_file = "./data/input/Abramov/snowlines/Abramov_TSLA_fixed-1990-2024.csv"
point_evaluation = false #false

["RUN LAPSE RATES ONLINE"]
station_altitude = 3030.0283

[DIMENSIONS]
# STANDARD LAT/LON or WRF INPUT
WRF = false # Set to True if you use WRF as input
WRF_X_CSPY = false # Interactive simulation with WRF
northing = "lat" # name of dimension in input and output
easting = "lon" # name of dimension in input and output

[COMPRESSION]
# Compression of output netCDF
# Recommendation: choose 1, 2 or 3 (higher not worthwhile, because of needed time for writing output)
compression_level = 2 # Choose value between 1 and 9 (highest compression)

[PARALLELIZATION]
slurm_use = true #false
workers = 0
local_port = 8786

[FULL_FIELDS]
# WRITE FULL FIELDS
full_field = false # write full fields (2D data) to file

[FORCINGS]
# TOTAL PRECIPITATION
force_use_TP = true #!! aws set true # If total precipitation and snowfall in input data, use total precipitation
# CLOUD COVER FRACTION
# If cloud cover fraction and incoming longwave radiation in input data, use cloud cover fraction
force_use_N = false #!! aws set false
use_srf = true #false

[SUBSET]
# provide pixel values
tile = false
xstart = 20
xend = 40
ystart = 20
yend = 40

[OUTPUT_VARIABLES]
# Select which output variables are written to disk. Comma-separated. Edit with caution.
#output_atm="ALBEDO,SNOWFALL,RRR,U2"
#output_internal="MB,SNOWHEIGHT,ME"
#output_full="HEIGHT"
output_atm = "T2,RH2,U2,RAIN,SNOWFALL,RRR,PRES,N,G,LWin,LWout,H,LE,B,QRR,Z0,ALBEDO,TS"
output_internal = "ME,MB,surfMB,intMB,EVAPORATION,SUBLIMATION,CONDENSATION,DEPOSITION,surfM,subM,Q,REFREEZE,SNOWHEIGHT,TOTALHEIGHT,LAYERS"
output_full = "HEIGHT,RHO,T,LWC,CC,POROSITY,LW,ICE_FRACTION,IRREDUCIBLE_WATER,REFREEZE"
